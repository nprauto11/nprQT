apiVersion: 1
groups:
    - orgId: 1
      name: Prometheus_Cluster02_Status
      folder: Infra-Tahoe
      interval: 1m
      rules:
        - uid: WPwdWiUnz
          title: Prometheus_Cluster02_Status
          condition: prometheus_cluster02_status
          data:
            - refId: prometheus_cluster02
              relativeTimeRange:
                from: 60
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                exemplar: false
                expr: absent(up{prometheus_replica="tahoe-prod-cluster02-prometheus-agent-0"})
                hide: false
                interval: ""
                intervalMs: 1000
                legendFormat: ""
                maxDataPoints: 43200
                range: true
                refId: prometheus_cluster02
            - refId: prometheus_cluster02_status
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 3
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - prometheus_cluster02
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: prometheus_cluster02
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: prometheus_cluster02_status
                type: reduce
          noDataState: OK
          execErrState: Alerting
          for: 1m
          annotations:
            description: Prometheus Cluster02 Status Down
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/14254047956/Prometheus+Thanos+and+Grafana+Monitoring+in+GCP
            summary: Prometheus Cluster02 Status Down
          labels:
            Prometheus_down: cluster02
          isPaused: false
    - orgId: 1
      name: Prometheus_Cluster03_Status
      folder: Infra-Tahoe
      interval: 1m
      rules:
        - uid: P7I9Ck8nz
          title: Prometheus_Cluster03_Status
          condition: prometheus_cluster03_status
          data:
            - refId: prometheus_cluster03
              relativeTimeRange:
                from: 60
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                exemplar: false
                expr: absent(sum(up{prometheus_replica="tahoe-prod-cluster03-prometheus-agent-0"}))
                hide: false
                instant: false
                interval: ""
                intervalMs: 1000
                legendFormat: ""
                maxDataPoints: 43200
                refId: prometheus_cluster03
            - refId: prometheus_cluster03_status
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - prometheus_cluster02
                      reducer:
                        params: []
                        type: sum
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: prometheus_cluster03
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: prometheus_cluster03_status
                type: reduce
          noDataState: OK
          execErrState: Alerting
          for: 1m
          annotations:
            description: Prometheus Cluster03 Status Down
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/14254047956/Prometheus+Thanos+and+Grafana+Monitoring+in+GCP
            summary: Prometheus Cluster03 Status Down
          labels:
            Prometheus_down: cluster03
          isPaused: false
    - orgId: 1
      name: Redis-SFO-OFFER
      folder: Redis-Cluster
      interval: 10s
      rules:
        - uid: gVXcIr54k
          title: Redis | SFO | Service Availability
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_uptime_in_seconds{job="redis-sfo-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 300
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 1m
          annotations:
            description: |-
                Uptime of the Redis service |  Alert on this metric can help you identify unscheduled restarts

                redis_uptime_in_seconds{job="redis-sfo-prod"}  < 300 Seconds
            summary: '"This Redis node got restarted 5min Back (instance {{ $value }})"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: q5yyp9c4k
          title: Redis | SFO | Cluster Status
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_cluster_state{job="redis-sfo-prod",monitor="redis-service"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 30s
          annotations:
            description: |-
                "Cluster is down (instance VALUE = {{ $value }})"

                Exp : redis_cluster_state{job="redis-sfo-prod",monitor="redis-service"}  < 1
            summary: '"Cluster is down (instance VALUE = {{ $value }})"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: E-5t_qcVk
          title: REDIS | SFO | Redis missing master
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_instance_info{role="master",job="redis-sfo-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 5m
          annotations:
            description: '"cluster has no node marked as master VALUE = {{ $value }}"'
            summary: '"Redis missing master VALUE = {{ $value }}"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: RH0Tu3cVk
          title: REDIS | SFO | Redis too many masters
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_instance_info{role="master",job="redis-sfo-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 2m
          annotations:
            description: '"Redis cluster has too many nodes marked as master.\n  VALUE = {{ $value }}"'
            summary: '"Redis too many masters (instance {{ $value }})"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: N0zNC3cVk
          title: REDIS | SFO | Redis replication broken
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: delta(redis_connected_slaves{job="redis-sfo-prod",monitor="redis-service"}[1m])
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 1m
          annotations:
            description: '"Redis instance lost a slave\n  VALUE = {{ $value }}"'
            summary: '"Redis replication broken (instance {{ $value }})"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: F8Skq35Vk
          title: REDIS | SFO | Redis cluster flapping
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: changes(redis_connected_slaves{job="redis-sfo-prod"}[1m])
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 2m
          annotations:
            description: '"Changes have been detected in Redis replica connection. This can occur when replica nodes lose connection to the master and reconnect (a.k.a flapping).\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: |-
                "Redis cluster flapping (instance {{ $value }})"

                Exp : changes(redis_connected_slaves{job="redis-sfo-prod"}[1m])  > 1
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: uKx2M6c4z
          title: REDIS | SFO | Redis is running out of system memory (> 90%)
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_memory_used_bytes{job="redis-sfo-prod"} / redis_memory_max_bytes{job="redis-sfo-prod"} * 100
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 80
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 2m
          annotations:
            description: '"Redis is running out of system memory (> 90%)\n  VALUE = {{ $value }}"'
            summary: |-
                Redis out of system memory (instance {{ $value }})

                redis_memory_used_bytes{job="redis-sfo-prod"} / redis_memory_max_bytes{job="redis-sfo-prod"} * 100
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: ytq8M6cVz
          title: REDIS | SFO | Redis is running out of configured maxmemory (> 90%)
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_memory_used_bytes{job="redis-sfo-prod"} / redis_memory_max_bytes{job="redis-sfo-prod"} * 100
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 90
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 2m
          annotations:
            description: '"Redis is running out of configured max memory (> 90%)\n  VALUE = {{ $value }}"'
            summary: '"Redis out of configured max memory (instance {{ $value }})"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: BxsZne54z
          title: REDIS | SFO | Redis instance has too many connections  > 250
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_connected_clients{job="redis-sfo-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 270
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 2m
          annotations:
            description: |-
                "Redis instance has too many connections\n  VALUE = {{ $value }}"

                "This instance got too many connections (instance {{ $value }})"
            summary: '"This instance has too many connections\n  VALUE = {{ $value }}"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: u2B37e54k
          title: REDIS | SFO | Redis instance should have more connections (> 5)
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_connected_clients{job="redis-sfo-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 2m
          annotations:
            description: '"Redis instance should have more connections (> 5)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: '"This Redis instance is  not having enough connections (instance {{ $value }})"'
          labels:
            redis_sfo: redis_sfo
          isPaused: false
        - uid: mdZSV6cVz
          title: REDIS | SFO | Redis rejected connections
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: increase(redis_rejected_connections_total{job="redis-sfo-prod"}[1m])
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 2m
          annotations:
            description: '"Some connections to Redis has been rejected\n  VALUE = {{ $value }}"'
            summary: |-
                "Redis rejected connections (instance {{ $value }})"

                expr: increase(redis_rejected_connections_total[1m]) > 0
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: deR6I6h4z
          title: REDIS | SFO | High number of commands per second
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: rate(redis_commands_processed_total{job="redis-sfo-prod"}[1m])
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1000
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 2m
          annotations:
            description: This monitors the number of commands per second. If any of the instances gets a number of commands per second goes above 1000 for more than 5 minutes, then alert
            summary: "\"High number of commands per second > 1000 VALUE = \n{{ $value }}\n)\""
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: V43of62Vz
          title: REDIS | SFO | Redis Latency
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 86400
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_last_slow_execution_duration_seconds{job="redis-sfo-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0.5
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 1m
          annotations:
            description: '"Redis instance {{ $value }} has slow command execution"'
            summary: '"Redis instance {{ $value}} has slow command execution"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: WYOg-rcVk
          title: 'Redis | SFO | Redis Service Down '
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_up{job="redis-sfo-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: min
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 30s
          annotations:
            description: '"Redis instance is down \n  VALUE = {{ $value }}"'
            summary: |-
                "Redis down (instance {{ $value }})"

                redis_up{job="redis-sfo-prod"} < 1
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: LJE2AsJ4z
          title: Redis | SFO | One of the Redis instance is HUNG(or)DOWN
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: sum(redis_up{instance=~"sfo-prd-reds20[4-9]:9121|sfo-prd-reds21[4-9]:9121"})
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 12
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 20s
          annotations:
            description: |-
                1--> Check the status of the Redis instances manually to ensure they are up and running.
                You can check in the Grafana dashboard dropdown list if all the 12 nodes are showing

                2-->Verify that the Redis exporter is running and is able to scrape metrics from the Redis instances. You can check the exporter logs to see if there are any errors or warnings.
                systemctl status redis_exporter

                3-->You can do this by querying the Prometheus metrics endpoint of the Redis exporter and looking for the up metric. The endpoint is typically available at http://<redis-exporter-host>:<redis-exporter-port>/metrics
                Ex: http://sfo-prd-redis17.sfo.ci.lan:9121/metrics


                4-->Check if the Redis service is running on the server. You can do this by using the command. ps -ef |grep Redis
            summary: '"One of the Redis instance is HUNG(or)DOWN "'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: b1821c91-cf00-40f0-a6e3-5d07b069001e
          title: REDIS | SFO | CPU Utilization
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: 100 * (rate(redis_cpu_sys_seconds_total{job="redis-sfo-prod"}[5m]) + rate(redis_cpu_user_seconds_total{job="redis-sfo-prod"}[5m]))
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 80
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 2m
          annotations:
            summary: |-
                "REDIS CPU Utilization VALUE = {{ $value }}"

                100 * (rate(redis_cpu_sys_seconds_total{job="rdst-sfo-prod"}[5m]) + rate(redis_cpu_user_seconds_total{job="rdst-sfo-prod"}[5m]))
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: fTG_0Uh4k
          title: 'REDIS | SFO | Redis blocked clients '
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_blocked_clients{job="redis-sfo-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 5m
          annotations:
            description: '"Redis Blocked connections \n  VALUE = {{ $value }}"'
            summary: '"This Redis instance has Blocked connections \n  VALUE = {{ $value }}"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
    - orgId: 1
      name: Redis-DCA-Token
      folder: Redis-DCA-Token
      interval: 10s
      rules:
        - uid: c06fe94c-3a1c-43b1-a93c-4fb660191dcd
          title: Redis | DCA | Token Cluster Status
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_cluster_state{job="rdst-dca-prod",monitor="redis-service"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 1m
          annotations:
            description: '"DCA REDIS Token Cluster Status is down VALUE = {{ $value }})"'
            summary: |-
                Cluster is down (instance VALUE = {{ $value }})"

                Exp : redis_cluster_state{job="rdst-dca-prod",monitor="redis-service"}
          labels:
            redis_dca: redis_token_dca
          isPaused: false
        - uid: df47fe99-e8a5-487b-8af2-762bef77ee10
          title: REDIS | DCA | Token cluster flapping
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: changes(redis_connected_slaves{job="rdst-dca-prod"}[1m])
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 1m
          annotations:
            description: |-
                Redis cluster flapping (instance {{ $labels.instance }})

                Exp : changes(redis_connected_slaves{job="rdst-dca-prod"}[1m])  > 1
            summary: '"Changes have been detected in Redis replica connection. This can occur when replica nodes lose connection to the master and reconnect (a.k.a flapping).\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_token_dca
          isPaused: false
        - uid: ceafd286-5332-4da0-a7db-46378de15a20
          title: REDIS | DCA |  Redis Token Cluster is running out of configured maxmemory (> 90%)
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_memory_used_bytes{job="rdst-dca-prod"} / redis_memory_max_bytes{job="rdst-dca-prod"} * 100
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 80
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 1m
          annotations:
            description: Redis out of configured maxmemory (instance {{ $labels.instance }})
            summary: '"Redis is running out of configured maxmemory (> 90%)\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_token_dca
          isPaused: false
        - uid: b945f660-68a6-447a-9c84-4375096a8856
          title: REDIS | DCA | Redis Token Cluster instance should have more connections (> 5)
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_connected_clients{job="rdst-dca-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 30s
          annotations:
            description: Redis not enough connections (instance {{ $labels.instance }})
            summary: '"Redis instance should have more connections (> 5)\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_token_dca
          isPaused: false
        - uid: a101ffca-aca5-4469-b85e-ba8df881ab27
          title: REDIS | DCA | Redis Token Cluster missing master
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_instance_info{role="master",job="rdst-dca-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 2m
          annotations:
            description: Redis missing master (instance {{ $labels.instance }})
            summary: '"cluster has no node marked as master.\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_token_dca
          isPaused: false
        - uid: ed668c45-2b40-482f-9b21-57b54f78a423
          title: REDIS | DCA | Redis Token Cluster is running out of system memory (> 90%)
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_memory_used_bytes{job="rdst-dca-prod"} / redis_memory_max_bytes{job="rdst-dca-prod"} * 100
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 80
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 1m
          annotations:
            description: |-
                Redis out of system memory (instance {{ $labels.instance }})

                redis_memory_used_bytes{job="rdst-dca-prod"} / redis_memory_max_bytes{job="rdst-dca-prod"} * 100
            summary: '"Redis is running out of system memory (> 90%)\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_token_dca
          isPaused: false
        - uid: a15be1b2-8ad4-4ad1-b991-181220866dd3
          title: REDIS | DCA | Redis Token Cluster rejected connections
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: increase(redis_rejected_connections_total{job="rdst-dca-prod"}[1m])
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 2m
          annotations:
            description: |-
                Redis rejected connections (instance {{ $labels.instance }})

                expr: increase(redis_rejected_connections_total[1m]) > 0
            summary: '"Some connections to Redis has been rejected\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_token_dca
          isPaused: false
        - uid: b4cf537a-d8d7-4cd7-8b13-68a50157b5da
          title: REDIS | DCA | Redis Token Cluster replication broken
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: delta(redis_connected_slaves{job="rdst-dca-prod",monitor="redis-service"}[1m])
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 30s
          annotations:
            description: Redis replication broken (instance {{ $labels.instance }})
            summary: '"Redis instance lost a slave\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_token_dca
          isPaused: false
        - uid: cf060348-6b91-4e51-b372-49da8c409604
          title: 'Redis | DCA | Token Cluster Redis Service Down '
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_up{job="rdst-dca-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 30s
          annotations:
            description: '"Redis Service Down   VALUE = {{ $value }}"'
            summary: '"Redis Service Down   VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_token_dca
          isPaused: false
        - uid: ce870eb2-ac4d-4a5b-83d8-0c60f8e18d13
          title: REDIS | DCA | Token Cluster Redis too many masters
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_instance_info{role="master",job="rdst-dca-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 30s
          annotations:
            description: Redis too many masters (instance {{ $value }})
            summary: '"Redis cluster has too many nodes marked as master.\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_token_dca
          isPaused: false
        - uid: aad80938-a711-411b-9809-0b7ca4021c5c
          title: REDIS | DCA | Token Cluster Redis blocked clients
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_blocked_clients{job="rdst-dca-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 30s
          annotations:
            description: "\"Redis Blocked connections \\n  VALUE = \n{{ $value }}\n\""
            summary: "\"Redis Blocked connections \\n  VALUE = \n{{ $value }}\n\""
          labels:
            redis_dca: redis_token_dca
          isPaused: false
        - uid: a6e907f8-ecb2-43d2-852c-5da73b8d2a65
          title: REDIS | DCA | Token Cluster High number of commands per second
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: rate(redis_commands_processed_total{job="rdst-dca-prod"}[1m])
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1000
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 1m
          annotations:
            description: This monitors the number of commands per second. If any of the instances get a number of commands per second goes above 1000 for more than 1 minute, then alert
            summary: '"High number of commands per second > 1000 VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_token_dca
          isPaused: false
        - uid: b0397f0d-0a71-43f3-9c1d-989c343b8a83
          title: REDIS | DCA | Average Time Spent by Commands
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: "sum(irate(redis_commands_duration_seconds_total{job=\"rdst-dca-prod\"}[1m])) by (cmd)\r\n  /\r\nsum(irate(redis_commands_total{job=\"rdst-dca-prod\"}[1m])) by (cmd)\r\n"
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0.03
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 30s
          annotations:
            description: Any of the commands took more than 30ms of time
            summary: '"Average Time Spent by Commands > 30 ms {{ $value }}"'
          labels:
            redis_dca: redis_token_dca
          isPaused: false
        - uid: e996bb87-83b3-4867-a6bd-408c16291b09
          title: Redis | DCA | Token Cluster One of the Redis instance is HUNG(or)DOWN
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: code
                expr: sum(redis_up{instance=~"dca-prd-rdst20[1-9]:9121|dca-prd-rdst21[0-2]:9121"})
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 12
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 20s
          annotations:
            description: |-
                1--> Check the status of the Redis instances manually to ensure they are up and running.
                You can check in the Grafana dashboard dropdown list, if all the 12 nodes are showing

                2-->Verify that the Redis exporter is running and is able to scrape metrics from the Redis instances. You can check the exporter logs to see if there are any errors or warnings.
                systemctl status redis_exporter

                3-->You can do this by querying the Prometheus metrics endpoint of the Redis exporter and looking for the up metric. The endpoint is typically available at http://<redis-exporter-host>:<redis-exporter-port>/metrics
                Ex: http://sfo-prd-redis17.sfo.ci.lan:9121/metrics


                4-->Check if the Redis service is running on the server. You can do this by using the command. ps -ef |grep Redis
            summary: '"One of the redis instance is HUNG or Down"'
          labels:
            redis_dca: redis_token_dca
          isPaused: false
        - uid: e0f20832-cf99-44e5-8d93-97ffe50ea338
          title: REDIS | DCA | Token Cluster Redis instance has too many connections  > 250
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_connected_clients{job="rdst-dca-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 250
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 30s
          annotations:
            description: '"Redis too many connections (instance {{  $value  }})"'
            summary: '"Redis instance has too many connections\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_token_dca
          isPaused: false
    - orgId: 1
      name: Redis-DCA-Offer
      folder: Redis-DCA-Offer
      interval: 10s
      rules:
        - uid: c28dc9db-0082-45c0-933c-d4ea6ae7806e
          title: Redis | DCA | Offer Cluster Status
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_cluster_state{job="reds-dca-prod",monitor="redis-service"}
                hide: false
                instant: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 1m
          annotations:
            description: '"DCA REDIS Offer Cluster Status is down VALUE = {{ $value }})"'
            summary: |-
                Offer Cluster is down (instance VALUE = {{ $value }})"

                Exp : redis_cluster_state{job="reds-dca-prod",monitor="reds-service"} < 1
          labels:
            redis_dca: redis_offer_dca
          isPaused: false
        - uid: abdf9d7b-78bc-4f7c-a11e-515d7baca563
          title: REDIS | DCA | Redis Offer cluster flapping
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: changes(redis_connected_slaves{job="reds-dca-prod"}[1m])
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Error
          for: 1m
          annotations:
            description: |-
                Redis cluster flapping (instance {{ $labels.instance }})

                Exp : changes(redis_connected_slaves{job="reds-dca-prod"}[1m])  > 1
            summary: '"Changes have been detected in Redis replica connection. This can occur when replica nodes lose connection to the master and reconnect (a.k.a flapping).\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_offer_dca
          isPaused: false
        - uid: ae54a5a6-4681-40f8-92aa-765764871b45
          title: REDIS | DCA | Redis Offer cluster is running out of configured maxmemory (> 90%)
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_memory_used_bytes{job="reds-dca-prod"} / redis_memory_max_bytes{job="reds-dca-prod"} * 100
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 80
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Error
          for: 1m
          annotations:
            description: Redis out of configured maxmemory (instance {{ $labels.instance }})
            summary: '"Redis is running out of configured maxmemory (> 90%)\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_offer_dca
          isPaused: false
        - uid: b3bf90e1-181d-4baa-8467-34c77b6c36f6
          title: REDIS | DCA | Offer Redis instance should have more connections (> 5)
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_connected_clients{job="reds-dca-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Error
          for: 30s
          annotations:
            description: Redis not enough connections (instance {{ $labels.instance }})
            summary: '"Redis instance should have more connections (> 5)\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_offer_dca
          isPaused: false
        - uid: baed6c27-4ed6-4c6c-b141-c330ab8ab727
          title: REDIS | DCA | Offer Redis is running out of system memory (> 90%)
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_memory_used_bytes{job="reds-dca-prod"} / redis_memory_max_bytes{job="reds-dca-prod"} * 100
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 80
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Error
          for: 1m
          annotations:
            description: |-
                Redis out of system memory (instance {{ $labels.instance }})

                redis_memory_used_bytes{job="reds-sfo-prod"} / redis_memory_max_bytes{job="reds-sfo-prod"} * 100
            summary: '"Redis is running out of system memory (> 90%)\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_offer_dca
          isPaused: false
        - uid: f83032f6-9337-44c0-ad9d-0c98cdba66bc
          title: REDIS | DCA | Offer Redis missing master
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_instance_info{role="master",job="reds-dca-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Error
          for: 2m
          annotations:
            description: Redis missing master (instance {{ $labels.instance }})
            summary: '"cluster has no node marked as master.\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_offer_dca
          isPaused: false
        - uid: e5359b35-acdd-4f7e-b0d9-804b8468f984
          title: REDIS | DCA | Offer Redis rejected connections
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: increase(redis_rejected_connections_total{job="reds-dca-prod"}[1m])
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Error
          for: 2m
          annotations:
            description: |-
                Redis rejected connections (instance {{ $labels.instance }})

                expr: increase(redis_rejected_connections_total[1m]) > 0
            summary: '"Some connections to Redis has been rejected\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_offer_dca
          isPaused: false
        - uid: e6679c58-6b2c-4262-9051-b4cebe5fae81
          title: REDIS | DCA |Offer Cluster Redis replication broken
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: delta(redis_connected_slaves{job="reds-dca-prod",monitor="redis-service"}[1m])
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 30s
          annotations:
            description: Redis replication broken (instance {{ $labels.instance }})
            summary: '"Redis instance lost a slave\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_offer_dca
          isPaused: false
        - uid: b7aec793-c9a6-420d-92f0-57fa59c8ea29
          title: 'Redis | DCA | Offer Cluster Redis Service Down '
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_up{job="reds-dca-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 30s
          annotations:
            description: '"Redis Service Down   VALUE = {{ $value }}"'
            summary: '"Redis Service Down   VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_offer_dca
          isPaused: false
        - uid: ef581224-dc03-48ab-b7ae-2fa786bdfb4a
          title: REDIS | DCA | Offer Cluster Redis too many masters
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_instance_info{role="master",job="reds-dca-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 30s
          annotations:
            description: Redis too many masters (instance {{ $value }})
            summary: '"Redis cluster has too many nodes marked as master.\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_offer_dca
          isPaused: false
        - uid: ea0c72d0-cfc3-4d7b-b21b-0284ac15ea7a
          title: REDIS | DCA | Offer Cluster Redis blocked clients
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_blocked_clients{job="reds-dca-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 30s
          annotations:
            description: "\"Redis Blocked connections \\n  VALUE = \n{{ $value }}\n\""
            summary: "\"Redis Blocked connections \\n  VALUE = \n{{ $value }}\n\""
          labels:
            redis_dca: redis_offer_dca
          isPaused: false
        - uid: c5a868ee-f4c6-494f-9485-8171f2b96e5b
          title: REDIS | DCA | Offer Cluster High number of commands per second
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: rate(redis_commands_processed_total{job="reds-dca-prod"}[1m])
                instant: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1000
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 1m
          annotations:
            description: This monitors the number of commands per second. If any of the instances get a number of commands per second goes above 1000 for more than 1 minute, then alert
            summary: '"High number of commands per second > 1000 VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_offer_dca
          isPaused: false
        - uid: a5777593-3260-4e11-b99f-f766b1f8f46f
          title: REDIS | DCA | Offer Cluster Average Time Spent by Commands
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: "sum(irate(redis_commands_duration_seconds_total{job=\"reds-dca-prod\"}[1m])) by (cmd)\r\n  /\r\nsum(irate(redis_commands_total{job=\"reds-dca-prod\"}[1m])) by (cmd)"
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0.03
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 30s
          annotations:
            description: Any of the commands took more than 30ms of time
            summary: '"Average Time Spent by Commands > 30 ms {{ $value }}"'
          labels:
            redis_dca: redis_offer_dca
          isPaused: false
        - uid: b929df39-bc46-4472-baa5-2a1be4475732
          title: Redis | DCA | Offer Cluster One of the Redis instance is HUNG(or)DOWN
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: sum(redis_up{instance=~"dca-prd-reds20[4-9].dca.ci.lan:9121|dca-prd-reds21[4-9].dca.ci.lan:9121"})
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 12
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 20s
          annotations:
            description: |-
                1--> Check the status of the Redis instances manually to ensure they are up and running.
                You can check in the Grafana dashboard dropdown list, if all the 12 nodes are showing

                2-->Verify that the Redis exporter is running and is able to scrape metrics from the Redis instances. You can check the exporter logs to see if there are any errors or warnings.
                systemctl status redis_exporter

                3-->You can do this by querying the Prometheus metrics endpoint of the Redis exporter and looking for the up metric. The endpoint is typically available at http://<redis-exporter-host>:<redis-exporter-port>/metrics
                Ex: http://sfo-prd-redis17.sfo.ci.lan:9121/metrics


                4-->Check if the Redis service is running on the server. You can do this by using the command. ps -ef |grep Redis
            summary: '"One of the redis instance is HUNG or Down"'
          labels:
            redis_dca: redis_offer_dca
          isPaused: false
        - uid: fe76c84a-c4f6-4807-ae40-9785f1feff4e
          title: REDIS | DCA | Offer Cluster Redis instance has too many connections  > 250
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_connected_clients{job="reds-dca-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 250
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 30s
          annotations:
            description: '"Redis too many connections (instance {{  $value  }})"'
            summary: '"Redis instance has too many connections\n  VALUE = {{ $value }}"'
          labels:
            redis_dca: redis_offer_dca
          isPaused: false
    - orgId: 1
      name: ETL-JOBS
      folder: QTA
      interval: 1m
      rules:
        - uid: bb525092-6911-44bd-99df-613c8af8b4e5
          title: ETL-QT-ACTIVATION-REDEMPTIONS-TO-NRS-PROD
          condition: CopyCronJobMaxFailThreshold
          data:
            - refId: CopyToNrsS3BucketFailureProd
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: sum(count_over_time({cluster="gke-gke-bi-uswst2-prod-active", namespace="etl", job=~"etl/qt-activations-redemptions-to-nrs.*",component!="gke-gcsfuse-sidecar"} |= `FAILED TO COPY` |= `bkt-etl-prod`[5m]))
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: CopyToNrsS3BucketFailureProd
            - refId: CopyCronJobMaxFailCount
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: CopyToNrsS3BucketFailureProd
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: CopyCronJobMaxFailCount
                type: reduce
            - refId: CopyCronJobMaxFailThreshold
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: CopyCronJobMaxFailCount
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: CopyCronJobMaxFailThreshold
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 1m
          annotations:
            description: |-
                Please check Job logs at below url and troubleshoot issue and fix.
                https://grafana.corp.quotient.com/goto/vFb81hcSg?orgId=1
            summary: 'PROD: Cron job to copy ETL files from GCS bucket to NRS AWS S3 bucket FAILED.'
          labels:
            metric: etl-jobs
          isPaused: false
        - uid: cdcfc6b8-a2ec-40f5-b10a-6258645b7cac
          title: ETL-QT-USER-ACTIVATION-REDEMPTIONS-TO-NRS-PROD
          condition: CopyCronJobMaxFailThreshold
          data:
            - refId: CopyToNrsS3BucketFailureProd
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: sum(count_over_time({cluster="gke-gke-bi-uswst2-prod-active", namespace="etl", job=~"etl/qt-user-activations-redemptions-to-nrs.*",component!="gke-gcsfuse-sidecar"} |= `FAILED TO COPY` |= `bkt-etl-prod`[5m]))
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: CopyToNrsS3BucketFailureProd
            - refId: CopyCronJobMaxFailCount
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: CopyToNrsS3BucketFailureProd
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: CopyCronJobMaxFailCount
                type: reduce
            - refId: CopyCronJobMaxFailThreshold
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: CopyCronJobMaxFailCount
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: CopyCronJobMaxFailThreshold
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 1m
          annotations:
            description: |-
                Please check Job logs at below url and troubleshoot issue and fix.
                https://grafana.corp.quotient.com/goto/NtlZyAcSR?orgId=1
            summary: 'PROD: Cron job to copy ETL files from GCS bucket to NRS AWS S3 bucket FAILED.'
          labels:
            metric: etl-jobs
          isPaused: false
        - uid: b82b87af-586f-4d15-aba4-22510d19c758
          title: ETL-NRS-CO51-NAM-FEED-TO-QT-PROD
          condition: CopyCronJobMaxFailThreshold
          data:
            - refId: CopyFromNrsS3BucketFailureProd
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: sum(count_over_time({cluster="gke-gke-bi-uswst2-prod-active", namespace="etl", job=~"etl/nrs-co51-nam-data-feed-to-qt.*",component!="gke-gcsfuse-sidecar"} |= `FAILED TO COPY` |= `bkt-etl-prod`[5m]))
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: CopyFromNrsS3BucketFailureProd
            - refId: CopyCronJobMaxFailCount
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: CopyFromNrsS3BucketFailureProd
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: CopyCronJobMaxFailCount
                type: reduce
            - refId: CopyCronJobMaxFailThreshold
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: CopyCronJobMaxFailCount
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: CopyCronJobMaxFailThreshold
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 1m
          annotations:
            description: |-
                Please check Job logs at below url and troubleshoot issue and fix.
                https://grafana.corp.quotient.com/goto/li9RsMhSg?orgId=1
            summary: 'PROD: Cron job to copy CO51 feeds from NRS S3 bucket to QT GCS bkt-etl-multi-prod Failed.'
          labels:
            metric: etl-jobs
          isPaused: false
        - uid: b88eb71f-c128-452f-9f05-8af8c14bd7a6
          title: ETL-NRS-CO51-4SQ-VISITS-TO-QT-PROD
          condition: CronJobMaxFailThreshold
          data:
            - refId: FromNrsS3BucketFailureProd
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: sum(count_over_time({cluster="gke-gke-bi-uswst2-prod-active", namespace="etl", job=~"etl/nrs-co51-4sq-visits-to-qt.*",component!="gke-gcsfuse-sidecar"} |~ `FAILED TO COPY`[5m]))
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: FromNrsS3BucketFailureProd
            - refId: CronJobMaxFailCount
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: FromNrsS3BucketFailureProd
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: CronJobMaxFailCount
                type: reduce
            - refId: CronJobMaxFailThreshold
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: CronJobMaxFailCount
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: CronJobMaxFailThreshold
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 1m
          annotations:
            description: |-
                Please check Job logs at below url and troubleshoot issue and fix.
                https://grafana.corp.quotient.com/goto/v5rIFq0Ig?orgId=1
            summary: 'PROD: Cron job to copy CO51 4 Square Visits Feeds from NRS S3 bucket to QT GCS bkt-etl-multi-prod Failed.'
          labels:
            metric: etl-jobs
          isPaused: false
        - uid: c57641a0-e09c-4e37-8348-bee44270406d
          title: ETL-NRS-FREEDOM-FEEDS-TO-QT-PROD
          condition: CronJobMaxFailThreshold
          data:
            - refId: FromNrsS3BucketFailureProd
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: sum(count_over_time({cluster="gke-gke-bi-uswst2-prod-active", namespace="etl", job=~"etl/nrs-freedom-feeds.*",component!="gke-gcsfuse-sidecar"} |~ `FAILED TO COPY`[5m]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: FromNrsS3BucketFailureProd
            - refId: CronJobMaxFailCount
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: FromNrsS3BucketFailureProd
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: CronJobMaxFailCount
                type: reduce
            - refId: CronJobMaxFailThreshold
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: CronJobMaxFailCount
                intervalMs: 1000
                maxDataPoints: 43200
                refId: CronJobMaxFailThreshold
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 1m
          annotations:
            description: |-
                Please check Job logs at below url and troubleshoot issue and fix.
                https://grafana.corp.quotient.com/goto/K4BlePXSR?orgId=1
            summary: 'PROD: Cron job to copy Freedom Feeds from NRS S3 bucket to QT GCS bkt-etl-multi-prod Failed.'
          labels:
            metric: etl-jobs
          isPaused: false
    - orgId: 1
      name: Redis-SFO-Token
      folder: Redis-SFO-Token
      interval: 10s
      rules:
        - uid: db8bcff8-5b2e-4c74-b717-5d03205cab5d
          title: Redis | SFO | Token Cluster Status
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_cluster_state{job="rdst-sfo-prod",monitor="redis-service"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 1m
          annotations:
            description: |-
                "Cluster is down (instance VALUE = {{ $value }})"

                Exp : redis_cluster_state{job="rdst-sfo-prod",monitor="redis-service"}  < 1
            summary: '"Cluster is down (instance VALUE = {{ $value }})"'
          labels:
            redis_sfo: redis_token_sfo
          isPaused: false
        - uid: 28q_hehVz
          title: REDIS | SFO | CPU Utilization
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: code
                expr: 100 * (rate(redis_cpu_sys_seconds_total{job="rdst-sfo-prod"}[5m]) + rate(redis_cpu_user_seconds_total{job="rdst-sfo-prod"}[5m]))
                hide: false
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 80
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 2m
          annotations:
            summary: |-
                "REDIS CPU Utilization VALUE = {{ $value }}"

                100 * (rate(redis_cpu_sys_seconds_total{job="rdst-sfo-prod"}[5m]) + rate(redis_cpu_user_seconds_total{job="rdst-sfo-prod"}[5m]))
          labels:
            redis_sfo: sfo_token_cluster
          isPaused: false
        - uid: e15264ad-7719-4e3b-b540-f7ee5dd95ce3
          title: Redis | SFO | Service Availability
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_uptime_in_seconds{job="rdst-sfo-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 300
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 1m
          annotations:
            summary: |-
                "Cluster is down (instance VALUE = {{ $value }})"

                Exp : redis_cluster_state{job="rdst-sfo-prod",monitor="redis-service"}  < 1
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: bc2bc828-128f-41bf-9936-dda0a17e718c
          title: REDIS | SFO | Redis missing master
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_instance_info{role="master",job="rdst-sfo-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 1m
          annotations:
            description: '"Redis missing master VALUE = {{ $value }}"'
            summary: '"cluster has no node marked as master VALUE = {{ $value }}"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: b6863e07-cbd0-4b9d-94af-5763cda42a71
          title: REDIS | SFO | Redis too many masters
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_instance_info{role="master",job="rdst-sfo-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 2m
          annotations:
            description: '"Redis too many masters (instance {{ $value }})"'
            summary: '"Redis cluster has too many nodes marked as master.\n  VALUE = {{ $value }}"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: d1ddbfc9-2038-40a8-9c73-275e403940bf
          title: REDIS | SFO | Redis replication broken
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: delta(redis_connected_slaves{job="rdst-sfo-prod",monitor="redis-service"}[1m])
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 1m
          annotations:
            description: '"Redis replication broken (instance {{ $value }})"'
            summary: '"Redis instance lost a slave\n  VALUE = {{ $value }}"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: fa192749-3580-4343-9bcb-7b0df3c924df
          title: REDIS | SFO | Redis cluster flapping
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: changes(redis_connected_slaves{job="rdst-sfo-prod"}[1m])
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 2m
          annotations:
            description: |-
                "Redis cluster flapping (instance {{ $value }})"

                Exp : changes(redis_connected_slaves{job="redis-sfo-prod"}[1m])  > 1
            summary: '"Changes have been detected in Redis replica connection. This can occur when replica nodes lose connection to the master and reconnect (a.k.a flapping).\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: f09ab4fe-9279-4481-a000-4487382304fb
          title: REDIS | SFO | Redis is running out of system memory (> 90%)
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_memory_used_bytes{job="rdst-sfo-prod"} / redis_memory_max_bytes{job="rdst-sfo-prod"} * 100
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 80
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 2m
          annotations:
            description: |-
                Redis out of system memory (instance {{ $value }})

                redis_memory_used_bytes{job="rdst-sfo-prod"} / redis_memory_max_bytes{job="rdst-sfo-prod"} * 100
            summary: '"Redis is running out of system memory (> 90%)\n  VALUE = {{ $value }}"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: c3d97af1-57e0-4b56-8275-c65fe6eec5ab
          title: REDIS | SFO | Redis is running out of configured maxmemory (> 90%)
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_memory_used_bytes{job="rdst-sfo-prod"} / redis_memory_max_bytes{job="rdst-sfo-prod"} * 100
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 90
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 2m
          annotations:
            description: '"Redis out of configured max memory (instance {{ $value }})"'
            summary: '"Redis is running out of configured max memory (> 90%)\n  VALUE = {{ $value }}"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: ad73f290-bf48-49c5-b9a5-41138955b206
          title: REDIS | SFO | Redis instance has too many connections  > 250
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_connected_clients{job="rdst-sfo-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 250
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 2m
          annotations:
            description: '"This instance has too many connections\n  VALUE = {{ $value }}"'
            summary: |-
                "Redis instance has too many connections\n  VALUE = {{ $value }}"

                "This instance got too many connections (instance {{ $value }})"
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: a1fc5aab-fab5-41af-bc19-e99be6e062f6
          title: REDIS | SFO | Redis instance should have more connections (> 5)
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_connected_clients{job="rdst-sfo-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 2m
          annotations:
            description: '"This Redis instance is  not having enough connections (instance {{ $value }})"'
            summary: '"Redis instance should have more connections (> 5)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: cf683db6-fb9a-439c-a515-7d05b89518af
          title: REDIS | SFO | Redis rejected connections
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: increase(redis_rejected_connections_total{job="rdst-sfo-prod"}[1m])
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 2m
          annotations:
            description: |-
                "Redis rejected connections (instance {{ $value }})"

                expr: increase(redis_rejected_connections_total[1m]) > 0
            summary: '"Some connections to Redis has been rejected\n  VALUE = {{ $value }}"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: fd754757-c1a5-40f1-aa50-e19661159640
          title: REDIS | SFO | High number of commands per second
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: rate(redis_commands_processed_total{job="rdst-sfo-prod"}[1m])
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1000
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 2m
          annotations:
            description: "\"High number of commands per second > 1000 VALUE = \n{{ $value }}\n)\""
            summary: This monitors the number of commands per second. If any of the instances gets a number of commands per second goes above 1000 for more than 5 minutes, then alert
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: ce1158eb-9ebe-40cc-ba17-0eb1435eb503
          title: REDIS | SFO | Redis Latency
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_last_slow_execution_duration_seconds{job="rdst-sfo-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0.5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: NoData
          execErrState: Alerting
          for: 1m
          annotations:
            description: '"Redis instance {{ $value}} has slow command execution"'
            summary: '"Redis instance {{ $value }} has slow command execution"'
          labels:
            redis_sfo: sfo_token_cluster
          isPaused: false
        - uid: e78a5c9e-df3e-44f0-bf47-6f66cb0dfaf4
          title: 'Redis | SFO | Redis Service Down '
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_up{job="rdst-sfo-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 30s
          annotations:
            description: |-
                "Redis down (instance {{ $value }})"

                redis_up{job="redis-sfo-prod"} < 1
            summary: '"Redis instance is down \n  VALUE = {{ $value }}"'
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: e92ea807-1217-4eae-9aec-25758de86c68
          title: Redis | SFO | One of the Redis instance is HUNG(or)DOWN
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: sum(redis_up{instance=~"sfo-prd-rdst20[1-9].sfo.ci.lan:9121|sfo-prd-rdst21[0-2].sfo.ci.lan:9121"})
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 12
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 30s
          annotations:
            description: '"One of the Redis instance is HUNG(or)DOWN "'
            summary: |-
                1--> Check the status of the Redis instances manually to ensure they are up and running.
                You can check in the Grafana dashboard dropdown list if all the 12 nodes are showing

                2-->Verify that the Redis exporter is running and is able to scrape metrics from the Redis instances. You can check the exporter logs to see if there are any errors or warnings.
                systemctl status redis_exporter

                3-->You can do this by querying the Prometheus metrics endpoint of the Redis exporter and looking for the up metric. The endpoint is typically available at http://<redis-exporter-host>:<redis-exporter-port>/metrics
                Ex: http://sfo-prd-redis17.sfo.ci.lan:9121/metrics


                4-->Check if the Redis service is running on the server. You can do this by using the command. ps -ef |grep Redis
          labels:
            redis_sfo: sfo_redis
          isPaused: false
        - uid: ec882b2c-cc76-40b7-9219-5ce67ac6f58b
          title: Redis | SFO | High Redis Output Buffer Usage
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: redis_client_recent_max_output_buffer_bytes{job="rdst-sfo-prod"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 80000
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: Alerting
          execErrState: Alerting
          for: 2m
          annotations:
            description: This alert is triggered when the Redis output buffer usage exceeds a certain threshold in the SFO Redis token cluster instance. High output buffer usage might indicate a potential performance issue or increased network activity. Please investigate the cause and take appropriate actions to ensure optimal Redis operation
            summary: High Redis Output Buffer Usage in SFO Token Cluster
          labels:
            redis_sfo: sfo_token_cluster
          isPaused: false
    - orgId: 1
      name: System-Events (Node_Exporter)
      folder: RIQ-POC
      interval: 5m
      rules:
        - uid: d681c46a-aa94-46bb-8450-c8f3a37d2fff
          title: HostOomKillDetected | warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: increase(node_vmstat_oom_kill{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[15m]) > 0
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostOomKillDetected
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostOomKillDetected
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: HostOomKillDetected
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: OOM kill detected\n  VALUE = {{ $value }}
            summary: Host OOM kill detected (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: f2663a48-2c18-4019-95fd-1e77c3e39a1f
          title: HostOutOfMemory | warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: "100 * (\n  1 - (\n    node_memory_MemAvailable_bytes{cluster=~\"tahoe-prod-cluster02|tahoe-prod-cluster03\",job=\"tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter\",project=\"riq-poc\"} \n    /\n    node_memory_MemTotal_bytes{cluster=~\"tahoe-prod-cluster02|tahoe-prod-cluster03\",job=\"tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter\",project=\"riq-poc\"}\n  )\n)\n"
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: NODE_MEMORY
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: NODE_MEMORY
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 90
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: NODE_MEMORY
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: Node memory is filling up (< 10% left)\n  VALUE = {{ $value }}
            summary: Host out of memory (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: b1a59f80-a5c5-4f48-a9ae-397498669332
          title: HostHighCpuLoad
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle", cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03", job=~"tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter", project="riq-poc"}[2m])) * 100)
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostHighCpuLoad
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostHighCpuLoad
                type: reduce
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 80
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: HostHighCpuLoad
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: CPU load is > 80%\n  VALUE = {{ $value }}
            summary: Host high CPU load (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: a2c3a6fe-705c-4a44-8b24-038863f187fd
          title: HostMemoryUnderMemoryPressure | warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: rate(node_vmstat_pgmajfault{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[1m])
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: page_faults
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: page_faults
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1000
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: page_faults
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: The node is under heavy memory pressure. High rate of major page faults\n  VALUE = {{ $value }}
            summary: Host memory under memory pressure (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: a1f912b2-bbca-41a3-8a52-a83fa332bde5
          title: HostUnusualNetworkThroughputIn
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: sum by (instance) (rate(node_network_receive_bytes_total{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[5m])) / 1024 / 1024
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: NetworkThroughputIn
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: NetworkThroughputIn
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 100
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: NetworkThroughputIn
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: Host network interfaces are probably receiving too much data (> 100 MB/s)\n  VALUE = {{ $value }}
            summary: Host unusual network throughput in (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: a8d178f0-97af-48f6-85af-4aa4ceea53d4
          title: HostUnusualNetworkThroughputOut
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: sum by (instance) (rate(node_network_transmit_bytes_total{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[5m])) / 1024 / 1024
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: NetworkThroughputOut
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: NetworkThroughputOut
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 100
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: NetworkThroughputOut
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: Host network interfaces are probably sending too much data (> 100 MB/s)\n  VALUE = {{ $value }}
            summary: Host unusual network throughput out (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: f879974d-f7eb-46cc-98be-ed12e0982584
          title: HostUnusualDiskReadRate
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: sum by (instance) (rate(node_disk_read_bytes_total{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[5m])) / 1024 / 1024
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: UnusualDiskReadRate
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: UnusualDiskReadRate
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 50
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: UnusualDiskReadRate
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: Disk is probably reading too much data (> 50 MB/s)\n  VALUE = {{ $value }}
            summary: Host unusual disk read rate (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: ecfa1a59-b1fb-44b3-8ae4-2c78d33ce4ab
          title: HostUnusualDiskWriteRate
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: sum by (instance) (rate(node_disk_written_bytes_total{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[5m])) / 1024 / 1024
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostUnusualDiskWriteRate
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostUnusualDiskWriteRate
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 50
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: HostUnusualDiskWriteRate
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: Disk is probably writing too much data (> 50 MB/s)\n  VALUE = {{ $value }}
            summary: Host unusual disk write rate (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: ee0aef5d-81b0-4151-b8e7-82cf5e759be5
          title: HostOutOfDiskSpace
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |
                    (
                      100 * (1 - (
                        node_filesystem_avail_bytes{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}
                        / node_filesystem_size_bytes{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}
                      ))
                    )
                      and
                    ON (instance, device, mountpoint)
                    node_filesystem_readonly{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"} == 0
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostOutOfDiskSpace
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostOutOfDiskSpace
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 80
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: HostOutOfDiskSpace
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: Disk is almost full (< 10% left)\n  VALUE = {{ $value }}
            summary: Host out of disk space (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: e17ef65f-517d-4eaf-af78-8c8caeddce95
          title: HostDiskWillFillIn24Hours
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |
                    (
                      100 * (
                        1 - (
                          node_filesystem_avail_bytes{fstype!~"tmpfs", cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}
                          / node_filesystem_size_bytes{fstype!~"tmpfs", cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}
                        )
                      )
                      and
                      ON (instance, device, mountpoint)
                      predict_linear(
                        node_filesystem_avail_bytes{fstype!~"tmpfs", cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[1h],
                        24 * 3600
                      ) < 0
                      and
                      ON (instance, device, mountpoint)
                      node_filesystem_readonly{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"} == 0
                    )
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostDiskWillFillIn24Hours
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostDiskWillFillIn24Hours
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 80
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: HostDiskWillFillIn24Hours
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: Filesystem is predicted to run out of space within the next 24 hours at current write rate\n  VALUE = {{ $value }}
            summary: Host disk will fill in 24 hours (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: ceac5ba5-0696-4215-aa3f-f63fc1c5b83c
          title: HostUnusualDiskReadLatency
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |-
                    (
                      rate(node_disk_read_time_seconds_total{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[1m])
                      /
                      rate(node_disk_reads_completed_total{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[1m])
                    ) > 0.1
                    and
                    rate(node_disk_reads_completed_total{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[1m]) > 0
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostUnusualDiskReadLatency
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostUnusualDiskReadLatency
                type: reduce
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: HostUnusualDiskReadLatency
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: Disk latency is growing (write operations > 100ms)\n  VALUE = {{ $value }}
            summary: Host unusual disk write latency (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: d0964385-4a1e-4f0f-b501-6f3af98e2a6d
          title: HostUnusualDiskWriteLatency
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |
                    (
                      rate(node_disk_write_time_seconds_total{device!~"mmcblk.+", cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[1m])
                      /
                      rate(node_disk_writes_completed_total{device!~"mmcblk.+", cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[1m])
                    ) > 0.1
                    and
                    rate(node_disk_writes_completed_total{device!~"mmcblk.+", cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[1m]) > 0
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostUnusualDiskWriteLatency
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostUnusualDiskWriteLatency
                type: reduce
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: HostUnusualDiskWriteLatency
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: Disk latency is growing (read operations > 100ms)\n  VALUE = {{ $value }}
            summary: Host unusual disk read latency (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: c2138088-0464-4767-96e3-f88aa115ada8
          title: HostCpuStealNoisyNeighbor
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |-
                    avg by(instance) (
                      rate(node_cpu_seconds_total{mode="steal", cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[5m])
                    ) * 100
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostCpuStealNoisyNeighbor
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostCpuStealNoisyNeighbor
                type: reduce
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: HostCpuStealNoisyNeighbor
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: CPU steal is > 10%. A noisy neighbor is killing VM performances or a spot instance may be out of credit.\n  VALUE = {{ $value }}
            summary: Host CPU steal noisy neighbor (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: a221c628-3723-45ef-b326-0a16b025bf8a
          title: HostSystemdServiceCrashed
          condition: HostSystemdServiceCrashed
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: node_systemd_unit_state{state="failed", cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"} == 1
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostSystemdServiceCrashed
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: HostSystemdServiceCrashed
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: SystemD service crashed\n  VALUE = {{ $value }}
            summary: Host SystemD service crashed (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: d468afaf-966f-4a05-acad-b3db5ed799a3
          title: HostClockNotSynchronising
          condition: HostSystemdServiceCrashed
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |-
                    min_over_time(node_timex_sync_status{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[1m]) == 0
                    and
                    node_timex_maxerror_seconds{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"} >= 16
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostSystemdServiceCrashed
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: HostSystemdServiceCrashed
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: Clock not synchronising.\n  VALUE = {{ $value }}
            summary: Host clock not synchronising (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: d5b75013-412a-4a9a-91b4-409975bb2486
          title: HostClockSkew
          condition: HostClockSkew
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |-
                    (
                      (node_timex_offset_seconds{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"} > 0.05
                      and
                      deriv(node_timex_offset_seconds{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[5m]) >= 0
                      )
                      or
                      (
                        node_timex_offset_seconds{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"} < -0.05
                        and
                        deriv(node_timex_offset_seconds{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[5m]) <= 0
                      )
                      )
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostClockSkew
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostClockSkew
                settings:
                    mode: ""
                type: reduce
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: Clock skew detected. Clock is out of sync.\n  VALUE = {{ $value }}
            summary: Host clock skew (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: fc5e305b-52d4-4b9f-9172-1e30274910c9
          title: HostConntrackLimit
          condition: HostConntrackLimit
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |-
                    node_nf_conntrack_entries{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}
                    /
                    node_nf_conntrack_entries_limit{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostConntrackLimit
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0.8
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: HostConntrackLimit
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: The number of conntrack is approching limit\n  VALUE = {{ $value }}
            summary: Host conntrack limit (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: db80cdfc-1e88-4884-b89f-9bcda24ac719
          title: HostNetworkInterfaceSaturated
          condition: HostNetworkInterfaceSaturated
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |-
                    (
                      rate(node_network_receive_bytes_total{device!~"^tap.*", cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[1m])
                      +
                      rate(node_network_transmit_bytes_total{device!~"^tap.*", cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[1m])
                    )
                    /
                    node_network_speed_bytes{device!~"^tap.*", cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostNetworkInterfaceSaturated
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0.8
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: HostNetworkInterfaceSaturated
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: The network interface is getting overloaded.\n  VALUE = {{ $value }}
            summary: Host Network Interface Saturated (instance {{ $labels.instance }}:{{ $labels.interface }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: e7ddca31-72eb-40ed-a34e-8baae9c8b28c
          title: HostNetworkTransmitErrors
          condition: HostNetworkInterfaceSaturated
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |-
                    rate(node_network_transmit_errs_total{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[2m])
                    /
                    rate(node_network_transmit_packets_total{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[2m])
                    > 0.01
                    and
                    rate(node_network_transmit_packets_total{cluster=~"tahoe-prod-cluster02|tahoe-prod-cluster03",job="tahoe-prod-cluster02-node-exporter|tahoe-prod-cluster03-node-exporter",project="riq-poc"}[2m]) > 0
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostNetworkInterfaceSaturated
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0.8
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: HostNetworkInterfaceSaturated
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: Instance has encountered {{ printf "%.0f" $value }} transmit errors in the last five minutes.\n  VALUE = {{ $value }}
            summary: Host Network Transmit Errors (instance {{ $labels.instance }}:{{ $labels.device }})
          labels:
            metric: tahoe_events
          isPaused: false
    - orgId: 1
      name: Tahoe
      folder: RIQ-POC
      interval: 15m
      rules:
        - uid: f1e029a5-3742-4761-86e9-224644807012
          title: KubePodNotReady | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: sum by (namespace, pod) (kube_pod_status_phase{project="riq-poc",job="kube-state-metrics",pod!~".*job.*", phase=~"Pending|Unknown|Failed"}) > 0
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-running state for longer than 15 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Pod not healthy (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: f3d61d17-f185-46af-981e-f3cc6af4c917
          title: KubeContainerWaiting
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                disableTextWrap: false
                editorMode: code
                expr: kube_pod_container_status_waiting_reason{job="kube-state-metrics",namespace="prod",project="riq-poc"}
                fullMetaSearch: false
                includeNullMetadata: true
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
                useBackend: false
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Pod {{ $labels.namespace }}/{{ $labels.pod }} container {{ $labels.container }} has been in waiting state for longer than 1 hour.\n  VALUE = {{ $value }}"'
            summary: Pod {{ $labels.namespace }}/{{ $labels.pod }} container waiting longer than 1 hour
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: d73fb1dc-ad87-4b22-962d-ddcb1cf78a9b
          title: KubeDeploymentReplicasMismatch
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: "(\n  kube_deployment_spec_replicas{namespace=\"prod\",project=\"riq-poc\",job=\"kube-state-metrics\"} != \n  kube_deployment_status_replicas_available{namespace=\"prod\",project=\"riq-poc\",job=\"kube-state-metrics\"}\n)\nand \n(\n  changes(kube_deployment_status_replicas_updated{namespace=\"prod\",project=\"riq-poc\",job=\"kube-state-metrics\"}[10m]) == 0\n)\n"
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: Deployment {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.deployment {{`}}`}} has not matched the expected number of replicas for longer than 15 minutes.
            summary: Deployment has not matched the expected number of replicas.
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: aaf2dc2c-2ca5-45f6-9738-1922355dec4a
          title: KubernetesNodeNotReady | East
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_node_status_condition{cluster="tahoe-prod-cluster03",job="kube-state-metrics",project="riq_poc",condition="Ready",status="true"} == 0
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} has been unready for a long time\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node not ready (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: a5949b43-f67c-4f32-a82a-84ed056fd16d
          title: KubernetesNodeNotReady | West
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_node_status_condition{cluster="tahoe-prod-cluster02",job="kube-state-metrics",project="riq-poc",condition="Ready",status="true"} == 0
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} has been unready for a long time\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node not ready (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: cb9ac700-b125-4ccc-aa7d-17a073da9301
          title: KubernetesNodeMemoryPressure | East | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_node_status_condition{cluster="tahoe-prod-cluster03",job="kube-state-metrics",project="riq-poc",condition="MemoryPressure",status="true"} == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} has MemoryPressure condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node memory pressure (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: a86e0bea-451c-456f-993c-96bcbb90c918
          title: KubernetesNodeMemoryPressure | West | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_node_status_condition{cluster="tahoe-prod-cluster02",job="kube-state-metrics",project="riq-poc",condition="MemoryPressure",status="true"} == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} has MemoryPressure condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node memory pressure (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: b3219f9f-4427-4320-8aca-9ec36e7b6bc4
          title: KubernetesNodeDiskPressure | East | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_node_status_condition{cluster="tahoe-prod-cluster03",job="kube-state-metrics",project="riq-poc",condition="DiskPressure",status="true"} == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} has DiskPressure condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node disk pressure (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: d72e4c47-2a1f-4fdd-82fa-6016e702b7b8
          title: KubernetesNodeDiskPressure | West | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_node_status_condition{cluster="tahoe-prod-cluster02",job="kube-state-metrics",project="riq-poc",condition="DiskPressure",status="true"} == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} has DiskPressure condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node disk pressure (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: ddd4a04f-8b6c-4611-b009-fcd11f0fa0de
          title: KubernetesNodeNetworkUnavailable | East | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_node_status_condition{cluster="tahoe-prod-cluster03",job="kube-state-metrics",project="riq-poc",condition="NetworkUnavailable",status="true"}  == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} has NetworkUnavailable condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node network unavailable (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: d1370d84-b555-42ac-94c6-16e7fbbb7d2a
          title: KubernetesNodeNetworkUnavailable | West | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_node_status_condition{cluster="tahoe-prod-cluster02",job="kube-state-metrics",project="riq-poc",condition="NetworkUnavailable",status="true"}  == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} has NetworkUnavailable condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node network unavailable (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: aab658fb-0e27-4a30-9ac0-b7687e93e7a9
          title: KubernetesNodeOutOfPodCapacity | Warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: sum by (node) ((kube_pod_status_phase{project="riq-poc",phase="Running"} == 1) + on(uid) group_left(node) (0 * kube_pod_info{project="riq-poc",pod_template_hash=""})) / sum by (node) (kube_node_status_allocatable{project="riq-poc",resource="pods"}) * 100 > 90
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} is out of pod capacity\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node out of pod capacity (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: d9033652-28ff-4b1b-a06c-88c6287a4e42
          title: KubernetesContainerOomKiller | Warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: (kube_pod_container_status_restarts_total{project="riq-poc"} - kube_pod_container_status_restarts_total{project="riq-poc"} offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{project="riq-poc",reason="OOMKilled"}[10m]) == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Container oom killer (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: b57fc979-8a6a-4c05-8ee6-3b459e4e9bd3
          title: KubernetesJobFailed | Warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: (kube_job_status_failed{job="kube-state-metrics",namespace="prod",project="riq-poc"}) > 0
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Job failed (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: ada40075-ef7e-4dd3-badd-b60ba04c08c7
          title: KubernetesCronjobSuspended | Warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_cronjob_spec_suspend{job="kube-state-metrics", namespace="prod", project="riq-poc", cronjob!="reward-redeem-retry-producer-job"} != 0
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"CronJob {{ $labels.namespace }}/{{ $labels.cronjob }} is suspended\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes CronJob suspended (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: a4d85cc2-d001-4829-8450-06587e542a33
          title: KubernetesPersistentvolumeclaimPending | Warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_persistentvolumeclaim_status_phase{job="kube-state-metrics",phase="Pending",project="riq-poc"} == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes PersistentVolumeClaim pending (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: a1f74bc6-8fb7-4643-8bbb-7c81beedee18
          title: KubernetesStatefulsetDown | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: (kube_statefulset_replicas{job="kube-state-metrics", project="riq-poc"} != kube_statefulset_status_replicas_ready{job="kube-state-metrics", project="riq-poc"}) > 0
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} went down\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes StatefulSet down (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: e40df0f1-caf3-4170-83a6-56207d86d6be
          title: KubernetesHpaMetricsUnavailability | Warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_horizontalpodautoscaler_status_condition{job="kube-state-metrics",project="riq-poc" ,status="false", condition="ScalingActive"} == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler }} is unable to collect metrics\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes HPA metrics unavailability (instance {{ $labels.instance }})
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: ec460d9d-1a11-4068-9450-7df001477244
          title: PodEvictionAlert | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_pod_status_reason{cluster=~"tahoe-prod-cluster03|tahoe-prod-cluster02",job="kube-state-metrics",namespace="prod",project="riq-poc",reason="Evicted"} >0
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: PodEviction
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: PodEviction
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: PodEviction
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Pod {{ $labels.namespace }}/{{ $labels.pod }} was evicted."'
            summary: '"Pod Evicted"'
          labels:
            metric: tahoe_events
          isPaused: false
        - uid: f547be4c-52d3-4d60-a585-8bd8fb9b3e7a
          title: KubeCronJobPodNotReady | Critical
          condition: Threshold
          data:
            - refId: KubeCronJobPodNotReady
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: (sum by (namespace)(kube_pod_status_phase{project="riq-poc",job="kube-state-metrics",pod=~".*job.*", phase=~"Pending|Unknown|Failed"})-sum by (namespace)(kube_pod_status_phase{project="riq-poc",job="kube-state-metrics",pod=~".*job.*", phase=~"Pending|Unknown|Failed"}offset 10m)) > 0
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: KubeCronJobPodNotReady
            - refId: Last Value
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: KubeCronJobPodNotReady
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: Last Value
                type: reduce
            - refId: Threshold
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: Last Value
                intervalMs: 1000
                maxDataPoints: 43200
                refId: Threshold
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"CronJob Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-running state for longer than 15 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: |-
                Kubernetes CronJob Pod not healthy (instance {{ $labels.instance }})
                Check the related Job and assure if the next execution of pod got successful, notify related team on failed instance for analysis purpose.

                if it's repeated failure on next pods as well, check of error and involve respective team.
          labels:
            metric: tahoe_events
          isPaused: false
    - orgId: 1
      name: CPA
      folder: CPA-CampaignBuilder
      interval: 1m
      rules:
        - uid: cb19027f-0797-4c9b-aad8-e02ccd364201
          title: Campaign_BE | Exceptions in cpa-campaign-builder-api | west | Prod | P3
          condition: B
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: sum(count_over_time({app="cpa-campaign-builder-api",namespace="prod",project="qt-bizsys-prod",source_type="kubernetes_logs"} |~ "exception|error"[1m]))
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 3
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: max
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            description: Exception Observed in logs for cpa-campaign-builder-api service application logs.
            summary: Exception Observed in logs for cpa-campaign-builder-api service application logs.
          labels:
            metric: CPA-CB
            severity: Critical
          isPaused: false
        - uid: c35e784d-a0cc-43c1-a6dd-3dc2609953b0
          title: Campaign_FE| High number of HTTP 5xx errors in quotient-campaign-builder-web | west | Prod |P1
          condition: B
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: count_over_time({project="qt-bizsys-prod", namespace="prod", app="quotient-campaign-builder-web", source_type="ingress_logs"} | json | httpRequest_status=`500`[1m])
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: sum
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            description: High rate of 5xx status codes > 5 in last 5 mins
            summary: The rate of 5xx status codes on the quotient-campaign-builder-web is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
          labels:
            metric: CPA-CB
            severity: Critical
          isPaused: false
        - uid: d57760d8-1eef-4716-97c2-7a6bb686b34b
          title: Campaign_FE | Exceptions in quotient-campaign-builder-web | west | Prod | P3
          condition: B
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: sum(count_over_time({app="quotient-campaign-builder-web", project="qt-bizsys-prod", source_type="kubernetes_logs"} | json !~ "health-check" | level=`error` | err_message!~`Jwt is expired`[1m]))
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 3
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: max
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            description: Exception Observed in logs for quotient-campaign-builder-web.
            summary: Exception Observed in logs for quotient-campaign-builder-web.
          labels:
            metric: CPA-CB
            severity: Critical
          isPaused: false
    - orgId: 1
      name: Batch Jobs
      folder: Optimus
      interval: 2m
      rules:
        - uid: f250be56-e05c-4e20-becd-98d616bf5f25
          title: FIC | POD Health Checks failed | East | Prod | P2
          condition: A
          data:
            - refId: A
              queryType: instant
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: count(count_over_time({app="platform-file-ingestion-cooridinator",namespace="prod",region="us-east4",project="prj-promoplat-p",source_type="ingress_logs"} | json | message_httpRequest_status!=`200` |message_jsonPayload_statusDetails!="client_disconnected_before_any_response" | message_httpRequest_status!~ "4[0-9][0-9]" |~"/ingestion-coordinator/actuator/health"[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: instant
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: sum
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: this query helps monitor and quantify instances where the health check for the FIC application fails, based on non-200 HTTP responses in the specified endpoint.
            summary: this query helps monitor and quantify instances where the health check for the FIC application fails, based on non-200 HTTP responses in the specified endpoint.
          labels:
            application: FIC
            metric: optimus
          isPaused: false
        - uid: be9e6544-daa0-4c78-973b-b9a2e3572122
          title: FIC | Exceptions | East | Prod | P3
          condition: C
          data:
            - refId: log_metrics_galo_Exception
              queryType: instant
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: sum(count_over_time({app="platform-file-ingestion-coordinator",cluster=~"gke-gke-riq-uswst.+-prod-active",project="prj-promoplat-p", namespace="prod"}|~".*Exception.*"[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: instant
                refId: log_metrics_galo_Exception
            - refId: log_metrics_FIC_Exception_Status
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_galo_Exception
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: log_metrics_FIC_Exception_Status
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_FIC_Exception_Status
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            description: Exception Observed in logs for file-ingestion-coordinator Service.
            summary: Exception Observed in logs for file-ingestion-cooridnator Service.
          isPaused: false
        - uid: f4018e71-cac2-4b08-810e-8af50906b730
          title: platform-file-ingestion-coordinator | No Ingestion Mapping Found | P1
          condition: C
          data:
            - refId: A
              queryType: instant
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: 'sum(count_over_time({app="platform-file-ingestion-coordinator",namespace="prod",project="prj-promoplat-p",source_type="kubernetes_logs"} |~ "no ingestion mapping found for : FileIngestionNotification"[$__range]))'
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: instant
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: 'no ingestion mapping found for : FileIngestionNotification'
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/14779645953/File+ingestion+co-ordinator#1.-No-Ingestion-Mapping-Found---P1
            summary: "Check if the file is a valid file or not (for now we are inserting avro and parquet files only). \n\nCheck in file_ingestion_mapping if we have any mapping which matches above filePath\n\nIf mapping is not present and still want to ingest the file , please add the relavent mapping and re-drop the file"
          labels:
            metric: optimus
          isPaused: false
        - uid: b9cd9b04-240f-471c-ae7a-4e9a871cb3bf
          title: 'platform-file-ingestion-coordinator | More than one mapping found | P1 '
          condition: C
          data:
            - refId: A
              queryType: instant
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: sum(count_over_time({app="platform-file-ingestion-coordinator",namespace="prod",project="prj-promoplat-p",source_type="kubernetes_logs"} |~ "more than one ingestion mapping found"[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: instant
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: '"more than one ingestion mapping found for : {} matched mapping : {}", fileIngestionNotification, matchedRegex'
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/14779645953/File+ingestion+co-ordinator#2.-More-than-one-mapping-found---P1
            summary: "If you see the above error , then there are more that one mappings in file_ingestion_mapping collection . File ingestion coordinator cant determine where to ingest the file. \n\nPlease make sure only one mappings is present for a given filePath as we don't support writing to more that one data source"
          labels:
            metric: optimus
          isPaused: false
        - uid: b48569fa-d17c-4829-a644-dc1b690c630f
          title: platform-file-ingestion-coordinator | Failed to get job status | P2
          condition: C
          data:
            - refId: A
              queryType: instant
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: sum(count_over_time({app="platform-file-ingestion-coordinator",namespace="prod",project="prj-promoplat-p",source_type="kubernetes_logs"} |~ "Failed to get the the job status for"[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: instant
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: log.error("Failed to get the the job status for {}", job.getId());
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/14779645953/File+ingestion+co-ordinator#3.-Failed-to-get-job-status---P2%5BhardBreak%5D
            summary: "log.error(\"Failed to get the the job status for {}\", job.getId());\nCheck if the job id is valid \n\nGo to file_ingestion_status and search with the current jobId and get the batchJobUrl"
          labels:
            metric: optimus
          isPaused: false
        - uid: bbaa8b6d-3061-431f-966d-1a663f85a869
          title: platform-file-ingestion-coordinator | Failed to trigger the job  | P2
          condition: C
          data:
            - refId: A
              queryType: instant
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: sum(count_over_time({app="platform-file-ingestion-coordinator",namespace="prod",project="prj-promoplat-p",source_type="kubernetes_logs"} |~ "Failed to trigger the job"[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: instant
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: Failed to trigger the job , ex = {}", ExceptionUtils.getStackTrace(ex));
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/14779645953/File+ingestion+co-ordinator#4.-Failed-to-trigger-the-job---P2
            summary: "This can happen due to the unavaliabilty of writer service \n\nThis also can happen if we  haven’t configured all required attributes under parameters in the respective mapping inside file_ingestion_mapping collection"
          labels:
            metric: optimus
          isPaused: false
        - uid: a8e6408a-6cd9-4963-80e4-c75245074e32
          title: platform-file-ingestion-coordinator | No DBSink Present | P2
          condition: C
          data:
            - refId: A
              queryType: instant
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: sum(count_over_time({app="platform-file-ingestion-coordinator",namespace="prod",project="prj-promoplat-p",source_type="kubernetes_logs"} |~ "No DBSink present with id"[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: instant
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: log.error("No DBSink present with id  {}", fileIngestion.getDataSink().getName());
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/14779645953/File+ingestion+co-ordinator#5.-No-DBSink-Present---P2
            summary: "This can happen if the current mapping doesnt have a valid data sink \n\nSee if destination is defined in the mapping or not \n\nIf defined , verify if it is present in destination_datastore collection"
          labels:
            metric: optimus
          isPaused: false
    - orgId: 1
      name: Error Exceptions
      folder: Optimus
      interval: 5m
      rules:
        - uid: ae3bbf8e-5f67-4e99-9149-7dd5ecef59ad
          title: LogErrors-East
          condition: A
          data:
            - refId: A
              queryType: instant
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: 'sum by(app) (rate({cluster="gke-gke-riq-usest4-prod-active"} |~ `(?i)Error` !~ `errorCode: 4` [5m])) + sum by(app) (rate({cluster="gke-gke-riq-usest4-prod-active"} |~ `(?i)Exception` !~ `errorCode: 4` [5m])) + sum by(app) (rate({cluster="gke-gke-riq-usest4-prod-active"} |~ `(?i)fail` !~ `errorCode: 4` [5m]))'
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: instant
                refId: A
          noDataState: OK
          execErrState: Error
          for: 10m
          annotations:
            summary: Error/exception log rate found in East cluster by app name
          labels:
            optimus: Exceptions
          isPaused: false
        - uid: c8a66a10-1320-4713-bea5-0722a1a63dde
          title: LogErrors-West
          condition: A
          data:
            - refId: A
              queryType: instant
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: 'sum by(app) (rate({cluster="gke-gke-riq-uswst1-prod-active"} |~ `(?i)Error` !~ `errorCode: 4` [5m])) + sum by(app) (rate({cluster="gke-gke-riq-uswst1-prod-active"} |~ `(?i)Exception` !~ `errorCode: 4` [5m])) + sum by(app) (rate({cluster="gke-gke-riq-uswst1-prod-active"} |~ `(?i)fail` !~ `errorCode: 4` [5m]))'
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: instant
                refId: A
          noDataState: OK
          execErrState: Error
          for: 10m
          annotations:
            summary: Error/exception log rate found in West cluster by app name
          labels:
            optimus: Exceptions
          isPaused: false
    - orgId: 1
      name: GALO
      folder: Optimus
      interval: 1m
      rules:
        - uid: 8ph0aiBVk
          title: Galo | Exceptions | west | Prod | P3
          condition: A
          data:
            - refId: log_metrics_galo_Exception
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: sum(count_over_time({app="get-all-offers-ns",cluster=~"gke-gke-riq-uswst.+-prod-active",project="prj-promoplat-p", namespace="prod"} |~".*Exception.*" | __error__=`` [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: log_metrics_galo_Exception
                step: 5m
            - refId: log_metrics_galo_Exception_Status
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_galo_Exception
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: log_metrics_galo_Exception_Status
                type: reduce
            - refId: A
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_galo_Exception_Status
                intervalMs: 1000
                maxDataPoints: 43200
                refId: A
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 5
          noDataState: OK
          execErrState: OK
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "5"
            Grafana Query: https://grafana.corp.quotient.com/goto/57iRXvwSg?orgId=1
            description: Exception Observed in logs for get-all-offers-ns Service.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: Exception Observed in logs for get-all-offers-ns Service.
          labels:
            metric: optimus
          isPaused: false
        - uid: c0230053-8c1d-4bdc-82bb-e400c984c643
          title: Galo | Exceptions | east | Prod | P3
          condition: A
          data:
            - refId: log_metrics_galo_Exception
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: sum(count_over_time({app="get-all-offers-ns",cluster=~"gke-gke-riq-usest.+-prod-active",project="prj-promoplat-p", namespace="prod"} |~".*Exception.*" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: log_metrics_galo_Exception
            - refId: log_metrics_galo_Exception_Status
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_galo_Exception
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: log_metrics_galo_Exception_Status
                type: reduce
            - refId: A
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_galo_Exception_Status
                intervalMs: 1000
                maxDataPoints: 43200
                refId: A
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 5
          noDataState: OK
          execErrState: OK
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "5"
            Grafana Query: https://grafana.corp.quotient.com/goto/6d4cuvQIg?orgId=1
            description: Exception Observed in logs for get-all-offers-ns Service.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: Exception Observed in logs for get-all-offers-ns Service.
          labels:
            metric: optimus
          isPaused: false
        - uid: cJuubq8Vz
          title: Galo | High number of HTTP 4xx errors  | west | Prod | P3
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-all-offers-ns",namespace="prod",project="prj-promoplat-p",region=~"us-west.+",source_type="ingress_logs"} | json | message_httpRequest_status =~ "4[0-9][0-9]" | message_httpRequest_requestUrl !~ ".*health.*" | __error__=``[5m]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: 5m
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 28
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "28"
            Grafana Query: https://grafana.corp.quotient.com/goto/gN8QjvQIg?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the client request or the API endpoint itself. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes
          labels:
            metric: optimus
          isPaused: false
        - uid: ee05c436-0ddb-4e41-becb-b9a13499ac53
          title: 'Galo | High number of HTTP 4xx errors  | east | Prod | P3 '
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-all-offers-ns",namespace="prod",project="prj-promoplat-p",region=~"us-east.+",source_type="ingress_logs"} | json | message_httpRequest_status =~ "4[0-9][0-9]" | message_httpRequest_requestUrl !~ ".*health.*" | __error__=``[5m]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: ""
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 28
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "28"
            Grafana Query: https://grafana.corp.quotient.com/goto/B_VF6QuIg?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the client request or the API endpoint itself. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes
          labels:
            application: PAO
            metric: optimus
          isPaused: false
        - uid: NS2QY384z
          title: Galo | High number of HTTP 5xx errors  | west | Prod | P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-all-offers-ns",namespace="prod",project="prj-promoplat-p",region=~"us-west.+",source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ ".*health.*" | __error__=``[$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 27
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "27"
            Grafana Query: https://grafana.corp.quotient.com/goto/sWzmqDwSg?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: GALO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: db01a27a-45b8-438a-a24f-a2988ae1cb60
          title: 'Galo | High Latency Requests | east | Prod | P2 '
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({project="prj-promoplat-p", namespace="prod", app="get-all-offers-ns", region=~"us-east.+", source_type="kubernetes_logs"} |= `http_response_time=` |= `vr=1.0` != `oauth_internal=yes` != `warmup_service` != `GALO_HYDRATOR` != `user-agent=Postman` != `user-agent=curl` | pattern `nonce=<nonce> client_ip=<client_ip> - <datetime> <_> - /<endpoint>/<_> partnerId=<partnerId> <_> http_response_time=<latency>ms http_commit_response_time=<committime>ms` | latency > 1000 | __error__=``[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 26
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "26"
            Query: https://grafana.corp.quotient.com/goto/OQTGqDwIg?orgId=1
            description: This alert is triggered when the latency of 5 requests to the get-all-offers-ns service in the East Prod environment exceeds the threshold of 1 second.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High latency was observed in get-all-offers-ns service (> 1 second )  requests in the Optimus-East environment.
          labels:
            metric: optimus
          isPaused: false
        - uid: b25878b4-63cc-49ac-b9f6-eedc018950ea
          title: Galo | POD Health Checks failed | West|  Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-all-offers-ns",namespace="prod",region="us-west1",project="prj-promoplat-p",source_type="ingress_logs"} | json | message_httpRequest_status!=`200` | message_jsonPayload_statusDetails!="client_disconnected_before_any_response" | message_httpRequest_status!~ "4[0-9][0-9]" |~"/galo/actuator/health" | __error__=``[$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: sum
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 2
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: OK
          for: 2m
          annotations:
            Query: https://grafana.corp.quotient.com/goto/2wVcqvQSR?orgId=1
            description: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
          labels:
            metric: optimus
          isPaused: false
        - uid: a309ef1f-8a97-45b4-9f4a-d6a7b9056cc8
          title: Galo | POD Health Checks failed | East |  Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-all-offers-ns",namespace="prod",region="us-east4",project="prj-promoplat-p",source_type="ingress_logs"} | json | message_httpRequest_status!=`200` | message_jsonPayload_statusDetails!="client_disconnected_before_any_response" | message_httpRequest_status!~ "4[0-9][0-9]" |~"/galo/actuator/health" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: sum
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 2
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: OK
          for: 2m
          annotations:
            Query: https://grafana.corp.quotient.com/goto/EIKlc_XSg?orgId=1
            description: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
          labels:
            application: PAO
            metric: optimus
          isPaused: false
        - uid: dfeb6bd9-7a24-408e-883d-cac1f48ae747
          title: Galo | DB Fetch Time Exceeds 1 Seconds | East | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-all-offers-ns",namespace="prod",project="prj-promoplat-p",region="us-east4",source_type="kubernetes_logs"} |= `db_fetch_time` | pattern `<nonce> - <datetime> <_> - OfferDetails cache lookup stats for partnerId=<partnerId>. fetch_time=<fetch_time>, request_count=<request_count>, cache_hit_count=<cache_hit_count>, db_fetch_count=<db_fetch_count>, db_fetch_time=<db_fetch_time>, cache_get_count=<cache_get_count>, cache_get_time=<cache_get_time>, cache_put_count=<cache_put_count>, cache_put_time=<cache_put_time>, by_pass_cache=<by_pass_cache>` | db_fetch_time > 1000 !~ "GALO_HYDRATOR" | __error__=``[$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            description: Database fetch time is over 1 second, indicating a performance issue
            summary: Database fetch time is over 1 second, indicating a performance issue
          labels:
            application: GALO
            metric: optimus
          isPaused: false
        - uid: e29a10b9-3472-4bf7-9b33-c0e9ca916689
          title: Galo | DB Fetch Time Exceeds 1 Seconds | West | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-all-offers-ns",namespace="prod",project="prj-promoplat-p",region="us-west1",source_type="kubernetes_logs"} |= `db_fetch_time` | pattern `<nonce> - <datetime> <_> - OfferDetails cache lookup stats for partnerId=<partnerId>. fetch_time=<fetch_time>, request_count=<request_count>, cache_hit_count=<cache_hit_count>, db_fetch_count=<db_fetch_count>, db_fetch_time=<db_fetch_time>, cache_get_count=<cache_get_count>, cache_get_time=<cache_get_time>, cache_put_count=<cache_put_count>, cache_put_time=<cache_put_time>, by_pass_cache=<by_pass_cache>` | db_fetch_time > 1000 !~ "GALO_HYDRATOR"[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: 5m
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            description: Database fetch time is over 1 second, indicating a performance issue
            summary: Database fetch time is over 1 second, indicating a performance issue
          labels:
            application: GALO
            metric: optimus
          isPaused: false
        - uid: b599881b-93cb-44d8-908d-82695748d294
          title: Galo | High number of HTTP 5xx errors  | east | Prod | P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-all-offers-ns",namespace="prod",project="prj-promoplat-p",region=~"us-east.+",source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ ".*health.*" | __error__=``[$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 27
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "27"
            Grafana Query: https://grafana.corp.quotient.com/goto/Pr8uxluIg?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: GALO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: e6f03ec5-ad2d-477c-8456-ff4ee5bc3d3d
          title: Galo | High Latency Requests | west | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({project="prj-promoplat-p", namespace="prod", app="get-all-offers-ns", region=~"us-west.+", source_type="kubernetes_logs"} |= `http_response_time=` |= `vr=1.0` != `oauth_internal=yes` != `GALO_HYDRATOR` != `warmup_service` != `user-agent=curl` != `user-agent=Postman` | pattern `nonce=<nonce> client_ip=<client_ip> - <datetime> <_> - /<endpoint>/<_> partnerId=<partnerId> <_> http_response_time=<latency>ms http_commit_response_time=<committime>ms` | latency > 1000 | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: 5m
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 26
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "26"
            Query: https://grafana.corp.quotient.com/goto/RFEpb_uSR?orgId=1
            description: This alert is triggered when the latency of 5 requests to the get-all-offers-ns service in the WEST Prod environment exceeds the threshold of 1 seconds.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High latency was observed in get-all-offers-ns service (> 1 second )  requests in the Optimus-West environment.
          labels:
            metric: optimus
          isPaused: false
    - orgId: 1
      name: GAO
      folder: Optimus
      interval: 1m
      rules:
        - uid: c9f4b7b4-9d4a-4d7a-89ff-519179feb8c2
          title: GAO | Exceptions | west| Prod | P3
          condition: B
          data:
            - refId: log_metrics_gro_Exception
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: |-
                    sum(count_over_time(
                      {app="get-activated-offers-ns", namespace="prod", project="prj-promoplat-p", source_type="kubernetes_logs", region=~"us-west.+"}
                      |~ "(?P<identifier>[^ ]+) - (?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}) \\[(?P<thread>[^\\]]+)\\] (?P<level>\\w+)"
                      |~ ".*Exception.*"
                      !~"Input Validation Failed"
                      | __error__=``
                      [$__range]
                    ))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: log_metrics_gro_Exception
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_gro_Exception
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: A
                type: reduce
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 8
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "8"
            Grafana Query: https://grafana.corp.quotient.com/goto/vdxozdwSR?orgId=1
            description: |-
                Exception Observed in logs for get-activated-offers-ns Service greater than 1

                Logs: https://cloudlogging.app.goo.gl/9caeai94RzUNds4j8
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: GAO | Exception Observed in logs for get-activated-offers-ns Service greater than 1
          labels:
            application: GAO
            metric: optimus
          isPaused: false
        - uid: b266d2e1-617a-411b-8627-065a02e177c1
          title: GAO | Exceptions | east | Prod | P3
          condition: B
          data:
            - refId: log_metrics_gro_Exception
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: |-
                    sum(count_over_time(
                      {app="get-activated-offers-ns", namespace="prod", project="prj-promoplat-p", source_type="kubernetes_logs", region=~"us-east.+"}
                      |~ "(?P<identifier>[^ ]+) - (?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}) \\[(?P<thread>[^\\]]+)\\] (?P<level>\\w+)"
                      |~ ".*Exception.*"
                      !~"Input Validation Failed"
                      | __error__=``
                      [$__range]
                    ))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: log_metrics_gro_Exception
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_gro_Exception
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: A
                type: reduce
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 8
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "8"
            Grafana Query: https://grafana.corp.quotient.com/goto/GpBjWdwIg?orgId=1
            description: |-
                Exception Observed in logs for get-activated-offers-ns Service greater than 1

                Logs: https://cloudlogging.app.goo.gl/9caeai94RzUNds4j8
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: GRO | Exception Observed in logs for get-activated-offers-ns Service greater than 1
          labels:
            application: GAO
            metric: optimus
          isPaused: false
        - uid: b40b305c-fd57-4a89-8c1f-2c97da59c9db
          title: GAO | High number of HTTP 5xx errors  | west | Prod |P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-activated-offers-ns",project="prj-promoplat-p",region=~"us-west.+",source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ ".*health.*" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 27
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "27"
            Grafana Query: https://grafana.corp.quotient.com/goto/w81p3DQSg?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: GAO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: da42320e-9d6a-48c5-a930-ebf4e50e4852
          title: GAO | High number of HTTP 5xx errors  | east | Prod | P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-activated-offers-ns",project="prj-promoplat-p",region=~"us-east.+",source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ ".*health.*" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: 5m
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 27
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "27"
            Grafana Query: https://grafana.corp.quotient.com/goto/-jjWkdwIg?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: GAO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: b156c097-4add-400e-8937-aeefb1427dbf
          title: GAO | High p90 Response Times | east | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: |-
                    quantile_over_time(0.90,
                    {app="get-activated-offers-ns", namespace="prod", project="prj-promoplat-p", region=~"us-east.+", source_type="kubernetes_logs"}|= `http_response_time` != `oauth_internal=yes` != `warmup_service` != `user-agent=curl` != `user-agent=Postman`| pattern `nonce=<nonce> client_ip=<client_ip> - <datetime> <_> - /<endpoint>/<_> partnerId=<partnerId> <_> http_response_time=<latency>ms http_commit_response_time=<committime>ms` | unwrap latency  | __error__="" [5m]) by (app)
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1000
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 21
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "21"
            Query: https://grafana.corp.quotient.com/goto/yVW1C2wSg?orgId=1
            description: The 90th percentile response time for the application `get-activated-offers-ns` in the `east` namespace has exceeded 1000ms. This indicates that 90% of the requests took longer than 1000ms over the past 5 minutes.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: The 90th percentile response time for the `get-activated-offers-ns` app in the `east` namespace has exceeded 1000ms.
          labels:
            application: GAO
            metric: optimus
          isPaused: false
        - uid: fb4a320f-6f28-42fa-a8ae-625d3b95b160
          title: GAO | High p90 Response Times | west | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: |-
                    quantile_over_time(0.90,
                    {app="get-activated-offers-ns", namespace="prod", project="prj-promoplat-p", region=~"us-west.+", source_type="kubernetes_logs"}|= `http_response_time` != `oauth_internal=yes` != `warmup_service` != `user-agent=curl` != `user-agent=Postman`| pattern `nonce=<nonce> client_ip=<client_ip> - <datetime> <_> - /<endpoint>/<_> partnerId=<partnerId> <_> http_response_time=<latency>ms http_commit_response_time=<committime>ms` | unwrap latency  | __error__="" [5m]) by (app)
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: p90Latency
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: p90Latency
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1000
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: p90Latency
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 21
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "21"
            Grafana Query: https://grafana.corp.quotient.com/goto/HoKGVQQSg?orgId=1
            description: The 90th percentile response time for the application `get-activated-offers-ns` in the `west` namespace has exceeded 1000ms. This indicates that 90% of the requests took longer than 1000ms over the past 5 minutes.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: The 90th percentile response time for the `get-activated-offers-ns` app in the `west` namespace has exceeded 1000ms.
          labels:
            application: GAO
            metric: optimus
          isPaused: false
        - uid: f89bdac3-fbfa-4309-a022-412cc20d21e1
          title: GAO | High number of HTTP 4xx errors  | west | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-activated-offers-ns",project="prj-promoplat-p",region=~"us-west.+",source_type="ingress_logs"} | json | message_httpRequest_status =~ "4[0-9][0-9]"  | message_httpRequest_requestUrl !~ ".*health.*" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: 5m
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 28
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "28"
            Grafana Query: https://grafana.corp.quotient.com/goto/6ynYWOQSg?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes > 5 in last 5 mins
          labels:
            application: GAO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: d55f8359-60a4-4541-b745-502ca1367a7b
          title: GAO | High number of HTTP 4xx errors  | east | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-activated-offers-ns",project="prj-promoplat-p",region=~"us-east.+",source_type="ingress_logs"} | json | message_httpRequest_status =~ "4[0-9][0-9]"  | message_httpRequest_requestUrl !~ ".*health.*" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: 5m
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 28
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "28"
            Grafana Query: https://grafana.corp.quotient.com/goto/mjeyWOwIR?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes > 5 in last 5 mins
          labels:
            application: GAO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: d77ed554-e859-44a9-89e4-68fa26197040
          title: GAO | POD Health Checks failed | East | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-activated-offers-ns",namespace="prod",region="us-east4",project="prj-promoplat-p",source_type="ingress_logs"} | json | message_httpRequest_status!=`200` |message_jsonPayload_statusDetails!="client_disconnected_before_any_response" | message_httpRequest_status!~ "4[0-9][0-9]" |~"/gro/actuator/health" | __error__=`` [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: sum
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 2
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: OK
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/QPVgMOQSg?orgId=1
            description: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
          labels:
            application: GAO
            metric: optimus
          isPaused: false
        - uid: f1c691c6-3b0b-4a7e-b707-b1b6aa6cc6af
          title: GAO | POD Health Checks failed | West | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-activated-offers-ns",namespace="prod",region="us-west1",project="prj-promoplat-p",source_type="ingress_logs"} | json | message_httpRequest_status!=`200` |message_jsonPayload_statusDetails!="client_disconnected_before_any_response" | message_httpRequest_status!~ "4[0-9][0-9]" |~"/gro/actuator/health" | __error__=`` [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: sum
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 2
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: OK
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/D6tmGOwSg?orgId=1
            description: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
          labels:
            application: GAO
            metric: optimus
          isPaused: false
        - uid: a206cda7-cb2f-48d5-bf9f-c4816180c6cd
          title: GAO | DB Fetch Time Exceeds 1 Seconds | West | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-activated-offers-ns",namespace="prod",project="prj-promoplat-p",region="us-west1",source_type="kubernetes_logs"} |= `db_fetch_time` | pattern `<nonce> - <datetime> <_> - OfferDetails cache lookup stats for partnerId=<partnerId>. fetch_time=<fetch_time>, request_count=<request_count>, cache_hit_count=<cache_hit_count>, db_fetch_count=<db_fetch_count>, db_fetch_time=<db_fetch_time>, cache_get_count=<cache_get_count>, cache_get_time=<cache_get_time>, cache_put_count=<cache_put_count>, cache_put_time=<cache_put_time>, by_pass_cache=<by_pass_cache>` | db_fetch_time > 1000 !~ "GALO_HYDRATOR" | __error__=`` [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/dmJMGdQSR?orgId=1
            description: Database fetch time is over 1 second, indicating a performance issue
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: Database fetch time is over 1 second, indicating a performance issue
          labels:
            application: GAO
            metric: optimus
          isPaused: false
        - uid: fe5df9bf-0d78-49c0-9906-da1bdb66aefc
          title: GAO | DB Fetch Time Exceeds 1 Seconds | East | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-activated-offers-ns",namespace="prod",project="prj-promoplat-p",region="us-east4",source_type="kubernetes_logs"} |= `db_fetch_time` | pattern `<nonce> - <datetime> <_> - OfferDetails cache lookup stats for partnerId=<partnerId>. fetch_time=<fetch_time>, request_count=<request_count>, cache_hit_count=<cache_hit_count>, db_fetch_count=<db_fetch_count>, db_fetch_time=<db_fetch_time>, cache_get_count=<cache_get_count>, cache_get_time=<cache_get_time>, cache_put_count=<cache_put_count>, cache_put_time=<cache_put_time>, by_pass_cache=<by_pass_cache>` | db_fetch_time > 1000 !~ "GALO_HYDRATOR" | __error__=`` [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/DIxnMOQIR?orgId=1
            description: Database fetch time is over 1 second, indicating a performance issue
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: Database fetch time is over 1 second, indicating a performance issue
          labels:
            application: GAO
            metric: optimus
          isPaused: false
    - orgId: 1
      name: GOD
      folder: Optimus
      interval: 1m
      rules:
        - uid: dbe23978-4819-46a9-8536-9a1e175d3cf9
          title: GOD | High number of HTTP 4xx errors  | east | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-offer-details-ns",project="prj-promoplat-p",region=~"us-east.+",source_type="ingress_logs"} | json | message_httpRequest_status =~ "4[0-9][0-9]"  | message_httpRequest_requestUrl !~ ".*health.*" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 17
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "17"
            Grafana Query: https://grafana.corp.quotient.com/goto/XSTc7OwSg?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes > 5 in last 5 mins
          labels:
            application: get-offer-details
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: a7660f1d-110c-4144-bee9-14dd0f00f319
          title: God (get-offer-details) | Exceptions | east | Prod | P3
          condition: B
          data:
            - refId: log_metrics_god_Exception
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-offer-details-ns",namespace="prod",project="prj-promoplat-p",source_type="kubernetes_logs",region=~"us-east.+"}|~".*Exception.*" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: log_metrics_god_Exception
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_god_Exception
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: A
                type: reduce
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 8
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "8"
            Grafana Query: https://grafana.corp.quotient.com/goto/mgnqndQIg?orgId=1
            description: |-
                Exception Observed in logs for get-offer-details-ns Service greater than 1

                Logs: https://cloudlogging.app.goo.gl/9caeai94RzUNds4j8
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: GOD | Exception Observed in logs for get-offer-details-ns Service greater than 1
          labels:
            application: get-offer-details
            metric: optimus
          isPaused: false
        - uid: aeadf6bc-296b-4847-ae33-0b0d096453b1
          title: God (get-offer-details) | Exceptions | west | Prod | P3
          condition: B
          data:
            - refId: log_metrics_god_Exception
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-offer-details-ns", project="prj-promoplat-p",region=~"us-west.+", source_type="kubernetes_logs", namespace="prod"}|~".*Exception.*" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: log_metrics_god_Exception
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_god_Exception
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: A
                type: reduce
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 8
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "8"
            Grafana Query: https://grafana.corp.quotient.com/goto/iC9EVOQIg?orgId=1
            description: |-
                Exception Observed in logs for get-offer-details-ns Service.

                Logs: https://cloudlogging.app.goo.gl/9caeai94RzUNds4j8
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: Exception Observed in logs for get-offer-details-ns Service.
          labels:
            application: get-offer-details
            metric: optimus
          isPaused: false
        - uid: f12b1a2c-0f78-4288-ae9a-0c2cb24dceaa
          title: GOD | POD Health Checks failed | West | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-offer-details-ns",namespace="prod",region="us-west1",project="prj-promoplat-p",source_type="ingress_logs"} | json | message_httpRequest_status!=`200` |message_jsonPayload_statusDetails!="client_disconnected_before_any_response" | message_httpRequest_status!~ "4[0-9][0-9]" |~"/gro/actuator/health" | __error__=`` [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: sum
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 2
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: OK
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/TCmqVdQIg?orgId=1
            description: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
          labels:
            application: GOD
            metric: optimus
          isPaused: false
        - uid: c1c6b202-9ba6-4eea-9711-5f99fd356fbe
          title: God | High Latency Requests | west | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-offer-details-ns",namespace="prod",project="prj-promoplat-p",region=~"us-west.+",source_type="kubernetes_logs"} |= `http_response_time` != `oauth_internal=yes` != `GALO_HYDRATOR` != `warmup_service` != `user-agent=curl` != `user-agent=Postman` | pattern `nonce=<nonce> client_ip=<client_ip> - <datetime> <_> - /<endpoint>/<_> partnerId=<partnerId> <_> http_response_time=<latency>ms http_commit_response_time=<committime>ms`  | latency > 1000 | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/30OCIOwSg?orgId=1
            description: This alert is triggered when the latency of 5 requests to the get-offer-details service in the WEST Prod environment exceeds the threshold of 1 second.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High latency was observed in get-offer-details service (> 1 second )  requests in the Optimus-West environment.
          labels:
            application: get-offer-details
            metric: optimus
          isPaused: false
        - uid: fdb75aa1-117c-43ca-a558-aca132b7296d
          title: God | High Latency Requests | east | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-offer-details-ns",namespace="prod",project="prj-promoplat-p",region="us-east4",source_type="kubernetes_logs"} |= `http_response_time` != `oauth_internal=yes` != `GALO_HYDRATOR` != `warmup_service` != `user-agent=curl` != `user-agent=Postman` | pattern `nonce=<nonce> client_ip=<client_ip> - <datetime> <_> - /<endpoint>/<_> partnerId=<partnerId> <_> http_response_time=<latency>ms http_commit_response_time=<committime>ms`  | latency > 1000 | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/z2DBtOQSR?orgId=1
            description: This alert is triggered when the latency of 5 requests to the get-offer-details service in the EAST Prod environment exceeds the threshold of 1 second.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High latency was observed in get-offer-details service (> 1 second )  requests in the Optimus-east environment.
          labels:
            application: get-offer-details
            metric: optimus
          isPaused: false
        - uid: c71f9db8-4e53-4598-87e8-a8ad2d2dc3a4
          title: GOD | High number of HTTP 5xx errors  | west | Prod |P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-offer-details-ns",project="prj-promoplat-p",region=~"us-west.+",source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ ".*health.*" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 18
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "18"
            Grafana Query: https://grafana.corp.quotient.com/goto/6aVypOwIR?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: get-offer-details
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: d2222fe7-80a3-43be-acac-0dc55142e458
          title: GOD | High number of HTTP 5xx errors  | east | Prod |P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-offer-details-ns",project="prj-promoplat-p",region=~"us-east.+",source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ ".*health.*" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 18
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "18"
            Grafana Query: https://grafana.corp.quotient.com/goto/IKeQtOwIR?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: get-offer-details
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: ddb2224f-8fb3-43f0-8abd-ffa3394d9831
          title: 'GOD | High number of HTTP 4xx errors  | west | Prod | P2 '
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-offer-details-ns",project="prj-promoplat-p",region=~"us-west.+",source_type="ingress_logs"} | json | message_httpRequest_status =~ "4[0-9][0-9]"  | message_httpRequest_requestUrl !~ ".*health.*" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 17
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "17"
            Grafana Query: https://grafana.corp.quotient.com/goto/k2NrpdwIR?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes > 5 in last 5 mins
          labels:
            application: get-offer-details
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: b2a2a48d-be0e-4e53-bc7f-a2ef61cc9cf8
          title: 'GOD | POD Health Checks failed | East | Prod | P2 '
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-offer-details-ns",namespace="prod",region="us-east4",project="prj-promoplat-p",source_type="ingress_logs"} | json | message_httpRequest_status!=`200` |message_jsonPayload_statusDetails!="client_disconnected_before_any_response" | message_httpRequest_status!~ "4[0-9][0-9]" |~"/gro/actuator/health" | __error__=`` [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: sum
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 2
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: OK
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/Mtj3pdQIg?orgId=1
            description: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
          labels:
            application: GOD
            metric: optimus
          isPaused: false
        - uid: f9346a11-b68a-47eb-9a07-4e6d66112a7d
          title: GOD | DB Fetch Time Exceeds 1 Seconds | West | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-offer-details-ns",namespace="prod",project="prj-promoplat-p",region="us-west1",source_type="kubernetes_logs"} |= `db_fetch_time` | pattern `<nonce> - <datetime> <_> - OfferDetails cache lookup stats for partnerId=<partnerId>. fetch_time=<fetch_time>, request_count=<request_count>, cache_hit_count=<cache_hit_count>, db_fetch_count=<db_fetch_count>, db_fetch_time=<db_fetch_time>, cache_get_count=<cache_get_count>, cache_get_time=<cache_get_time>, cache_put_count=<cache_put_count>, cache_put_time=<cache_put_time>, by_pass_cache=<by_pass_cache>` | db_fetch_time > 1000 !~ "GALO_HYDRATOR" | __error__=`` [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/v-ikhOwSg?orgId=1
            description: Database fetch time is over 1 second, indicating a performance issue
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: Database fetch time is over 1 second, indicating a performance issue
          labels:
            application: GOD
            metric: optimus
          isPaused: false
        - uid: e974960a-4ea6-447d-ab9b-de2d6a6f1053
          title: GOD | DB Fetch Time Exceeds 1 Seconds | East | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-offer-details-ns",namespace="prod",project="prj-promoplat-p",region="us-east4",source_type="kubernetes_logs"} |= `db_fetch_time` | pattern `<nonce> - <datetime> <_> - OfferDetails cache lookup stats for partnerId=<partnerId>. fetch_time=<fetch_time>, request_count=<request_count>, cache_hit_count=<cache_hit_count>, db_fetch_count=<db_fetch_count>, db_fetch_time=<db_fetch_time>, cache_get_count=<cache_get_count>, cache_get_time=<cache_get_time>, cache_put_count=<cache_put_count>, cache_put_time=<cache_put_time>, by_pass_cache=<by_pass_cache>` | db_fetch_time > 1000 !~ "GALO_HYDRATOR" | __error__=`` [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/GBHZhOwSg?orgId=1
            description: Database fetch time is over 1 second, indicating a performance issue
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: Database fetch time is over 1 second, indicating a performance issue
          labels:
            application: GOD
            metric: optimus
          isPaused: false
    - orgId: 1
      name: GRO
      folder: Optimus
      interval: 1m
      rules:
        - uid: b879cf72-8795-41e3-9667-d583ec4fda37
          title: GRO | High Latency Requests | west | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-recommended-offers-ns",namespace="prod",project="prj-promoplat-p",region=~"us-west.+",source_type="kubernetes_logs"} |= `http_response_time` != `oauth_internal=yes` != `GALO_HYDRATOR` != `warmup_service` != `user-agent=curl` != `user-agent=Postman` | pattern `nonce=<nonce> client_ip=<client_ip> - <datetime> <_> - /<endpoint>/<_> partnerId=<partnerId> <_> http_response_time=<latency>ms http_commit_response_time=<committime>ms`  | latency > 1500 | __error__="" [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 20
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "20"
            Grafana query: https://grafana.corp.quotient.com/goto/t_sgGOQSR?orgId=1
            description: This alert is triggered when the latency of 5 requests to the get-recommended-offers-ns service in the WEST Prod environment exceeds the threshold of 2 second.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High latency was observed in get-recommended-offers-ns service (> 1 second )  requests in the Optimus-West environment.
          labels:
            application: GRO
            metric: optimus
          isPaused: false
        - uid: ffcfed9c-ef71-44e8-bfd2-eaac09cb0e8a
          title: GRO | High number of HTTP 5xx errors  | west | Prod |P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-recommended-offers-ns",project="prj-promoplat-p",region=~"us-west.+",source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ ".*health.*" | __error__=``[$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 18
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "18"
            Grafana query: https://grafana.corp.quotient.com/goto/McOJndwSR?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: GRO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: ac478db9-fba5-4963-a106-5eefdaebda4d
          title: GRO | High number of HTTP 5xx errors  | east | Prod | P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-recommended-offers-ns",project="prj-promoplat-p",region=~"us-east.+",source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ ".*health.*" | __error__=``[$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 18
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "18"
            Grafana query: https://grafana.corp.quotient.com/goto/BL2l7OQIR?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: GRO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: ae075b65-8288-490e-ba88-ecb210a77a94
          title: GRO | High Latency Requests | east | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-recommended-offers-ns",namespace="prod",project="prj-promoplat-p",region=~"us-east.+",source_type="kubernetes_logs"} |= `http_response_time` != `oauth_internal=yes` != `GALO_HYDRATOR` != `warmup_service` != `user-agent=curl` != `user-agent=Postman` | pattern `nonce=<nonce> client_ip=<client_ip> - <datetime> <_> - /<endpoint>/<_> partnerId=<partnerId> <_> http_response_time=<latency>ms http_commit_response_time=<committime>ms`  | latency > 1000 | __error__=""[$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 20
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "20"
            Grafana query: https://grafana.corp.quotient.com/goto/UObR4dwIR?orgId=1
            description: This alert is triggered when the latency of 5 requests to the get-recommended-offers-ns service in the EAST Prod environment exceeds the threshold of 1 second.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High latency was observed in get-recommended-offers-ns service (> 1 second )  requests in the Optimus-east environment.
          labels:
            application: GRO
            metric: optimus
          isPaused: false
        - uid: a870d485-e0a5-4661-97f4-d49d72b2c895
          title: GRO | High number of HTTP 4xx errors  | west | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-recommended-offers-ns",project="prj-promoplat-p",region=~"us-west.+",source_type="ingress_logs"} | json | message_httpRequest_status =~ "4[0-9][0-9]"  | message_httpRequest_requestUrl !~ ".*health.*" | __error__=``[$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 17
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "17"
            Grafana query: https://grafana.corp.quotient.com/goto/RcLSVdwSg?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes > 5 in last 5 mins
          labels:
            application: GRO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: b532216f-0578-4e42-add1-2469190015f7
          title: GRO | High number of HTTP 4xx errors  | east | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-recommended-offers-ns",project="prj-promoplat-p",region=~"us-east.+",source_type="ingress_logs"} | json | message_httpRequest_status =~ "4[0-9][0-9]"  | message_httpRequest_requestUrl !~ ".*health.*" | __error__=``[$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 17
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "17"
            Grafana query: https://grafana.corp.quotient.com/goto/BcZcVOwIR?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes > 5 in last 5 mins
          labels:
            application: GRO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: c226aac6-b202-4f1c-b45e-f0c33be6d2f5
          title: GRO | Exceptions | west| Prod | P3
          condition: B
          data:
            - refId: log_metrics_gro_Exception
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: |-
                    sum(count_over_time(
                      {app="get-recommended-offers-ns", namespace="prod", project="prj-promoplat-p", source_type="kubernetes_logs", region=~"us-west.+"}
                      |~ "(?P<identifier>[^ ]+) - (?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}) \\[(?P<thread>[^\\]]+)\\] (?P<level>\\w+)"
                      |~ ".*Exception.*"
                      !~"Input Validation Failed"
                      | __error__=``
                      [$__range]
                    ))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: log_metrics_gro_Exception
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_gro_Exception
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: A
                type: reduce
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 8
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "8"
            Grafana query: https://grafana.corp.quotient.com/goto/tu3P4OQSR?orgId=1
            description: Exception Observed in logs for get-recommended-offers Service greater than 1
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: GRO | Exception Observed in logs for get-recommended-offers Service greater than 1
          labels:
            application: GRO
            metric: optimus
          isPaused: false
        - uid: fce2abeb-5dec-4037-9d45-c90a0eee5696
          title: GRO | Exceptions | east | Prod | P3
          condition: B
          data:
            - refId: log_metrics_gro_Exception
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: |-
                    sum(count_over_time(
                      {app="get-recommended-offers-ns", namespace="prod", project="prj-promoplat-p", source_type="kubernetes_logs", region=~"us-east.+"}
                      |~ "(?P<identifier>[^ ]+) - (?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d{3}) \\[(?P<thread>[^\\]]+)\\] (?P<level>\\w+)"
                      |~ ".*Exception.*"
                      !~"Input Validation Failed"
                      | __error__=``
                      [$__range]
                    ))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: log_metrics_gro_Exception
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_gro_Exception
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: A
                type: reduce
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 8
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "8"
            Grafana query: https://grafana.corp.quotient.com/goto/CJ7j4OQSg?orgId=1
            description: Exception Observed in logs for get-recommended-offers Service greater than 1
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: GRO | Exception Observed in logs for get-recommended-offers Service greater than 1
          labels:
            application: GRO
            metric: optimus
          isPaused: false
        - uid: a2d3343b-894c-4116-8dfd-c9126e89622d
          title: GRO | POD Health Checks failed | East | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-recommended-offers-ns",namespace="prod",region="us-east4",project="prj-promoplat-p",source_type="ingress_logs"} | json | message_httpRequest_status!=`200` |message_jsonPayload_statusDetails!="client_disconnected_before_any_response" | message_httpRequest_status!~ "4[0-9][0-9]" |~"/gro/actuator/health" | __error__=`` [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: sum
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 2
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 5
          noDataState: OK
          execErrState: OK
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "5"
            Grafana query: https://grafana.corp.quotient.com/goto/RnU7IOwSg?orgId=1
            description: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
          labels:
            application: GRO
            metric: optimus
          isPaused: false
        - uid: aeb447cb-1798-439d-b4db-af5ec7ae124e
          title: GRO | POD Health Checks failed | West | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-recommended-offers-ns",namespace="prod",region="us-west1",project="prj-promoplat-p",source_type="ingress_logs"} | json | message_httpRequest_status!=`200` |message_jsonPayload_statusDetails!="client_disconnected_before_any_response" | message_httpRequest_status!~ "4[0-9][0-9]" |~"/gro/actuator/health" | __error__=`` [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: sum
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 2
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 5
          noDataState: OK
          execErrState: OK
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "5"
            Grafana query: https://grafana.corp.quotient.com/goto/AdicIdQIg?orgId=1
            description: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
          labels:
            application: GRO
            metric: optimus
          isPaused: false
        - uid: fbfb98d8-f21c-4eeb-9a11-347015f0e421
          title: GRO | DB Fetch Time Exceeds 1 Seconds | West | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-recommended-offers-ns",namespace="prod",project="prj-promoplat-p",region="us-west1",source_type="kubernetes_logs"} |= `db_fetch_time` | pattern `<nonce> - <datetime> <_> - OfferDetails cache lookup stats for partnerId=<partnerId>. fetch_time=<fetch_time>, request_count=<request_count>, cache_hit_count=<cache_hit_count>, db_fetch_count=<db_fetch_count>, db_fetch_time=<db_fetch_time>, cache_get_count=<cache_get_count>, cache_get_time=<cache_get_time>, cache_put_count=<cache_put_count>, cache_put_time=<cache_put_time>, by_pass_cache=<by_pass_cache>` | db_fetch_time > 1000 !~ "GALO_HYDRATOR" | __error__=`` [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            Grafana query: https://grafana.corp.quotient.com/goto/ZRraSOQSg?orgId=1
            description: Database fetch time is over 1 second, indicating a performance issue
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: Database fetch time is over 1 second, indicating a performance issue
          labels:
            application: GRO
            metric: optimus
          isPaused: false
        - uid: ec38f0a7-8776-40cb-a9a0-e61226830921
          title: GRO | DB Fetch Time Exceeds 1 Seconds | East | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-recommended-offers-ns",namespace="prod",project="prj-promoplat-p",region="us-east4",source_type="kubernetes_logs"} |= `db_fetch_time` | pattern `<nonce> - <datetime> <_> - OfferDetails cache lookup stats for partnerId=<partnerId>. fetch_time=<fetch_time>, request_count=<request_count>, cache_hit_count=<cache_hit_count>, db_fetch_count=<db_fetch_count>, db_fetch_time=<db_fetch_time>, cache_get_count=<cache_get_count>, cache_get_time=<cache_get_time>, cache_put_count=<cache_put_count>, cache_put_time=<cache_put_time>, by_pass_cache=<by_pass_cache>` | db_fetch_time > 1000 !~ "GALO_HYDRATOR" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            Grafana query: https://grafana.corp.quotient.com/goto/5guySOwIg?orgId=1
            description: Database fetch time is over 1 second, indicating a performance issue
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: Database fetch time is over 1 second, indicating a performance issue
          labels:
            application: GRO
            metric: optimus
          isPaused: false
    - orgId: 1
      name: GTO
      folder: Optimus
      interval: 1m
      rules:
        - uid: e7f7e5d9-cc6c-406b-bcd8-5fe534e35722
          title: GTO | High Latency Requests | west | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-targeted-offers-ns",namespace="prod",project="prj-promoplat-p",region=~"us-west.+",source_type="kubernetes_logs"} |= `http_response_time` != `oauth_internal=yes` != `GALO_HYDRATOR` != `warmup_service` != `user-agent=curl` != `user-agent=Postman` | pattern `nonce=<nonce> client_ip=<client_ip> - <datetime> <_> - /<endpoint>/<_> partnerId=<partnerId> <_> http_response_time=<latency>ms http_commit_response_time=<committime>ms`  | latency > 1000 | __error__=`` [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            description: This alert is triggered when the latency of 5 requests to the get-targeted-offers-ns in the WEST Prod environment exceeds the threshold of 2 second.
            summary: High latency was observed in get-targeted-offers-ns service (> 1 second )  requests in the Optimus-West environment.
          labels:
            application: GTO
            metric: optimus
          isPaused: false
        - uid: e10b2802-4367-443f-8788-a6beb2372bc0
          title: GTO | High number of HTTP 5xx errors  | west | Prod | P1
          condition: C
          data:
            - refId: GTO 5xx Failures
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-targeted-offers-ns",project="prj-promoplat-p",region=~"us-west.+",source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ ".*health.*" | __error__="" [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: GTO 5xx Failures
            - refId: GTO 5xx event
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GTO 5xx Failures
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: GTO 5xx event
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GTO 5xx event
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 18
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "18"
            Query: https://grafana.corp.quotient.com/goto/jWfUmdwIR?orgId=1
            description: The rate of 5xx status codes on the GTO API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes in GTO > 5 in last 5 mins
          labels:
            application: GTO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: f647039e-01e4-45e3-97bf-feea8df43d81
          title: GTO | High number of HTTP 5xx errors  | east | Prod | P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app=" get-targeted-offers-ns",project="prj-promoplat-p",region=~"us-east.+",source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ ".*health.*" | __error__="" [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 18
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "18"
            Grafana Query: https://grafana.corp.quotient.com/goto/KTh3mdwIg?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes in GTO east > 5 in last 5 mins
          labels:
            application: GTO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: c312e46b-5132-4dff-8d2e-8318a108ba98
          title: 'GTO | High Latency Requests | east | Prod | P2 '
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-targeted-offers-ns",namespace="prod",project="prj-promoplat-p",region=~"us-east.+",source_type="kubernetes_logs"} |= `http_response_time` != `oauth_internal=yes` != `GALO_HYDRATOR` != `warmup_service` != `user-agent=curl` != `user-agent=Postman` | pattern `nonce=<nonce> client_ip=<client_ip> - <datetime> <_> - /<endpoint>/<_> partnerId=<partnerId> <_> http_response_time=<latency>ms http_commit_response_time=<committime>ms`  | latency > 1000 | __error__=""  [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            description: This alert is triggered when the latency of 5 requests to the get-recommended-offers-ns service in the EAST Prod environment exceeds the threshold of 1 second.
            summary: High latency was observed in get-targeted-offers-ns service (> 1 second )  requests in the Optimus-east environment.
          labels:
            application: GTO
            metric: optimus
          isPaused: false
        - uid: b38f8ca5-d4e1-496b-b8ae-88aad3e9565b
          title: 'GTO | High number of HTTP 4xx errors  | west | Prod | P2 '
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app=" get-targeted-offers-ns",project="prj-promoplat-p",region=~"us-west.+",source_type="ingress_logs"} | json | message_httpRequest_status =~ "4[0-9][0-9]"  | message_httpRequest_requestUrl !~ ".*health.*" | __error__="" [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 17
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "17"
            Grafana Query: https://grafana.corp.quotient.com/goto/BuVQMOQIg?orgId=1
            description: The rate of 4xx status codes on the GTO API in west is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes in GTO west > 5 in last 5 mins
          labels:
            application: GTO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: a68f73f2-b6cc-4cf4-b5cb-b73374b8a1a8
          title: GTO | High number of HTTP 4xx errors  | east | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app=" get-targeted-offers-ns",project="prj-promoplat-p",region=~"us-east.+",source_type="ingress_logs"} | json | message_httpRequest_status =~ "4[0-9][0-9]"  | message_httpRequest_requestUrl !~ ".*health.*"| __error__="" [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 17
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "17"
            Grafana Query: https://grafana.corp.quotient.com/goto/EPv9GdwSg?orgId=1
            description: The rate of 4xx status codes on the GTO API in east is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes in GTO east > 5 in last 5 mins
          labels:
            application: GTO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: ce66edd3-8313-4519-ae43-1922fed2af67
          title: 'GTO | Exceptions | west| Prod | P3 '
          condition: B
          data:
            - refId: log_metrics_gto_Exception
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app=" get-targeted-offers-ns",namespace="prod",project="prj-promoplat-p",source_type="kubernetes_logs",region=~"us-west.+"}|~".*Exception.*" | __error__="" [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: log_metrics_gto_Exception
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_gto_Exception
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: A
                type: reduce
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 8
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "8"
            Grafana Query: https://grafana.corp.quotient.com/goto/Aq6jMdQSR?orgId=1
            description: |-
                Exception Observed in logs for get-recommended-offers Service greater than 1 in west

                Logs: https://cloudlogging.app.goo.gl/9caeai94RzUNds4j8
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: GTO | Exception Observed in logs for get-recommended-offers Service greater than 1 in west
          labels:
            application: GTO
            metric: optimus
          isPaused: false
        - uid: ec87e13b-0bfe-4aac-b2a8-f28012850cde
          title: 'GTO | Exceptions | east | Prod | P3 '
          condition: B
          data:
            - refId: log_metrics_gto_Exception
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-targeted-offers-ns",namespace="prod",project="prj-promoplat-p",source_type="kubernetes_logs",region=~"us-east.+"}|~".*Exception.*" | __error__="" [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: log_metrics_gto_Exception
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_gto_Exception
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: A
                type: reduce
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 8
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "8"
            Grafana Query: https://grafana.corp.quotient.com/goto/RIreGOQSR?orgId=1
            description: |-
                Exception Observed in logs for get-targeted-offers Service greater than 1 in east

                Logs: https://cloudlogging.app.goo.gl/wnc6Eh4QS521UVAC8
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: GTO | Exception Observed in logs for get-targeted-offers Service greater than 1 in east
          labels:
            application: GTO
            metric: optimus
          isPaused: false
        - uid: a6d9bdf4-2a01-4704-af41-bafe823ad053
          title: 'GTO | POD Health Checks failed | East | Prod | P2 '
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-targeted-offers-ns",namespace="prod",region="us-east4",project="prj-promoplat-p",source_type="ingress_logs"} | json | message_httpRequest_status!=`200` |message_jsonPayload_statusDetails!="client_disconnected_before_any_response" | message_httpRequest_status!~ "4[0-9][0-9]" |~"/gto/actuator/health" | __error__="" [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: sum
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: OK
          for: 2m
          annotations:
            description: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
            runbook_url: https://grafana.corp.quotient.com/explore?orgId=1&panes=%7B%224A3%22:%7B%22datasource%22:%22sXVBxwenz%22,%22queries%22:%5B%7B%22refId%22:%22A%22,%22editorMode%22:%22code%22,%22expr%22:%22count%28count_over_time%28%7Bapp%3D%5C%22get-targeted-offers-ns%5C%22,namespace%3D%5C%22prod%5C%22,project%3D%5C%22prj-promoplat-p%5C%22,source_type%3D%5C%22ingress_logs%5C%22%7D%20%7C%20json%20%7C%20message_httpRequest_status%21%3D%60200%60%20%7Cmessage_jsonPayload_statusDetails%21%3D%5C%22client_disconnected_before_any_response%5C%22%20%7C%20message_httpRequest_status%21~%20%5C%224%5B0-9%5D%5B0-9%5D%5C%22%20%7C~%5C%22%2Fgto%2Factuator%2Fhealth%5C%22%5B$__range%5D%29%29%22,%22hide%22:false,%22intervalMs%22:1000,%22maxDataPoints%22:43200,%22queryType%22:%22range%22,%22datasource%22:%7B%22type%22:%22loki%22,%22uid%22:%22sXVBxwenz%22%7D%7D%5D,%22range%22:%7B%22from%22:%22now-1h%22,%22to%22:%22now%22%7D%7D%7D&schemaVersion=1
            summary: this query helps monitor and quantify instances where the health check for the GTO application fails, based on non-200 HTTP responses in the specified endpoint.
          labels:
            application: GTO
            metric: optimus
          isPaused: false
        - uid: f8ff09c6-3b7c-498e-bd62-2947a2714d01
          title: GTO | POD Health Checks failed | West | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-targeted-offers-ns",namespace="prod",region="us-west1",project="prj-promoplat-p",source_type="ingress_logs"} | json | message_httpRequest_status!=`200` |message_jsonPayload_statusDetails!="client_disconnected_before_any_response" | message_httpRequest_status!~ "4[0-9][0-9]" |~"/gto/actuator/health" | __error__="" [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: sum
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: OK
          for: 2m
          annotations:
            description: this query helps monitor and quantify instances where the health check for the GTO application fails, based on non-200 HTTP responses in the specified endpoint.
            runbook_url: https://grafana.corp.quotient.com/explore?orgId=1&panes=%7B%22x9x%22:%7B%22datasource%22:%22sXVBxwenz%22,%22queries%22:%5B%7B%22refId%22:%22A%22,%22editorMode%22:%22code%22,%22expr%22:%22count%28count_over_time%28%7Bapp%3D%5C%22get-targeted-offers-ns%5C%22,namespace%3D%5C%22prod%5C%22,project%3D%5C%22prj-promoplat-p%5C%22,source_type%3D%5C%22ingress_logs%5C%22%7D%20%7C%20json%20%7C%20message_httpRequest_status%21%3D%60200%60%20%7Cmessage_jsonPayload_statusDetails%21%3D%5C%22client_disconnected_before_any_response%5C%22%20%7C%20message_httpRequest_status%21~%20%5C%224%5B0-9%5D%5B0-9%5D%5C%22%20%7C~%5C%22%2Fgto%2Factuator%2Fhealth%5C%22%5B$__range%5D%29%29%22,%22hide%22:false,%22intervalMs%22:1000,%22maxDataPoints%22:43200,%22queryType%22:%22range%22,%22datasource%22:%7B%22type%22:%22loki%22,%22uid%22:%22sXVBxwenz%22%7D%7D%5D,%22range%22:%7B%22from%22:%22now-1h%22,%22to%22:%22now%22%7D%7D%7D&schemaVersion=1
            summary: this query helps monitor and quantify instances where the health check for the GTO application fails, based on non-200 HTTP responses in the specified endpoint.
          labels:
            application: GTO
            metric: optimus
          isPaused: false
        - uid: dcf77941-509a-4a8b-8a19-14d02f4a9d0c
          title: GTO | DB Fetch Time Exceeds 1 Seconds | West | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-targeted-offers-ns",namespace="prod",project="prj-promoplat-p",region="us-west1",source_type="kubernetes_logs"} |= `db_fetch_time` | pattern `<nonce> - <datetime> <_> - OfferDetails cache lookup stats for partnerId=<partnerId>. fetch_time=<fetch_time>, request_count=<request_count>, cache_hit_count=<cache_hit_count>, db_fetch_count=<db_fetch_count>, db_fetch_time=<db_fetch_time>, cache_get_count=<cache_get_count>, cache_get_time=<cache_get_time>, cache_put_count=<cache_put_count>, cache_put_time=<cache_put_time>, by_pass_cache=<by_pass_cache>` | db_fetch_time > 1000 !~ "GALO_HYDRATOR"| __error__="" [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            description: fetch time for fetching offer detail is over 1 second, indicating a performance issue
            summary: fetch time for fetching offer detail is over 1 second, indicating a performance issue
          labels:
            application: GTO
            metric: optimus
          isPaused: false
        - uid: a3c968fd-aa2b-4a7c-87a2-852fd4e9fe6c
          title: 'GTO | DB Fetch Time Exceeds 1 Seconds | East | Prod | P2 '
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-targeted-offers-ns",namespace="prod",project="prj-promoplat-p",region="us-east4",source_type="kubernetes_logs"} |= `db_fetch_time` | pattern `<nonce> - <datetime> <_> - OfferDetails cache lookup stats for partnerId=<partnerId>. fetch_time=<fetch_time>, request_count=<request_count>, cache_hit_count=<cache_hit_count>, db_fetch_count=<db_fetch_count>, db_fetch_time=<db_fetch_time>, cache_get_count=<cache_get_count>, cache_get_time=<cache_get_time>, cache_put_count=<cache_put_count>, cache_put_time=<cache_put_time>, by_pass_cache=<by_pass_cache>` | db_fetch_time > 1000 !~ "GALO_HYDRATOR" | __error__="" [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            description: fetch time for offer details is over 1 second, indicating a performance issue
            summary: fetch time for offer details is over 1 second, indicating a performance issue
          labels:
            application: GTO
            metric: optimus
          isPaused: false
    - orgId: 1
      name: GUOD
      folder: Optimus
      interval: 2m
      rules:
        - uid: dd810385-60a2-4204-bb4d-014927ad093d
          title: GUOD | Exceptions | east | Prod | P3
          condition: A
          data:
            - refId: log_metrics_guod_Exception
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: sum(count_over_time({app="get-user-offer-details-ns",cluster=~"gke-gke-riq-usest.+-prod-active",project="prj-promoplat-p", namespace="prod"} !~"RestValidationException" |~".*Exception.*"| __error__="" [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: log_metrics_guod_Exception
            - refId: GUOD_Exceptions_East
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_guod_Exception
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: GUOD_Exceptions_East
                type: reduce
            - refId: A
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_Exceptions_East
                intervalMs: 1000
                maxDataPoints: 43200
                refId: A
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 5
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "5"
            Grafana Query: https://grafana.corp.quotient.com/goto/KYzLQvwIg?orgId=1
            description: Exception Observed in logs for get-user-offer-details Service.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: Exception Observed in logs for get-user-offer-details Service.
          labels:
            metric: optimus
          isPaused: false
        - uid: acf759fd-1f06-4ae7-bee6-4ffd3a185f66
          title: 'GUOD | Exceptions | west | Prod | P3 '
          condition: A
          data:
            - refId: log_metrics_guod_Exception
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: sum(count_over_time({app="get-user-offer-details-ns",region="us-west1", project="prj-promoplat-p", namespace="prod"} !~"RestValidationException" |~".*Exception.*"| __error__="" [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: log_metrics_guod_Exception
            - refId: GUOD_Exceptions_West
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_guod_Exception
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: GUOD_Exceptions_West
                type: reduce
            - refId: A
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_Exceptions_West
                intervalMs: 1000
                maxDataPoints: 43200
                refId: A
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 5
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "5"
            Grafana Query: https://grafana.corp.quotient.com/goto/IO4QevwSg?orgId=1
            description: Exception Observed in logs for get-user-offer-details Service.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: Exception Observed in logs for get-user-offer-details Service.
          labels:
            metric: optimus
          isPaused: false
        - uid: a98783c6-cc7e-487b-9029-a3815252eacb
          title: GUOD | High number of HTTP 5xx errors  | west | Prod | P1
          condition: C
          data:
            - refId: GUOD_5xx
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-user-offer-details-ns",namespace="prod",project="prj-promoplat-p",region=~"us-west.+",source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ ".*health.*"| __error__="" [$__interval]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: GUOD_5xx
            - refId: GUOD_5xx_failures
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_5xx
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: GUOD_5xx_failures
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_5xx_failures
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 27
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "27"
            Grafana Query: https://grafana.corp.quotient.com/goto/sSIyeDQIR?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://grafana.corp.quotient.com/goto/zqI8QDwSg?orgId=1
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: GUOD
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: ad33f366-213a-41da-87d7-4c308abda1a7
          title: GUOD | High number of HTTP 5xx errors  | east | Prod | P1
          condition: C
          data:
            - refId: GUOD_5xx
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-user-offer-details-ns",namespace="prod",project="prj-promoplat-p",region=~"us-west.+",source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ ".*health.*"| __error__="" [$__interval]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: GUOD_5xx
            - refId: GUOD_5xx_failures
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_5xx
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: GUOD_5xx_failures
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_5xx_failures
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 27
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "27"
            Grafana Query: https://grafana.corp.quotient.com/goto/bvqL6vwSR?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: GUOD
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: c920f9e9-f2ed-4bef-8967-4df829af5d88
          title: GUOD | High number of HTTP 4xx errors  | west | Prod | P1
          condition: C
          data:
            - refId: GUOD_4xx
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-user-offer-details-ns",namespace="prod",project="prj-promoplat-p",region=~"us-west.+",source_type="ingress_logs"} | json | message_httpRequest_status =~ "4[1-9][0-9]" | message_httpRequest_requestUrl !~ ".*health.*"| __error__="" [5m]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: GUOD_4xx
            - refId: GUOD_4xx_failures
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_4xx
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: GUOD_4xx_failures
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_4xx_failures
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 28
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "28"
            Grafana Query: https://grafana.corp.quotient.com/goto/iS6b6vQIg?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes > 5 in last 5 mins
          labels:
            application: GUOD
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: c85a0189-0e2d-4277-b3b8-dd9ed3c47fed
          title: GUOD | High number of HTTP 4xx errors  | east | Prod | P1
          condition: C
          data:
            - refId: GUOD_4xx
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-user-offer-details-ns",namespace="prod",project="prj-promoplat-p",region=~"us-east.+",source_type="ingress_logs"} | json | message_httpRequest_status =~ "4[1-9][0-9]" | message_httpRequest_requestUrl !~ ".*health.*"| __error__="" [$__interval]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: GUOD_4xx
            - refId: GUOD_4xx_failures
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_4xx
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: GUOD_4xx_failures
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_4xx_failures
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 17
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "17"
            Grafana Query: https://grafana.corp.quotient.com/goto/Mw7nRdQIR?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes > 5 in last 5 mins
          labels:
            application: GUOD
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: e3720883-10b8-46d4-bf96-f1574112dde5
          title: GUOD | High p90 Response Times | east | Prod | P2
          condition: C
          data:
            - refId: GUOD_Response_time
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: |-
                    quantile_over_time(0.90,
                      {project="prj-promoplat-p", namespace="prod", app="get-user-offer-details-ns", region=~"us-east.+", source_type="kubernetes_logs"} |= `http_response_time=` |= `vr=1.0` != `oauth_internal=yes` != `GALO_HYDRATOR` != `warmup_service` != `user-agent=curl` != `user-agent=Postman` | pattern `nonce=<nonce> client_ip=<client_ip> - <datetime> <_> - /<endpoint>/<_> partnerId=<partnerId> <_> http_response_time=<latency>ms http_commit_response_time=<committime>ms`
                        | unwrap latency
                        | __error__="" [5m]
                    ) by (app)
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: GUOD_Response_time
            - refId: GUOD_Latency
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_Response_time
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: GUOD_Latency
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1000
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_Latency
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 21
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "21"
            description: The 90th percentile response time for the application `get-user-offer-details-ns` in the `east` namespace has exceeded 1000ms. This indicates that 90% of the requests took longer than 1000ms over the past 5 minutes.
            runbook_url: https://grafana.corp.quotient.com/explore?orgId=1&left=%7B%22datasource%22:%22sXVBxwenz%22,%22queries%22:%5B%7B%22refId%22:%22A%22,%22datasource%22:%7B%22type%22:%22loki%22,%22uid%22:%22sXVBxwenz%22%7D,%22editorMode%22:%22code%22,%22expr%22:%22%7Bapp%3D%5C%22get-all-offers-ns%5C%22,namespace%3D%5C%22prod%5C%22,project%3D%5C%22prj-promoplat-p%5C%22,region%3D~%5C%22us-west.%2B%5C%22,source_type%3D%5C%22ingress_logs%5C%22%7D%20%7C%20json%20%7C%20message_httpRequest_latency%20%3E%3D%201s%20%7C%20message_httpRequest_requestUrl%20%21~%20%5C%22.%2Ahealth.%2A%5C%22%22,%22queryType%22:%22range%22%7D%5D,%22range%22:%7B%22from%22:%22now-1h%22,%22to%22:%22now%22%7D%7D
            summary: High latency was observed in get-user-offer-details-ns service (> 1 second )
          labels:
            metric: optimus
          isPaused: false
        - uid: ef87efe8-2490-4156-8071-44daa7ca7aab
          title: 'GUOD | High p90 Response Times | west | Prod | P2 '
          condition: C
          data:
            - refId: GUOD_Response_time
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: |-
                    quantile_over_time(0.90,
                      {project="prj-promoplat-p", namespace="prod", app="get-user-offer-details-ns", region=~"us-west.+", source_type="kubernetes_logs"} |= `http_response_time=` |= `vr=1.0` != `oauth_internal=yes` != `GALO_HYDRATOR` != `warmup_service` != `user-agent=curl` != `user-agent=Postman` | pattern `nonce=<nonce> client_ip=<client_ip> - <datetime> <_> - /<endpoint>/<_> partnerId=<partnerId> <_> http_response_time=<latency>ms http_commit_response_time=<committime>ms`
                        | unwrap latency
                        | __error__="" [5m]
                    ) by (app)
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: GUOD_Response_time
            - refId: GUOD_p90Latency
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_Response_time
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: GUOD_p90Latency
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1000
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_p90Latency
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 20
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "20"
            Grafana Query: https://grafana.corp.quotient.com/goto/UPu4RdwSg?orgId=1
            description: The 90th percentile response time for the application `get-user-offer-details-ns` in the `west` region has exceeded 1000ms. This indicates that 90% of the requests took longer than 1000ms over the past 5 minutes.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: The 90th percentile response time for the `get-user-offer-details-ns` app in the `west` region has exceeded 1000ms.
          labels:
            metric: optimus
          isPaused: false
        - uid: c92c77e5-ee26-432b-82af-42cf009394e8
          title: GUOD | DB Fetch Time Exceeds 1 Seconds | East | Prod | P2
          condition: C
          data:
            - refId: GUOD_DB_Fetch_time
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-user-offer-details-ns",namespace="prod",project="prj-promoplat-p",region="us-east4",source_type="kubernetes_logs"} |= `db_fetch_time` | pattern `<nonce> - <datetime> <_> - OfferDetails cache lookup stats for partnerId=<partnerId>. fetch_time=<fetch_time>, request_count=<request_count>, cache_hit_count=<cache_hit_count>, db_fetch_count=<db_fetch_count>, db_fetch_time=<db_fetch_time>, cache_get_count=<cache_get_count>, cache_get_time=<cache_get_time>, cache_put_count=<cache_put_count>, cache_put_time=<cache_put_time>, by_pass_cache=<by_pass_cache>` | db_fetch_time > 1000 !~ "GALO_HYDRATOR"| __error__="" [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: GUOD_DB_Fetch_time
            - refId: GUOD_DB_Fetch_Time
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_DB_Fetch_time
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: GUOD_DB_Fetch_Time
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_DB_Fetch_Time
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            description: Database fetch time is over 1 second, indicating a performance issue
            summary: Database fetch time is over 1 second, indicating a performance issue
          labels:
            application: GUOD
            metric: optimus
          isPaused: false
        - uid: cc436540-2fd7-4b52-9971-712f203e5874
          title: GUOD | DB Fetch Time Exceeds 1 Seconds | West | Prod | P2
          condition: C
          data:
            - refId: GUOD_DB_Fetch_time
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-user-offer-details-ns",namespace="prod",project="prj-promoplat-p",region=~"us-west.+",source_type="kubernetes_logs"} |= `db_fetch_time` | pattern `<nonce> - <datetime> <_> - OfferDetails cache lookup stats for partnerId=<partnerId>. fetch_time=<fetch_time>, request_count=<request_count>, cache_hit_count=<cache_hit_count>, db_fetch_count=<db_fetch_count>, db_fetch_time=<db_fetch_time>, cache_get_count=<cache_get_count>, cache_get_time=<cache_get_time>, cache_put_count=<cache_put_count>, cache_put_time=<cache_put_time>, by_pass_cache=<by_pass_cache>` | db_fetch_time > 1000 !~ "GALO_HYDRATOR"| __error__="" [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: GUOD_DB_Fetch_time
            - refId: GUOD_DB_Fetch_Time
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_DB_Fetch_time
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: GUOD_DB_Fetch_Time
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD_DB_Fetch_Time
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            description: Database fetch time is over 1 second, indicating a performance issue
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: Database fetch time is over 1 second, indicating a performance issue
          labels:
            application: GUOD
            metric: optimus
          isPaused: false
        - uid: baa8c164-782f-4704-9352-984ad773b168
          title: GUOD | POD Health Checks failed | East |  Prod | P2
          condition: C
          data:
            - refId: GUOD Health Checks
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-user-offer-details-ns",namespace="prod",region="us-east4",project="prj-promoplat-p",source_type="ingress_logs"} | json | message_httpRequest_status!=`200` | message_jsonPayload_statusDetails!="client_disconnected_before_any_response" | message_httpRequest_status!~ "4[0-9][0-9]" |~"/guod/actuator/health"| __error__="" [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: GUOD Health Checks
            - refId: GUDO Health Checks failed
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD Health Checks
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: sum
                refId: GUDO Health Checks failed
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 2
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUDO Health Checks failed
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: OK
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/Gz-IgdwSg?orgId=1
            description: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
          labels:
            metric: optimus
          isPaused: false
        - uid: d31a4b84-777a-4e37-900c-d10e0cc21bc2
          title: 'GUOD | POD Health Checks failed | west |  Prod | P2 '
          condition: C
          data:
            - refId: GUOD Health Checks
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="get-user-offer-details-ns",namespace="prod",region=~"us-west.+",project="prj-promoplat-p",source_type="ingress_logs"} | json | message_httpRequest_status!=`200` | message_jsonPayload_statusDetails!="client_disconnected_before_any_response" | message_httpRequest_status!~ "4[0-9][0-9]" |~"/guod/actuator/health"| __error__="" [$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: GUOD Health Checks
            - refId: GUDO Health Checks failed
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUOD Health Checks
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: sum
                refId: GUDO Health Checks failed
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 2
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: GUDO Health Checks failed
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: OK
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/eMKHRdwSR?orgId=1
            description: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
          labels:
            metric: optimus
          isPaused: false
    - orgId: 1
      name: General
      folder: Optimus
      interval: 5m
      rules:
        - uid: d6bdfe8e-4c3b-4f7c-b1d4-57cf0d009759
          title: Optimus | Permission Denied Exception | Prod  | P2
          condition: Threshold
          data:
            - refId: PermissionDeniedCount
              queryType: range
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: sum(count_over_time({project="prj-promoplat-p",namespace="prod",source_type="kubernetes_logs"}|~"PermissionDeniedException|PERMISSION_DENIED" | __error__=``[$__interval]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: PermissionDeniedCount
            - refId: PermissionDeniedCountMax
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: PermissionDeniedCount
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: PermissionDeniedCountMax
                type: reduce
            - refId: Threshold
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: PermissionDeniedCountMax
                intervalMs: 1000
                maxDataPoints: 43200
                refId: Threshold
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: This alert is generated when any Permission Denied logs are available in Optimus Prod.
            runbook_url: https://grafana.corp.quotient.com/goto/va3VOmsIR?orgId=1
            summary: "Permission Denied Exceptions are observed in the log lines in Optimus Prod.\n\nPlease check the application in scope for the alert and resource it failed to fetch. \n1. The reason might be due to recent deployments and application in scope is missing permissions.\n2. Some changes at resource.\n\nFurther Contact Points after Analysis:\n1. Update relevant QA team.\n2. Update SRE/DEVOPS if resource changes are causing issue."
          labels:
            metric: optimus
          isPaused: false
        - uid: ff234c8d-0e03-4d9b-a4fa-21407122938f
          title: GKE Node CPU Utilisation-Optimus PROD | Critical
          condition: Threshold
          data:
            - refId: CPU_Uses
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: '100 * (1 - avg(rate(node_cpu_seconds_total{mode="idle",project="prj-promoplat-p"}[$__rate_interval]))by (instance)) '
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: CPU_Uses
            - refId: Threshold
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 80
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: CPU_Uses
                intervalMs: 1000
                maxDataPoints: 43200
                refId: Threshold
                type: threshold
          noDataState: NoData
          execErrState: Error
          for: 5m
          annotations:
            description: |-
                Node CPU uses is above threshold, do observe/evaluate if pods are throttling on the node or restarting.

                Based on observations escalate to devops accordingly.
            summary: The GKE node {{ $labels.instance }} of cluster {{ $labels.cluster }}, CPU uses are higher than Threshold.
          labels:
            metric: optimus
          isPaused: false
    - orgId: 1
      name: Kubernetes Cluster Events
      folder: Optimus
      interval: 15m
      rules:
        - uid: f348f53d-6045-4134-833a-64ead75a33d3
          title: KubePodNotReady | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: sum by (namespace, pod) (kube_pod_status_phase{project="prj-promoplat-p",job="kube-state-metrics",pod!~".*job.*", phase=~"Pending|Unknown|Failed"}) > 0
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-running state for longer than 15 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Pod not healthy (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: b3d65d8e-bc4e-438f-a80c-3c5c25626f3d
          title: KubernetesHpaScaleMaximum | INFO
          condition: C
          data:
            - refId: max_replicas
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_horizontalpodautoscaler_status_current_replicas{namespace="prod",horizontalpodautoscaler=~".*"} == kube_horizontalpodautoscaler_spec_max_replicas{namespace="prod",horizontalpodautoscaler=~".*"}
                instant: true
                intervalMs: 300000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: max_replicas
            - refId: last_value_max_replicas
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: max_replicas
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: last_value_max_replicas
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: last_value_max_replicas
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 12h
          annotations:
            description: '"HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler }} has hit maximum number of desired pods\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes HPA scale maximum (instance {{ $labels.horizontalpodautoscaler }})
          labels:
            metric: optimus
          isPaused: false
        - uid: c8bda50c-fce0-4407-b346-fb24e4afe1bb
          title: KubeContainerWaiting
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_pod_container_status_waiting_reason{job="kube-state-metrics",namespace="prod",project="prj-promoplat-p"}
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Pod {{ $labels.namespace }}/{{ $labels.pod }} container {{ $labels.container }} has been in waiting state for longer than 1 hour.\n  VALUE = {{ $value }}"'
            summary: Pod container waiting longer than 1 hour
          labels:
            metric: optimus
          isPaused: false
        - uid: a919dcaf-4a68-47b5-84b0-6129e7f11182
          title: KubeDeploymentReplicasMismatch
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: "(\n  kube_deployment_spec_replicas{namespace=\"prod\",project=\"prj-promoplat-p\",job=\"kube-state-metrics\"} != \n  kube_deployment_status_replicas_available{namespace=\"prod\",project=\"prj-promoplat-p\",job=\"kube-state-metrics\"}\n)\nand \n(\n  changes(kube_deployment_status_replicas_updated{namespace=\"prod\",project=\"prj-promoplat-p\",job=\"kube-state-metrics\"}[10m]) == 0\n)\n"
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: Deployment {{`{{`}} $labels.namespace {{`}}`}}/{{`{{`}} $labels.deployment {{`}}`}} has not matched the expected number of replicas for longer than 15 minutes.
            summary: Deployment has not matched the expected number of replicas.
          labels:
            metric: optimus
          isPaused: false
        - uid: f457b47e-eb19-4e3d-a79a-fac3411e72fc
          title: KubernetesNodeNotReady | East
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_node_status_condition{cluster="gke-riq-usest4-prod-active",job="kube-state-metrics",project="prj-promoplat-p",condition="Ready",status="true"} == 0
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} has been unready for a long time\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node not ready (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: d9a10dab-5710-4c73-84bc-63f4603e86a8
          title: KubernetesNodeNotReady | West
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_node_status_condition{cluster="gke-riq-uswst1-prod-active",job="kube-state-metrics",project="prj-promoplat-p",condition="Ready",status="true"} == 0
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} has been unready for a long time\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node not ready (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: f594e060-87a9-4663-8544-667541a742e8
          title: KubernetesNodeMemoryPressure | East | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_node_status_condition{cluster="gke-riq-usest4-prod-active",job="kube-state-metrics",project="prj-promoplat-p",condition="MemoryPressure",status="true"} == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} has MemoryPressure condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node memory pressure (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: af461fc9-1edf-4240-8c8d-c6490b77003b
          title: 'KubernetesNodeMemoryPressure | West | Critical '
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_node_status_condition{cluster="gke-riq-uswst1-prod-active",job="kube-state-metrics",project="prj-promoplat-p",condition="MemoryPressure",status="true"} == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} has MemoryPressure condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node memory pressure (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: f07e50d0-61f6-4dc5-b4b5-0a2f40dd41ed
          title: KubernetesNodeDiskPressure | East | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_node_status_condition{cluster="gke-riq-usest4-prod-active",job="kube-state-metrics",project="prj-promoplat-p",condition="DiskPressure",status="true"} == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} has DiskPressure condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node disk pressure (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: f32ee60c-16c9-4bf5-94da-6348067a5808
          title: KubernetesNodeDiskPressure | West | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_node_status_condition{cluster="gke-riq-uswst1-prod-active",job="kube-state-metrics",project="prj-promoplat-p",condition="DiskPressure",status="true"} == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} has DiskPressure condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node disk pressure (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: d231f281-ffa8-4f90-aa33-a21aae64d6e9
          title: KubernetesNodeNetworkUnavailable | East | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_node_status_condition{cluster="gke-riq-usest4-prod-active",job="kube-state-metrics",project="prj-promoplat-p",condition="NetworkUnavailable",status="true"}  == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} has NetworkUnavailable condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node network unavailable (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: dc5e5774-1175-4d21-93ca-3efb89fef856
          title: KubernetesNodeNetworkUnavailable | West | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_node_status_condition{cluster="gke-riq-uswst1-prod-active",job="kube-state-metrics",project="prj-promoplat-p",condition="NetworkUnavailable",status="true"}  == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} has NetworkUnavailable condition\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node network unavailable (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: db7bccbe-59bd-4d9a-a35d-20baa3cc65bf
          title: KubernetesNodeOutOfPodCapacity | Warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: sum by (node) ((kube_pod_status_phase{project="prj-promoplat-p",phase="Running"} == 1) + on(uid) group_left(node) (0 * kube_pod_info{project="prj-promoplat-p",pod_template_hash=""})) / sum by (node) (kube_node_status_allocatable{project="prj-promoplat-p",resource="pods"}) * 100 > 90
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Node {{ $labels.node }} is out of pod capacity\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Node out of pod capacity (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: ed1db196-e60e-4b94-8115-3942442ae523
          title: KubernetesContainerOomKiller | Warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: (kube_pod_container_status_restarts_total{project="prj-promoplat-p"} - kube_pod_container_status_restarts_total{project="prj-promoplat-p"} offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{project="prj-promoplat-p",reason="OOMKilled"}[10m]) == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Container oom killer (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: a7ca33db-5dd8-4928-aa54-a11b256cd79f
          title: KubernetesJobFailed | Warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: (kube_job_status_failed{job="kube-state-metrics",namespace="prod",project="prj-promoplat-p"}) > 0
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes Job failed (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: eb475cff-9bf0-4bdf-baf3-f5dcb1922048
          title: KubernetesCronjobSuspended | Warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_cronjob_spec_suspend{job="kube-state-metrics",namespace="prod",project="prj-promoplat-p"} != 0
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"CronJob {{ $labels.namespace }}/{{ $labels.cronjob }} is suspended\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes CronJob suspended (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: db5f5e49-95fe-4d26-acd6-42a43886d73d
          title: KubernetesPersistentvolumeclaimPending | Warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_persistentvolumeclaim_status_phase{job="kube-state-metrics",phase="Pending",project="prj-promoplat-p"} == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes PersistentVolumeClaim pending (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: ef15a82b-1c5e-4f31-84d0-bf4c0ab34d83
          title: KubernetesPersistentvolumeError | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_persistentvolume_status_phase{phase=~"Failed|Pending", job="kube-state-metrics",project="prj-promoplat-p"} > 0
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Persistent volume {{ $labels.persistentvolume }} is in bad state\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes PersistentVolume error (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: f03ec15d-fc3b-463d-96b6-665e76fb4ae3
          title: KubernetesStatefulsetDown | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: (kube_statefulset_replicas{job="kube-state-metrics", project="prj-promoplat-p"} != kube_statefulset_status_replicas_ready{job="kube-state-metrics", project="prj-promoplat-p"}) > 0
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} went down\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes StatefulSet down (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: c37abb31-a533-4e7d-bd0f-7e4a2335da6d
          title: KubernetesHpaMetricsUnavailability | Warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_horizontalpodautoscaler_status_condition{job="kube-state-metrics",project="prj-promoplat-p" ,status="false", condition="ScalingActive"} == 1
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler }} is unable to collect metrics\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes HPA metrics unavailability (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: d565a3ba-3d4d-4c1a-b39f-98878b4c367e
          title: PodEvictionAlert | Critical
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: kube_pod_status_reason{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active",job="kube-state-metrics",namespace="prod",project="prj-promoplat-p",reason="Evicted"} >0
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: PodEviction
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: PodEviction
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: PodEviction
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"Pod {{ $labels.namespace }}/{{ $labels.pod }} was evicted."'
            summary: '"Pod Evicted"'
          labels:
            metric: optimus
          isPaused: false
        - uid: c9c6db56-ac00-45f5-86ae-98848dfa7c82
          title: KubeCronJobPodNotReady | Critical
          condition: Threshold
          data:
            - refId: KubeCronJobPodNotReady
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: (sum by (namespace)(kube_pod_status_phase{project="prj-promoplat-p",job="kube-state-metrics",pod=~".*job.*", phase=~"Pending|Unknown|Failed"})-sum by (namespace)(kube_pod_status_phase{project="prj-promoplat-p",job="kube-state-metrics",pod=~".*job.*", phase=~"Pending|Unknown|Failed"}offset 10m)) > 0
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: KubeCronJobPodNotReady
            - refId: Last Value
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: KubeCronJobPodNotReady
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: Last Value
                type: reduce
            - refId: Threshold
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: Last Value
                intervalMs: 1000
                maxDataPoints: 43200
                refId: Threshold
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 15m
          annotations:
            description: '"CronJob Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-running state for longer than 15 minutes.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: |-
                Kubernetes CronJob Pod not healthy (instance {{ $labels.instance }})
                Check the related Job and assure if the next execution of pod got successful, notify related team on failed instance for analysis purpose.

                if it's repeated failure on next pods as well, check of error and involve respective team.
          labels:
            metric: optimus
          isPaused: false
    - orgId: 1
      name: Kubernetes Cluster Events_1m
      folder: Optimus
      interval: 1m
      rules:
        - uid: e656bfd3-b2ad-4183-ab92-926360b41a39
          title: KubernetesPodRestarts | Warning
          condition: C
          data:
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: code
                expr: increase(kube_pod_container_status_restarts_total{job="kube-state-metrics",project="prj-promoplat-p"}[$__range]) > 3
                instant: true
                intervalMs: 3.6e+06
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: B
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: A
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            description: '"Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"'
            summary: Kubernetes pod crash looping (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
    - orgId: 1
      name: NRE-Client
      folder: Optimus
      interval: 2m
      rules:
        - uid: f408b23f-a029-4b84-801d-a18b47589d78
          title: NRE | High Latency Requests | west | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: instant
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: "count(count_over_time({app=\"nre-client\", namespace=\"prod\", project=\"prj-promoplat-p\", region=~\"us-west.+\"} \r\n|= \"http_response_time\"\r\n!= `oauth_internal=yes`\r\n!= `GALO_HYDRATOR`\r\n!= `warmup_service`\r\n!= `user-agent=curl`\r\n!= `user-agent=Postman`\r\n| pattern `<_> http_response_time=<latency>ms` \r\n| __error__=\"\"\r\n| latency >= 1000\r\n[$__range]))"
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: instant
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: High latency was observed in nre-client service (> 1 second )  requests in the Optimus-West environment.
            summary: High latency was observed in nre-client service (> 1 second )  requests in the Optimus-West environment.
          labels:
            metric: optimus
          isPaused: false
        - uid: b09b4413-a0e5-4f73-a6b4-e4bb56124542
          title: NRE | High Latency Requests | east | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: "count(count_over_time({app=\"nre-client\", namespace=\"prod\", project=\"prj-promoplat-p\", region=~\"us-east.+\"} \r\n|= \"http_response_time\"\r\n!= `oauth_internal=yes`\r\n!= `GALO_HYDRATOR`\r\n!= `warmup_service`\r\n!= `user-agent=curl`\r\n!= `user-agent=Postman`\r\n| pattern `<_> http_response_time=<latency>ms` \r\n| latency >= 1000\r\n| __error__=\"\"\r\n[$__range]))"
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            description: This alert is triggered when the latency of 5 requests to the nre-client service in the East Prod environment exceeds the threshold of 1 second.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High latency was observed in nre-client service (> 1 second )  requests in the Optimus-East environment.
          labels:
            metric: optimus
          isPaused: false
        - uid: d9621459-1cd8-49d1-8254-a9b03743c350
          title: NRE | High number of HTTP 5xx errors | west | Prod |P1
          condition: C
          data:
            - refId: A
              queryType: instant
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: count(count_over_time({app="nre-client",project="prj-promoplat-p",region=~"us-west.+",source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ ".*health.*"[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: instant
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: High rate of 5xx status codes > 5 in last 5 mins
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            metric: optimus
          isPaused: false
        - uid: e8c80b05-de2a-46fd-85c9-97bf29f7f5fb
          title: NRE | High number of HTTP 5xx errors | East | Prod |P1
          condition: C
          data:
            - refId: A
              queryType: instant
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: count(count_over_time({app="nre-client",project="prj-promoplat-p",region=~"us-east.+",source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ ".*health.*"[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: instant
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: High rate of 5xx status codes > 5 in last 5 mins
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            metric: optimus
          isPaused: false
    - orgId: 1
      name: NRE-Hydrator
      folder: Optimus
      interval: 5m
      rules:
        - uid: b7b6557b-e1e9-4a74-a9e0-89aad31af195
          title: Optimus | NRE-Hydrator | Exception | P3
          condition: B
          data:
            - refId: A
              queryType: instant
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: sum(count_over_time({app="nre-hydrator", namespace="prod", project="prj-promoplat-p", source_type="kubernetes_logs"} !~ "Bucket not found for bucketId" |~ "Partner not found for partnerName|Bucket config not found for partner|Failed to parse file|Invalid offer data" [24h]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: instant
                refId: A
            - refId: B
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: threshold
          dashboardUid: e85ddf84-e8da-4b3b-8bb2-8a37149eec00
          panelId: 7
          noDataState: OK
          execErrState: Error
          for: 1d
          annotations:
            __dashboardUid__: e85ddf84-e8da-4b3b-8bb2-8a37149eec00
            __panelId__: "7"
            Grafana Query: https://grafana.corp.quotient.com/goto/ctYdYTQSg?orgId=1
            description: Exception observed in the logs for the nre-hydrator service. Please contact Ashwini Kumar, PenPeng Li, and the NRE team for assistance."
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: Exception Observed in logs for nre-hydrator Service.
          labels:
            application: nre-hydrator
            metric: nre
          isPaused: false
        - uid: b26b727b-4340-4a46-a757-cae823f06715
          title: Optimus | NRE-Hydrator | Hydration Failed
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 172800
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: code
                expr: sum(increase(populate_recommendation_success_total{app="nre-hydrator", cluster="gke-riq-usest4-prod-active", filePath=~".*", filePath!~"Delhaize/ItemToItemCF_Jaccard.csv|Hannaford/CREItemToItemCF_TW_WithRecoFC.csv|Hannaford/CREofferScores2Python.csv|Hyvee RiQ/CREofferScores2Spark.csv", job="kubernetes-pods", kubernetes_namespace="prod", partnerId=~".*", project="prj-promoplat-p"}[$__range])) by (filePath)
                instant: false
                interval: ""
                intervalMs: 3.6e+06
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 172800
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 172800
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: e85ddf84-e8da-4b3b-8bb2-8a37149eec00
          panelId: 6
          noDataState: OK
          execErrState: Error
          for: 12h
          annotations:
            __dashboardUid__: e85ddf84-e8da-4b3b-8bb2-8a37149eec00
            __panelId__: "6"
            Grafana Query: https://grafana.corp.quotient.com/goto/rypZqhQSg?orgId=1
            description: This alert is triggered when nre-hydration fails to occur or if there is any issue with a specific file in the nre-hydrator Prod environment within the past 24 hours."
            summary: |-
                Service: nre-hydrator
                Environment: Optimus
                Issue: Hydration Failed
          labels:
            application: nre-hydrator
            metric: nre
          isPaused: false
    - orgId: 1
      name: Optimus_DLQ
      folder: Optimus
      interval: 1m
      rules:
        - uid: e475edee-00a0-46f4-95fd-417957c47300
          title: optimus-prod-west-pubsub-dlq-count
          condition: DLQThreshold
          data:
            - refId: DLQCount
              queryType: timeSeriesQuery
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: db1ba123-6a88-4e2b-8389-d1fe326058e7
              model:
                datasource:
                    type: stackdriver
                    uid: db1ba123-6a88-4e2b-8389-d1fe326058e7
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: timeSeriesQuery
                refId: DLQCount
                timeSeriesList:
                    alignmentPeriod: cloud-monitoring-auto
                    crossSeriesReducer: REDUCE_NONE
                    filters: []
                    groupBys: []
                    perSeriesAligner: ALIGN_MEAN
                    projectName: prj-promoplat-p
                timeSeriesQuery:
                    graphPeriod: disabled
                    projectName: prj-promoplat-p
                    query: |-
                        fetch pubsub_subscription
                        | metric 'pubsub.googleapis.com/subscription/dead_letter_message_count'
                        | filter (resource.subscription_id == 'S.CPA_OFFER_EVENT_WEST')
                        | group_by 1m, [row_count: row_count()]
                        | every 1m
                        | group_by [resource.subscription_id],
                            [row_count_aggregate: aggregate(row_count)]
            - refId: DLQLastCount
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: DLQCount
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: DLQLastCount
                type: reduce
            - refId: DLQThreshold
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: DLQLastCount
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: DLQThreshold
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 1m
          annotations:
            description: S.CPA_OFFER_EVENT_WEST Subscription has sent a message to DeadLetter Topic.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/14941028756/Runbook+for+CPA+Offer+Event+Dead+Letter+Queue+Publish+Alert
          labels:
            metric: optimus
          isPaused: false
        - uid: f8f44c65-cf65-4608-853d-b0ca1fb07a98
          title: optimus-prod-east-pubsub-dlq-count
          condition: DLQThreshold
          data:
            - refId: DLQCount
              queryType: timeSeriesQuery
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: db1ba123-6a88-4e2b-8389-d1fe326058e7
              model:
                datasource:
                    type: stackdriver
                    uid: db1ba123-6a88-4e2b-8389-d1fe326058e7
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: timeSeriesQuery
                refId: DLQCount
                timeSeriesList:
                    alignmentPeriod: cloud-monitoring-auto
                    crossSeriesReducer: REDUCE_NONE
                    filters: []
                    groupBys: []
                    perSeriesAligner: ALIGN_MEAN
                    projectName: prj-promoplat-p
                timeSeriesQuery:
                    graphPeriod: disabled
                    projectName: prj-promoplat-p
                    query: |-
                        fetch pubsub_subscription
                        | metric 'pubsub.googleapis.com/subscription/dead_letter_message_count'
                        | filter (resource.subscription_id == 'S.CPA_OFFER_EVENT_EAST')
                        | group_by 1m, [row_count: row_count()]
                        | every 1m
                        | group_by [resource.subscription_id],
                            [row_count_aggregate: aggregate(row_count)]
            - refId: DLQLastCount
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: DLQCount
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: DLQLastCount
                type: reduce
            - refId: DLQThreshold
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: DLQLastCount
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: DLQThreshold
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 1m
          annotations:
            description: S.CPA_OFFER_EVENT_EAST Subscription has sent a message to DeadLetter Topic.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/14941028756/Runbook+for+CPA+Offer+Event+Dead+Letter+Queue+Publish+Alert
          labels:
            metric: optimus
          isPaused: false
    - orgId: 1
      name: Optimus_Undelivered_Messages_Pileup
      folder: Optimus
      interval: 2m
      rules:
        - uid: fdbbaaf0-5fdb-43d6-bf3b-210134359e99
          title: Unacked Message Pileup  | S.ACTIVATE_OFFER.CPR_INT_DLQ | WEST | PROD | Warning
          condition: C
          data:
            - refId: A
              queryType: timeSeriesQuery
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: db1ba123-6a88-4e2b-8389-d1fe326058e7
              model:
                datasource:
                    type: stackdriver
                    uid: db1ba123-6a88-4e2b-8389-d1fe326058e7
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: timeSeriesQuery
                refId: A
                timeSeriesList:
                    alignmentPeriod: cloud-monitoring-auto
                    crossSeriesReducer: REDUCE_NONE
                    filters: []
                    groupBys: []
                    perSeriesAligner: ALIGN_MEAN
                    projectName: prj-devops-p
                timeSeriesQuery:
                    graphPeriod: 1m
                    projectName: prj-promoplat-p
                    query: |-
                        fetch pubsub_subscription
                        | metric 'pubsub.googleapis.com/subscription/num_unacked_messages_by_region'
                        | filter
                            resource.project_id == 'prj-promoplat-p'
                            &&region == 'us-west1'
                            && resource.subscription_id == 'S.ACTIVATE_OFFER.CPR_INT_DLQ'
                        | group_by 1m,
            - refId: Message_Pileup_Count
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: Message_Pileup_Count
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: Message_Pileup_Count
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: b5b207e2-74ee-4e08-b926-8715fe47f972
          panelId: 7
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            __dashboardUid__: b5b207e2-74ee-4e08-b926-8715fe47f972
            __panelId__: "7"
            GCP Console Link - Dashboard: https://console.cloud.google.com/cloudpubsub/subscription/detail/S.ACTIVATE_OFFER.CPR_INT_DLQ?project=prj-promoplat-p
            description: The number of unacked messages in the S.ACTIVATE_OFFER.CPR_INT_DLQ subscription has exceeded 10 in the last minute. This could indicate potential issues with message processing or delivery. Immediate investigation is required to ensure that messages are being processed in a timely manner
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/15312879644/Runbook+for+Optimus+alerts+-+Pubsub+version
            summary: 'More than 10 unacknowledged messages in subscription (Last 2 minutes): S.ACTIVATE_OFFER.CPR_INT_DLQ"'
          labels:
            metric: optimus
          isPaused: false
        - uid: a1fa1dc6-1e6d-474b-9501-dd3a6864d013
          title: Unacked Message Pileup  | S.ACTIVATE_OFFER.CPR_INT_DLQ | EAST | PROD | Warning
          condition: C
          data:
            - refId: A
              queryType: timeSeriesQuery
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: db1ba123-6a88-4e2b-8389-d1fe326058e7
              model:
                datasource:
                    type: stackdriver
                    uid: db1ba123-6a88-4e2b-8389-d1fe326058e7
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: timeSeriesQuery
                refId: A
                timeSeriesList:
                    alignmentPeriod: cloud-monitoring-auto
                    crossSeriesReducer: REDUCE_NONE
                    filters: []
                    groupBys: []
                    perSeriesAligner: ALIGN_MEAN
                    projectName: prj-devops-p
                timeSeriesQuery:
                    graphPeriod: 1m
                    projectName: prj-promoplat-p
                    query: |-
                        fetch pubsub_subscription
                        | metric 'pubsub.googleapis.com/subscription/num_unacked_messages_by_region'
                        | filter
                            resource.project_id == 'prj-promoplat-p'
                            && region == 'us-east4'
                            && resource.subscription_id == 'S.ACTIVATE_OFFER.CPR_INT_DLQ'
                        | group_by 1m,
            - refId: Message_Pileup_Count
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: Message_Pileup_Count
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: Message_Pileup_Count
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: b5b207e2-74ee-4e08-b926-8715fe47f972
          panelId: 7
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            __dashboardUid__: b5b207e2-74ee-4e08-b926-8715fe47f972
            __panelId__: "7"
            GCP Console Link - Dashboard: https://console.cloud.google.com/cloudpubsub/subscription/detail/S.ACTIVATE_OFFER.CPR_INT_DLQ?project=prj-promoplat-p
            description: The number of unacked messages in the S.ACTIVATE_OFFER.CPR_INT_DLQ subscription has exceeded 10 in the last minute. This could indicate potential issues with message processing or delivery. Immediate investigation is required to ensure that messages are being processed in a timely manner
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/15312879644/Runbook+for+Optimus+alerts+-+Pubsub+version
            summary: 'More than 10 unacknowledged messages in subscription (Last 2 minutes): S.ACTIVATE_OFFER.CPR_INT_DLQ"'
          labels:
            metric: optimus
          isPaused: false
        - uid: feca7cf8-a4ca-4720-bb70-e1de8a713dd9
          title: Unacked Message Pileup  | S.REDEEM_OFFER.CPR_INT_DLQ | EAST | PROD | Warning
          condition: C
          data:
            - refId: A
              queryType: timeSeriesQuery
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: db1ba123-6a88-4e2b-8389-d1fe326058e7
              model:
                datasource:
                    type: stackdriver
                    uid: db1ba123-6a88-4e2b-8389-d1fe326058e7
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: timeSeriesQuery
                refId: A
                timeSeriesList:
                    alignmentPeriod: cloud-monitoring-auto
                    crossSeriesReducer: REDUCE_NONE
                    filters: []
                    groupBys: []
                    perSeriesAligner: ALIGN_MEAN
                    projectName: prj-devops-p
                timeSeriesQuery:
                    graphPeriod: 1m
                    projectName: prj-promoplat-p
                    query: |-
                        fetch pubsub_subscription
                        | metric 'pubsub.googleapis.com/subscription/num_unacked_messages_by_region'
                        | filter
                            resource.project_id == 'prj-promoplat-p'
                            && region == 'us-east4'
                            && resource.subscription_id == 'S.REDEEM_OFFER.CPR_INT_DLQ'
                        | group_by 1m,
            - refId: Message_Pileup_Count
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: Message_Pileup_Count
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: Message_Pileup_Count
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: b5b207e2-74ee-4e08-b926-8715fe47f972
          panelId: 7
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            __dashboardUid__: b5b207e2-74ee-4e08-b926-8715fe47f972
            __panelId__: "7"
            GCP Console Link - Dashboard: https://console.cloud.google.com/cloudpubsub/subscription/detail/S.REDEEM_OFFER.CPR_INT_DLQ?project=prj-promoplat-p
            description: The number of unacked messages in the S.REDEEM_OFFER.CPR_INT_DLQ subscription has exceeded 10 in the last minute. This could indicate potential issues with message processing or delivery. Immediate investigation is required to ensure that messages are being processed in a timely manner
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/15312879644/Runbook+for+Optimus+alerts+-+Pubsub+version
            summary: 'More than 10 unacknowledged messages in subscription (Last 2 minutes): S.REDEEM_OFFER.CPR_INT_DLQ"'
          labels:
            metric: optimus
          isPaused: false
        - uid: c5e33aa7-7b63-4539-92a0-3ae6c2e340d3
          title: Unacked Message Pileup  | S.REDEEM_OFFER.CPR_INT_DLQ | WEST | PROD | Warning
          condition: C
          data:
            - refId: A
              queryType: timeSeriesQuery
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: db1ba123-6a88-4e2b-8389-d1fe326058e7
              model:
                datasource:
                    type: stackdriver
                    uid: db1ba123-6a88-4e2b-8389-d1fe326058e7
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: timeSeriesQuery
                refId: A
                timeSeriesList:
                    alignmentPeriod: cloud-monitoring-auto
                    crossSeriesReducer: REDUCE_NONE
                    filters: []
                    groupBys: []
                    perSeriesAligner: ALIGN_MEAN
                    projectName: prj-devops-p
                timeSeriesQuery:
                    graphPeriod: 1m
                    projectName: prj-promoplat-p
                    query: |-
                        fetch pubsub_subscription
                        | metric 'pubsub.googleapis.com/subscription/num_unacked_messages_by_region'
                        | filter
                            resource.project_id == 'prj-promoplat-p'
                            &&region == 'us-west1'
                            && resource.subscription_id == 'S.REDEEM_OFFER.CPR_INT_DLQ'
                        | group_by 1m
            - refId: Message_Pileup_Count
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: Message_Pileup_Count
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: Message_Pileup_Count
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: b5b207e2-74ee-4e08-b926-8715fe47f972
          panelId: 7
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            __dashboardUid__: b5b207e2-74ee-4e08-b926-8715fe47f972
            __panelId__: "7"
            GCP Console Link - Dashboard: https://console.cloud.google.com/cloudpubsub/subscription/detail/S.REDEEM_OFFER.CPR_INT_DLQ?project=prj-promoplat-p
            description: The number of unacked messages in the S.REDEEM_OFFER.CPR_INT_DLQ subscription has exceeded 10 in the last minute. This could indicate potential issues with message processing or delivery. Immediate investigation is required to ensure that messages are being processed in a timely manner
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/15312879644/Runbook+for+Optimus+alerts+-+Pubsub+version
            summary: 'More than 10 unacknowledged messages in subscription (Last 2 minutes): S.REDEEM_OFFER.CPR_INT_DLQ"'
          labels:
            metric: optimus
          isPaused: false
        - uid: ce45db52-4fec-4931-b8e8-bae3c869c228
          title: Unacked Message Pileup  | S.ACTIVATE_OFFER.INMAR_DLQ | EAST | PROD | Warning
          condition: C
          data:
            - refId: A
              queryType: timeSeriesQuery
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: db1ba123-6a88-4e2b-8389-d1fe326058e7
              model:
                datasource:
                    type: stackdriver
                    uid: db1ba123-6a88-4e2b-8389-d1fe326058e7
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: timeSeriesQuery
                refId: A
                timeSeriesList:
                    alignmentPeriod: cloud-monitoring-auto
                    crossSeriesReducer: REDUCE_NONE
                    filters: []
                    groupBys: []
                    perSeriesAligner: ALIGN_MEAN
                    projectName: prj-devops-p
                timeSeriesQuery:
                    graphPeriod: 1m
                    projectName: prj-promoplat-p
                    query: |-
                        fetch pubsub_subscription
                        | metric 'pubsub.googleapis.com/subscription/num_unacked_messages_by_region'
                        | filter
                            resource.project_id == 'prj-promoplat-p'
                            && region == 'us-east4'
                            && resource.subscription_id == 'S.ACTIVATE_OFFER.INMAR_DLQ'
                        | group_by 1m,
            - refId: Message_Pileup_Count
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: Message_Pileup_Count
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: Message_Pileup_Count
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: b5b207e2-74ee-4e08-b926-8715fe47f972
          panelId: 7
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            __dashboardUid__: b5b207e2-74ee-4e08-b926-8715fe47f972
            __panelId__: "7"
            GCP Console Link - Dashboard: https://console.cloud.google.com/cloudpubsub/subscription/detail/S.ACTIVATE_OFFER.INMAR_DLQ?project=prj-promoplat-p
            description: The number of unacked messages in the S.ACTIVATE_OFFER.INMAR_DLQ subscription has exceeded 10 in the last minute. This could indicate potential issues with message processing or delivery. Immediate investigation is required to ensure that messages are being processed in a timely manner
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/15312879644/Runbook+for+Optimus+alerts+-+Pubsub+version
            summary: 'More than 10 unacknowledged messages in subscription (Last 2 minutes): S.ACTIVATE_OFFER.INMAR_DLQ"'
          labels:
            metric: optimus
          isPaused: false
        - uid: d9786cd0-4432-482a-bc62-62fd0b49e5fc
          title: Unacked Message Pileup  | S.ACTIVATE_OFFER.INMAR_DLQ | WEST | PROD | Warning
          condition: C
          data:
            - refId: A
              queryType: timeSeriesQuery
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: db1ba123-6a88-4e2b-8389-d1fe326058e7
              model:
                datasource:
                    type: stackdriver
                    uid: db1ba123-6a88-4e2b-8389-d1fe326058e7
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: timeSeriesQuery
                refId: A
                timeSeriesList:
                    alignmentPeriod: cloud-monitoring-auto
                    crossSeriesReducer: REDUCE_NONE
                    filters: []
                    groupBys: []
                    perSeriesAligner: ALIGN_MEAN
                    projectName: prj-devops-p
                timeSeriesQuery:
                    graphPeriod: 1m
                    projectName: prj-promoplat-p
                    query: |-
                        fetch pubsub_subscription
                        | metric 'pubsub.googleapis.com/subscription/num_unacked_messages_by_region'
                        | filter
                            resource.project_id == 'prj-promoplat-p'
                            &&region == 'us-west1'
                            && resource.subscription_id == 'S.ACTIVATE_OFFER.INMAR_DLQ'
                        | group_by 1m,
            - refId: Message_Pileup_Count
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: Message_Pileup_Count
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: Message_Pileup_Count
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: b5b207e2-74ee-4e08-b926-8715fe47f972
          panelId: 7
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            __dashboardUid__: b5b207e2-74ee-4e08-b926-8715fe47f972
            __panelId__: "7"
            GCP Console Link - Dashboard: https://console.cloud.google.com/cloudpubsub/subscription/detail/S.ACTIVATE_OFFER.INMAR_DLQ?project=prj-promoplat-p
            description: The number of unacked messages in the S.ACTIVATE_OFFER.INMAR_DLQ subscription has exceeded 10 in the last minute. This could indicate potential issues with message processing or delivery. Immediate investigation is required to ensure that messages are being processed in a timely manner
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/15312879644/Runbook+for+Optimus+alerts+-+Pubsub+version
            summary: 'More than 10 unacknowledged messages in subscription (Last 2 minutes): S.ACTIVATE_OFFER.INMAR_DLQ"'
          labels:
            metric: optimus
          isPaused: false
        - uid: ad37eb2a-a7df-4934-8451-f36dd49df616
          title: Unacked Message Pileup  | S.REDEEM_OFFER.INMAR_DLQ | EAST | PROD | Warning
          condition: C
          data:
            - refId: A
              queryType: timeSeriesQuery
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: db1ba123-6a88-4e2b-8389-d1fe326058e7
              model:
                datasource:
                    type: stackdriver
                    uid: db1ba123-6a88-4e2b-8389-d1fe326058e7
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: timeSeriesQuery
                refId: A
                timeSeriesList:
                    alignmentPeriod: cloud-monitoring-auto
                    crossSeriesReducer: REDUCE_NONE
                    filters: []
                    groupBys: []
                    perSeriesAligner: ALIGN_MEAN
                    projectName: prj-devops-p
                timeSeriesQuery:
                    graphPeriod: 1m
                    projectName: prj-promoplat-p
                    query: |-
                        fetch pubsub_subscription
                        | metric 'pubsub.googleapis.com/subscription/num_unacked_messages_by_region'
                        | filter
                            resource.project_id == 'prj-promoplat-p'
                            && region == 'us-east4'
                            && resource.subscription_id == 'S.REDEEM_OFFER.INMAR_DLQ'
                        | group_by 1m,
            - refId: Message_Pileup_Count
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: Message_Pileup_Count
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: Message_Pileup_Count
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: b5b207e2-74ee-4e08-b926-8715fe47f972
          panelId: 7
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            __dashboardUid__: b5b207e2-74ee-4e08-b926-8715fe47f972
            __panelId__: "7"
            GCP Console Link - Dashboard: https://console.cloud.google.com/cloudpubsub/subscription/detail/S.REDEEM_OFFER.INMAR_DLQ?project=prj-promoplat-p
            description: The number of unacked messages in the S.REDEEM_OFFER.INMAR_DLQ subscription has exceeded 10 in the last minute. This could indicate potential issues with message processing or delivery. Immediate investigation is required to ensure that messages are being processed in a timely manner
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/15312879644/Runbook+for+Optimus+alerts+-+Pubsub+version
            summary: 'More than 10 unacknowledged messages in subscription (Last 2 minutes): S.REDEEM_OFFER.INMAR_DLQ"'
          labels:
            metric: optimus
          isPaused: false
        - uid: e3755718-39e0-4844-ba2c-c2f88790ecfe
          title: Unacked Message Pileup  | S.REDEEM_OFFER.INMAR_DLQ | WEST | PROD | Warning
          condition: C
          data:
            - refId: A
              queryType: timeSeriesQuery
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: db1ba123-6a88-4e2b-8389-d1fe326058e7
              model:
                datasource:
                    type: stackdriver
                    uid: db1ba123-6a88-4e2b-8389-d1fe326058e7
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: timeSeriesQuery
                refId: A
                timeSeriesList:
                    alignmentPeriod: cloud-monitoring-auto
                    crossSeriesReducer: REDUCE_NONE
                    filters: []
                    groupBys: []
                    perSeriesAligner: ALIGN_MEAN
                    projectName: prj-devops-p
                timeSeriesQuery:
                    graphPeriod: 1m
                    projectName: prj-promoplat-p
                    query: |-
                        fetch pubsub_subscription
                        | metric 'pubsub.googleapis.com/subscription/num_unacked_messages_by_region'
                        | filter
                            resource.project_id == 'prj-promoplat-p'
                            &&region == 'us-west1'
                            && resource.subscription_id == 'S.REDEEM_OFFER.INMAR_DLQ'
                        | group_by 1m
            - refId: Message_Pileup_Count
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: Message_Pileup_Count
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: Message_Pileup_Count
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: b5b207e2-74ee-4e08-b926-8715fe47f972
          panelId: 7
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            __dashboardUid__: b5b207e2-74ee-4e08-b926-8715fe47f972
            __panelId__: "7"
            GCP Console Link - Dashboard: https://console.cloud.google.com/cloudpubsub/subscription/detail/S.REDEEM_OFFER.INMAR_DLQ?project=prj-promoplat-p
            description: The number of unacked messages in the S.REDEEM_OFFER.INMAR_DLQ subscription has exceeded 10 in the last minute. This could indicate potential issues with message processing or delivery. Immediate investigation is required to ensure that messages are being processed in a timely manner
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/15312879644/Runbook+for+Optimus+alerts+-+Pubsub+version
            summary: 'More than 10 unacknowledged messages in subscription (Last 2 minutes): S.REDEEM_OFFER.INMAR_DLQ"'
          labels:
            metric: optimus
          isPaused: false
        - uid: b5b1010b-a38f-4a42-8e0f-7f70fe73e54e
          title: Unacked Message Pileup  | S.ACTIVATE_OFFER.PARTNER_INT_DLQ | WEST | PROD | Warning
          condition: C
          data:
            - refId: A
              queryType: timeSeriesQuery
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: db1ba123-6a88-4e2b-8389-d1fe326058e7
              model:
                datasource:
                    type: stackdriver
                    uid: db1ba123-6a88-4e2b-8389-d1fe326058e7
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: timeSeriesQuery
                refId: A
                timeSeriesList:
                    alignmentPeriod: cloud-monitoring-auto
                    crossSeriesReducer: REDUCE_NONE
                    filters: []
                    groupBys: []
                    perSeriesAligner: ALIGN_MEAN
                    projectName: prj-devops-p
                timeSeriesQuery:
                    graphPeriod: 1m
                    projectName: prj-promoplat-p
                    query: |-
                        fetch pubsub_subscription
                        | metric 'pubsub.googleapis.com/subscription/num_unacked_messages_by_region'
                        | filter
                            resource.project_id == 'prj-promoplat-p'
                            &&region == 'us-west1'
                            && resource.subscription_id == 'S.ACTIVATE_OFFER.PARTNER_INT_DLQ'
                        | group_by 1m,
            - refId: Message_Pileup_Count
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: Message_Pileup_Count
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: Message_Pileup_Count
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: b5b207e2-74ee-4e08-b926-8715fe47f972
          panelId: 7
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            __dashboardUid__: b5b207e2-74ee-4e08-b926-8715fe47f972
            __panelId__: "7"
            GCP Console Link - Dashboard: https://console.cloud.google.com/cloudpubsub/subscription/detail/S.ACTIVATE_OFFER.PARTNER_INT_DLQ?project=prj-promoplat-p
            description: The number of unacked messages in the S.ACTIVATE_OFFER.PARTNER_INT_DLQ subscription has exceeded 10 in the last minute. This could indicate potential issues with message processing or delivery. Immediate investigation is required to ensure that messages are being processed in a timely manner
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/15312879644/Runbook+for+Optimus+alerts+-+Pubsub+version
            summary: 'More than 10 unacknowledged messages in subscription (Last 2 minutes): S.ACTIVATE_OFFER.PARTNER_INT_DLQ"'
          labels:
            metric: optimus
          isPaused: false
        - uid: fd51d915-ecd8-4c79-941d-7d401fac8ad4
          title: Unacked Message Pileup | S.ACTIVATE_OFFER.PARTNER_INT_DLQ | EAST | PROD | Warning
          condition: C
          data:
            - refId: A
              queryType: timeSeriesQuery
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: db1ba123-6a88-4e2b-8389-d1fe326058e7
              model:
                datasource:
                    type: stackdriver
                    uid: db1ba123-6a88-4e2b-8389-d1fe326058e7
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: timeSeriesQuery
                refId: A
                timeSeriesList:
                    alignmentPeriod: cloud-monitoring-auto
                    crossSeriesReducer: REDUCE_NONE
                    filters: []
                    groupBys: []
                    perSeriesAligner: ALIGN_MEAN
                    projectName: prj-devops-p
                timeSeriesQuery:
                    graphPeriod: 1m
                    projectName: prj-promoplat-p
                    query: |-
                        fetch pubsub_subscription
                        | metric 'pubsub.googleapis.com/subscription/num_unacked_messages_by_region'
                        | filter
                            resource.project_id == 'prj-promoplat-p'
                            && region == 'us-east4'
                            && resource.subscription_id == 'S.ACTIVATE_OFFER.PARTNER_INT_DLQ'
                        | group_by 1m,
            - refId: Message_Pileup_Count
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: Message_Pileup_Count
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: Message_Pileup_Count
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: b5b207e2-74ee-4e08-b926-8715fe47f972
          panelId: 7
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            __dashboardUid__: b5b207e2-74ee-4e08-b926-8715fe47f972
            __panelId__: "7"
            GCP Console Link - Dashboard: https://console.cloud.google.com/cloudpubsub/subscription/detail/S.ACTIVATE_OFFER.PARTNER_INT_DLQ?project=prj-promoplat-p
            description: The number of unacked messages in the S.ACTIVATE_OFFER.PARTNER_INT_DLQ subscription has exceeded 10 in the last minute. This could indicate potential issues with message processing or delivery. Immediate investigation is required to ensure that messages are being processed in a timely manner
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/15312879644/Runbook+for+Optimus+alerts+-+Pubsub+version
            summary: 'More than 10 unacknowledged messages in subscription (Last 2 minutes): S.ACTIVATE_OFFER.PARTNER_INT_DLQ"'
          labels:
            metric: optimus
          isPaused: false
        - uid: d20e339c-3331-4ce7-a7f8-7a9055d40243
          title: Unacked Message Pileup  | S.REDEEM_OFFER.PARTNER_INT_DLQ | EAST | PROD | Warning
          condition: C
          data:
            - refId: A
              queryType: timeSeriesQuery
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: db1ba123-6a88-4e2b-8389-d1fe326058e7
              model:
                datasource:
                    type: stackdriver
                    uid: db1ba123-6a88-4e2b-8389-d1fe326058e7
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: timeSeriesQuery
                refId: A
                timeSeriesList:
                    alignmentPeriod: cloud-monitoring-auto
                    crossSeriesReducer: REDUCE_NONE
                    filters: []
                    groupBys: []
                    perSeriesAligner: ALIGN_MEAN
                    projectName: prj-devops-p
                timeSeriesQuery:
                    graphPeriod: 1m
                    projectName: prj-promoplat-p
                    query: |-
                        fetch pubsub_subscription
                        | metric 'pubsub.googleapis.com/subscription/num_unacked_messages_by_region'
                        | filter
                            resource.project_id == 'prj-promoplat-p'
                            && region == 'us-east4'
                            && resource.subscription_id == 'S.REDEEM_OFFER.PARTNER_INT_DLQ'
                        | group_by 1m,
            - refId: Message_Pileup_Count
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: Message_Pileup_Count
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: Message_Pileup_Count
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: b5b207e2-74ee-4e08-b926-8715fe47f972
          panelId: 7
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            __dashboardUid__: b5b207e2-74ee-4e08-b926-8715fe47f972
            __panelId__: "7"
            GCP Console Link - Dashboard: https://console.cloud.google.com/cloudpubsub/subscription/detail/S.REDEEM_OFFER.PARTNER_INT_DLQ?project=prj-promoplat-p
            description: The number of unacked messages in the S.REDEEM_OFFER.PARTNER_INT_DLQ subscription has exceeded 10 in the last minute. This could indicate potential issues with message processing or delivery. Immediate investigation is required to ensure that messages are being processed in a timely manner
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/15312879644/Runbook+for+Optimus+alerts+-+Pubsub+version
            summary: 'More than 10 unacknowledged messages in subscription (Last 2 minutes): S.REDEEM_OFFER.PARTNER_INT_DLQ"'
          labels:
            metric: optimus
          isPaused: false
        - uid: d4fa342a-3aba-4699-8a17-629e4f4235b4
          title: Unacked Message Pileup  | S.REDEEM_OFFER.PARTNER_INT_DLQ | WEST | PROD | Warning
          condition: C
          data:
            - refId: A
              queryType: timeSeriesQuery
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: db1ba123-6a88-4e2b-8389-d1fe326058e7
              model:
                datasource:
                    type: stackdriver
                    uid: db1ba123-6a88-4e2b-8389-d1fe326058e7
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: timeSeriesQuery
                refId: A
                timeSeriesList:
                    alignmentPeriod: cloud-monitoring-auto
                    crossSeriesReducer: REDUCE_NONE
                    filters: []
                    groupBys: []
                    perSeriesAligner: ALIGN_MEAN
                    projectName: prj-devops-p
                timeSeriesQuery:
                    graphPeriod: 1m
                    projectName: prj-promoplat-p
                    query: |-
                        fetch pubsub_subscription
                        | metric 'pubsub.googleapis.com/subscription/num_unacked_messages_by_region'
                        | filter
                            resource.project_id == 'prj-promoplat-p'
                            &&region == 'us-west1'
                            && resource.subscription_id == 'S.REDEEM_OFFER.PARTNER_INT_DLQ'
                        | group_by 1m,
            - refId: Message_Pileup_Count
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: Message_Pileup_Count
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 120
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: Message_Pileup_Count
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: b5b207e2-74ee-4e08-b926-8715fe47f972
          panelId: 7
          noDataState: OK
          execErrState: Error
          for: 2m
          annotations:
            __dashboardUid__: b5b207e2-74ee-4e08-b926-8715fe47f972
            __panelId__: "7"
            GCP Console Link - Dashboard: https://console.cloud.google.com/cloudpubsub/subscription/detail/S.REDEEM_OFFER.PARTNER_INT_DLQ?project=prj-promoplat-p
            description: The number of unacked messages in the S.REDEEM_OFFER.PARTNER_INT_DLQ subscription has exceeded 10 in the last minute. This could indicate potential issues with message processing or delivery. Immediate investigation is required to ensure that messages are being processed in a timely manner
            runbook_url: https://quotient.atlassian.net/wiki/spaces/ENGPROJ/pages/15312879644/Runbook+for+Optimus+alerts+-+Pubsub+version
            summary: 'More than 10 unacknowledged messages in subscription (Last 2 minutes): S.REDEEM_OFFER.PARTNER_INT_DLQ"'
          labels:
            metric: optimus
          isPaused: false
    - orgId: 1
      name: PAO
      folder: Optimus
      interval: 2m
      rules:
        - uid: dc5c253d-74dc-4377-86b5-5e639eb6e6fd
          title: PAO(post-activate-offers-ns)  | Exceptions | west | Prod | P3
          condition: A
          data:
            - refId: log_metrics_pao_Exception
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: sum(count_over_time({app="post-activate-offers-ns",cluster=~"gke-gke-riq-uswst.+-prod-active",project="prj-promoplat-p", namespace="prod"} |~".*Exception.*" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: log_metrics_pao_Exception
                step: 5m
            - refId: log_metrics__Exception_Status
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_pao_Exception
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: log_metrics__Exception_Status
                type: reduce
            - refId: A
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics__Exception_Status
                intervalMs: 1000
                maxDataPoints: 43200
                refId: A
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 5
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "5"
            Grafana Query: https://grafana.corp.quotient.com/goto/XzGXEwuSR?orgId=1
            description: Exception Observed in logs for post-activate-offers-ns Service.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: Exception Observed in logs for post-activate-offers-ns Service.
          labels:
            application: PAO
            metric: optimus
          isPaused: false
        - uid: ecca0069-e80e-4d7a-a09c-96fcede7f1d5
          title: PAO | High number of HTTP 4xx errors  | west | Prod | P3
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 3600
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="post-activate-offers-ns", namespace="prod", project="prj-promoplat-p", region=~"us-west.+", source_type="ingress_logs"} | json | message_httpRequest_status =~ `4[0-9][0-9]` | message_httpRequest_requestUrl !~ `.*health.*` | __error__=`` [5m]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: 5m
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 28
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "28"
            Grafana Query: https://grafana.corp.quotient.com/goto/6x0ZfluSR?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the client request or the API endpoint itself. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes
          labels:
            application: pao
            metric: optimus
          isPaused: false
        - uid: f1d0a132-a8ba-4d96-9c77-e802aea75fa8
          title: PAO (post-activate-offers-ns) | Exceptions | east | Prod | P3
          condition: A
          data:
            - refId: log_metrics_galo_Exception
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: sum(count_over_time({app="post-activate-offers-ns", cluster=~"gke-gke-riq-usest.+-prod-active", project="prj-promoplat-p", namespace="prod"} |~ `.*Exception.*` | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: log_metrics_galo_Exception
            - refId: log_metrics_galo_Exception_Status
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_galo_Exception
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: log_metrics_galo_Exception_Status
                type: reduce
            - refId: A
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_galo_Exception_Status
                intervalMs: 1000
                maxDataPoints: 43200
                refId: A
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 5
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "5"
            Grafana Query: https://grafana.corp.quotient.com/goto/W_CpB_XIg?orgId=1
            description: Exception Observed in logs for get-all-offers-ns Service.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: Exception Observed in logs for get-all-offers-ns Service.
          labels:
            application: pao
            metric: optimus
          isPaused: false
        - uid: d964cfdb-81c2-42eb-a5a1-fd171cfb8ebc
          title: PAO | High number of HTTP 5xx errors  | west | Prod | P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="post-activate-offers-ns", namespace="prod", project="prj-promoplat-p", region=~"us-west.+", source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ `.*health.*` | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 27
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "27"
            Grafana Query: https://grafana.corp.quotient.com/goto/uJ4FyQuSR?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: EyAHy3UVz
          title: ' PAO | High Latency Requests | west | Prod | P2'
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({project="prj-promoplat-p", namespace="prod", app="post-activate-offers-ns", region=~"us-west.+", source_type="kubernetes_logs"} |= `http_response_time=` |= `vr=1.0` != `oauth_internal=yes` != `GALO_HYDRATOR` != `warmup_service` != `user-agent=curl` != `user-agent=Postman` | pattern `nonce=<nonce> client_ip=<client_ip> - <datetime> <_> - /<endpoint>/<_> partnerId=<partnerId> <_> http_response_time=<latency>ms http_commit_response_time=<committime>ms` | latency > 1000 | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: 5m
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 26
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "26"
            Query: https://grafana.corp.quotient.com/goto/bsb8_wXIR?orgId=1
            description: This alert is triggered when the latency of 5 requests to the get-all-offers-ns service in the WEST Prod environment exceeds the threshold of 1 seconds.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High latency was observed in get-all-offers-ns service (> 1 second )  requests in the Optimus-West environment.
          labels:
            metric: optimus
          isPaused: false
        - uid: c7a33995-9260-430c-928b-439fa3710aca
          title: PAO | High number of HTTP 4xx errors  | east | Prod | P3
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="post-activate-offers-ns",namespace="prod",project="prj-promoplat-p",region=~"us-east.+",source_type="ingress_logs"} | json | message_httpRequest_status =~ "4[0-9][0-9]" | message_httpRequest_requestUrl !~ ".*health.*" | __error__=``[5m]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: ""
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 28
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "28"
            Grafana Query: https://grafana.corp.quotient.com/goto/1QyrCDQIR?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the client request or the API endpoint itself. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes
          labels:
            metric: optimus
          isPaused: false
        - uid: d86bb805-0648-4a1f-9a4b-1b7e13480823
          title: PAO | High Latency Requests | east | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({project="prj-promoplat-p", namespace="prod", app="post-activate-offers-ns", region=~"us-east.+", source_type="kubernetes_logs"} |= `http_response_time=` |= `vr=1.0` != `oauth_internal=yes` != `warmup_service` != `GALO_HYDRATOR` != `user-agent=Postman` != `user-agent=curl` | pattern `nonce=<nonce> client_ip=<client_ip> - <datetime> <_> - /<endpoint>/<_> partnerId=<partnerId> <_> http_response_time=<latency>ms http_commit_response_time=<committime>ms` | latency > 1000 | __error__=``[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 26
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "26"
            Query: https://grafana.corp.quotient.com/goto/tPD6eQXSg?orgId=1
            description: This alert is triggered when the latency of 5 requests to the get-all-offers-ns service in the East Prod environment exceeds the threshold of 1 second.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High latency was observed in get-all-offers-ns service (> 1 second )  requests in the Optimus-East environment.
          labels:
            application: PAO
            metric: optimus
          isPaused: false
        - uid: a1b218b9-f2fb-4686-b0b3-a6ceee2f276d
          title: 'PAO | POD Health Checks failed | West|  Prod | P2 '
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="post-activate-offers-ns",namespace="prod",region="us-west1",project="prj-promoplat-p",source_type="ingress_logs"} | json | message_httpRequest_status!=`200` | message_jsonPayload_statusDetails!="client_disconnected_before_any_response" | message_httpRequest_status!~ "4[0-9][0-9]" |~"/galo/actuator/health" | __error__=``[$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: sum
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 2
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: OK
          for: 2m
          annotations:
            Query: https://grafana.corp.quotient.com/goto/2wVcqvQSR?orgId=1
            description: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
          labels:
            metric: optimus
          isPaused: false
        - uid: c5013f2a-e98e-4a48-bc38-a62d9075f61a
          title: 'PAO | POD Health Checks failed | East |  Prod | P2 '
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="post-activate-offers-ns",namespace="prod",region="us-east4",project="prj-promoplat-p",source_type="ingress_logs"} | json | message_httpRequest_status!=`200` | message_jsonPayload_statusDetails!="client_disconnected_before_any_response" | message_httpRequest_status!~ "4[0-9][0-9]" |~"/galo/actuator/health" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: sum
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 2
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: OK
          for: 2m
          annotations:
            Query: https://grafana.corp.quotient.com/goto/tfXOqDQSR?orgId=1
            description: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
          labels:
            application: PAO
            metric: optimus
          isPaused: false
        - uid: ff19ea4c-cf53-4118-a95a-c8f1fac43180
          title: 'PAO | DB Fetch Time Exceeds 1 Seconds | East | Prod | P2 '
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="post-activate-offers-ns",namespace="prod",project="prj-promoplat-p",region="us-east4",source_type="kubernetes_logs"} |= `db_fetch_time` | pattern `<nonce> - <datetime> <_> - OfferDetails cache lookup stats for partnerId=<partnerId>. fetch_time=<fetch_time>, request_count=<request_count>, cache_hit_count=<cache_hit_count>, db_fetch_count=<db_fetch_count>, db_fetch_time=<db_fetch_time>, cache_get_count=<cache_get_count>, cache_get_time=<cache_get_time>, cache_put_count=<cache_put_count>, cache_put_time=<cache_put_time>, by_pass_cache=<by_pass_cache>` | db_fetch_time > 1000 !~ "GALO_HYDRATOR" | __error__=``[$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            description: Database fetch time is over 1 second, indicating a performance issue
            summary: Database fetch time is over 1 second, indicating a performance issue
          labels:
            application: PAO
            metric: optimus
          isPaused: false
        - uid: d68dd372-f9d3-4354-bc19-f4f57105b6fa
          title: 'PAO | DB Fetch Time Exceeds 1 Seconds | West | Prod | P2 '
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="post-activate-offers-ns",namespace="prod",project="prj-promoplat-p",region="us-west1",source_type="kubernetes_logs"} |= `db_fetch_time` | pattern `<nonce> - <datetime> <_> - OfferDetails cache lookup stats for partnerId=<partnerId>. fetch_time=<fetch_time>, request_count=<request_count>, cache_hit_count=<cache_hit_count>, db_fetch_count=<db_fetch_count>, db_fetch_time=<db_fetch_time>, cache_get_count=<cache_get_count>, cache_get_time=<cache_get_time>, cache_put_count=<cache_put_count>, cache_put_time=<cache_put_time>, by_pass_cache=<by_pass_cache>` | db_fetch_time > 1000 !~ "GALO_HYDRATOR"[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: 5m
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            description: Database fetch time is over 1 second, indicating a performance issue
            summary: Database fetch time is over 1 second, indicating a performance issue
          labels:
            application: PAO
            metric: optimus
          isPaused: false
        - uid: f8f5e3c9-b58b-44d9-89d6-dd34d7110266
          title: 'PAO| High number of HTTP 5xx errors  | east | Prod | P1 '
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="post-activate-offers-ns",namespace="prod",project="prj-promoplat-p",region=~"us-east.+",source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ ".*health.*" | __error__=``[$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 27
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "27"
            Grafana Query: https://grafana.corp.quotient.com/goto/0s6XsluIR?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: PAO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: fbe03e97-84ca-4372-9b0a-ede52d32eb92
          title: PAO | inmar-consumer | High number of HTTP 4xx errors  | west | Prod | P3
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 3600
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: "count_over_time(\r\n  {app=\"inmar-consumer-ns\", namespace=\"prod\", region=~\"us-west.*\", project=\"prj-promoplat-p\", source_type=\"kubernetes_logs\"}\r\n  |~ \"statusCode: [4][0-9][0-9]\" != \"No retailer found matching crossref\"\r\n  [5m]\r\n)"
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: 5m
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 28
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "28"
            Grafana Query: https://grafana.corp.quotient.com/goto/RHAzSXuSR?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the client request or the API endpoint itself. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes
          labels:
            application: pao
            metric: optimus
          isPaused: false
        - uid: dcfb6052-985c-4110-8b8d-54d7b93a2b1a
          title: PAO | inmar-consumer | High number of HTTP 4xx errors  | east | Prod | P3
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: "count_over_time(\r\n  {app=\"inmar-consumer-ns\", namespace=\"prod\", region=~\"us-east.*\", project=\"prj-promoplat-p\", source_type=\"kubernetes_logs\"}\r\n  |~ \"statusCode: [4][0-9][0-9]\" != \"No retailer found matching crossref\"\r\n  [5m]\r\n)"
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: ""
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 28
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "28"
            Grafana Query: https://grafana.corp.quotient.com/goto/5E5tIuXSR?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the client request or the API endpoint itself. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes
          labels:
            application: PAO
            metric: optimus
          isPaused: false
        - uid: d32cd4f6-4960-4840-bfd2-f8241aed23c1
          title: PAO | inmar-consumer | High number of HTTP 5xx errors  | west | Prod | P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: "count_over_time(\r\n  {app=\"inmar-consumer-ns\", namespace=\"prod\", region=~\"us-west.*\", project=\"prj-promoplat-p\", source_type=\"kubernetes_logs\"}\r\n  |~ \"statusCode: [5][0-9][0-9]\"\r\n  [$__range]\r\n)"
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 27
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "27"
            Grafana Query: https://grafana.corp.quotient.com/goto/-iCCSuuIR?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: PAO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: e835e289-866f-4f0b-81d2-0aec74f27d27
          title: PAO | inmar-consumer | High number of HTTP 5xx errors  | east | Prod | P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: "count_over_time(\r\n  {app=\"inmar-consumer-ns\", namespace=\"prod\", region=~\"us-east.*\", project=\"prj-promoplat-p\", source_type=\"kubernetes_logs\"}\r\n  |~ \"statusCode: [5][0-9][0-9]\"\r\n  [$__range]\r\n)"
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 27
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "27"
            Grafana Query: https://grafana.corp.quotient.com/goto/HMmcNXuSg?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: PAO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: a636644b-98fc-472d-92df-2fc7b85887f0
          title: PAO | pao-cpr-consumer | High number of HTTP 4xx errors  | west | Prod | P3
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 3600
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: "count_over_time(\r\n  {app=\"pao-cpr-consumer-ns\", namespace=\"prod\", project=\"prj-promoplat-p\", source_type=\"kubernetes_logs\", region=~\"us-west.*\"}\r\n  |~ \"statusCode=[4][0-9][0-9]\"\r\n  [5m]\r\n)"
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: 5m
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 28
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "28"
            Grafana Query: https://grafana.corp.quotient.com/goto/0ZsdvXuSg?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the client request or the API endpoint itself. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes
          labels:
            application: PAO
            metric: optimus
          isPaused: false
        - uid: b69a5bbc-39f2-4ae5-9b43-a2e3e6da32f2
          title: PAO | pao-cpr-consumer | High number of HTTP 4xx errors  | east | Prod | P3
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: "count_over_time(\r\n  {app=\"pao-cpr-consumer-ns\", namespace=\"prod\", project=\"prj-promoplat-p\", source_type=\"kubernetes_logs\", region=~\"us-east.*\"}\r\n  |~ \"statusCode=[4][0-9][0-9]\"\r\n  [5m]\r\n)"
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: ""
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 28
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "28"
            Grafana Query: https://grafana.corp.quotient.com/goto/_j8LDuXIg?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the client request or the API endpoint itself. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes
          labels:
            application: PAO
            metric: optimus
          isPaused: false
        - uid: ce555858-ac61-47f6-95ed-07337af04a3b
          title: PAO | pao-cpr-consumer  | High number of HTTP 5xx errors | west | Prod | P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: "count_over_time(\r\n  {app=\"pao-cpr-consumer-ns\", namespace=\"prod\", project=\"prj-promoplat-p\", source_type=\"kubernetes_logs\", region=~\"us-west.*\"}\r\n  |~ \"statusCode=[5][0-9][0-9]\"\r\n  [$__range]\r\n)"
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 27
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "27"
            Grafana Query: https://grafana.corp.quotient.com/goto/jq0zOXXSR?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: PAO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: c1cdd189-bbc4-41e1-bd4f-e3bdc820a337
          title: PAO | pao-cpr-consumer  | High number of HTTP 5xx errors | east | Prod | P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: "count_over_time(\r\n  {app=\"pao-cpr-consumer-ns\", namespace=\"prod\", project=\"prj-promoplat-p\", source_type=\"kubernetes_logs\", region=~\"us-east.*\"}\r\n  |~ \"statusCode=[5][0-9][0-9]\"\r\n  [$__range]\r\n)"
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 27
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "27"
            Grafana Query: https://grafana.corp.quotient.com/goto/aooFOXXIg?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: PAO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: ee53f1b4-843d-4d4c-9f38-488635d84cf0
          title: 'PAO | partner-int-consumer | High number of HTTP 4xx errors  | west | Prod | P3 '
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 3600
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: "count_over_time(\r\n  {app=\"partner-int-consumer-ns\", namespace=\"prod\", region=~\"us-west.*\", project=\"prj-promoplat-p\", source_type=\"kubernetes_logs\"}\r\n  |~ \"statusCode: [4][0-9][0-9]\" != \"/actuator/prometheus\"\r\n  [5m]\r\n)"
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: 5m
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 28
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "28"
            Grafana Query: https://grafana.corp.quotient.com/goto/tIURFXuIR?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the client request or the API endpoint itself. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes
          labels:
            application: PAO
            metric: optimus
          isPaused: false
        - uid: f87efd27-69ad-43f7-9d8b-cbd194811dfa
          title: PAO | partner-int-consumer | High number of HTTP 4xx errors | east | Prod | P3
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: "count_over_time(\r\n  {app=\"partner-int-consumer-ns\", namespace=\"prod\", region=~\"us-east.*\", project=\"prj-promoplat-p\", source_type=\"kubernetes_logs\"}\r\n  |~ \"statusCode: [4][0-9][0-9]\" != \"/actuator/prometheus\"\r\n  [5m]\r\n)"
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: ""
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 28
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "28"
            Grafana Query: https://grafana.corp.quotient.com/goto/tw3cpuXIR?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the client request or the API endpoint itself. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes
          labels:
            application: PAO
            metric: optimus
          isPaused: false
        - uid: ed41d7ac-3747-4234-9835-da54f9c97c35
          title: PAO | partner-int-consumer   | High number of HTTP 5xx errors | west | Prod | P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: "count_over_time(\r\n  {app=\"partner-int-consumer-ns\", namespace=\"prod\", region=~\"us-west.*\", project=\"prj-promoplat-p\", source_type=\"kubernetes_logs\"}\r\n  |~ \"http_status_code=[5][0-9][0-9]\"\r\n  [$__range]\r\n)"
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 27
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "27"
            Grafana Query: https://grafana.corp.quotient.com/goto/VJOepXuSR?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: PAO
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: e2ea8e22-f8c4-41db-8374-5ea6be0ad320
          title: PAO | partner-int-consumer | High number of HTTP 5xx errors | east | Prod | P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: "count_over_time(\r\n  {app=\"partner-int-consumer-ns\", namespace=\"prod\", region=~\"us-east.*\", project=\"prj-promoplat-p\", source_type=\"kubernetes_logs\"}\r\n  |~ \"http_status_code=[5][0-9][0-9]\"\r\n  [$__range]\r\n)"
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 27
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "27"
            Grafana Query: https://grafana.corp.quotient.com/goto/lSYh2uuSR?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: PAO
            metric: optimus
            severity: Critical
          isPaused: false
    - orgId: 1
      name: POA
      folder: Optimus
      interval: 5m
      rules:
        - uid: d25cc782-7dff-4e3c-8c88-ab9a7c84e66c
          title: POA (post-offers-associate-ns)  | Exceptions | west | Prod | P3
          condition: A
          data:
            - refId: log_metrics_poa_Exception
              queryType: range
              relativeTimeRange:
                from: 10800
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: sum(count_over_time({app="post-offers-associate-ns",cluster=~"gke-gke-riq-uswst.+-prod-active",project="prj-promoplat-p", namespace="prod"} |~".*Exception.*" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: log_metrics_poa_Exception
                step: 5m
            - refId: log_metrics__Exception_Status
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_poa_Exception
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: log_metrics__Exception_Status
                type: reduce
            - refId: A
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics__Exception_Status
                intervalMs: 1000
                maxDataPoints: 43200
                refId: A
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 5
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "5"
            Grafana Query: https://grafana.corp.quotient.com/goto/qsx0I_uSR?orgId=1
            description: Exception Observed in logs for post-offers-associate-ns Service.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: Exception Observed in logs for post-offers-associate-ns Service.
          labels:
            application: post-offers-associate-ns
            metric: optimus
          isPaused: false
        - uid: df7d968a-efc3-492c-9be4-622fc3f39bed
          title: POA | High number of HTTP 4xx errors  | east | Prod | P3
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="post-offers-associate-ns",namespace="prod",project="prj-promoplat-p",region=~"us-east.+",source_type="ingress_logs"} | json | message_httpRequest_status =~ "4[0-9][0-9]" | message_httpRequest_requestUrl !~ ".*health.*" | __error__=``[5m]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: ""
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 28
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "28"
            Grafana Query: https://grafana.corp.quotient.com/goto/tLYLSluIg?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the client request or the API endpoint itself. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes
          labels:
            application: post-offers-associate-ns
            metric: optimus
          isPaused: false
        - uid: cce3292d-d9d9-43e9-b839-779ebc25486b
          title: POA | High number of HTTP 5xx errors  | east | Prod | P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="post-offers-associate-ns",namespace="prod",project="prj-promoplat-p",region=~"us-east.+",source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ ".*health.*" | __error__=``[$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 27
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "27"
            Grafana Query: https://grafana.corp.quotient.com/goto/31nlS_XIg?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: post-offers-associate-ns
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: baf6dba0-c7c9-4678-a2fe-b985c550bba5
          title: POA | High number of HTTP 4xx errors  | west | Prod | P3
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="post-offers-associate-ns",namespace="prod",project="prj-promoplat-p",region=~"us-west.+",source_type="ingress_logs"} | json | message_httpRequest_status =~ "4[0-9][0-9]" | message_httpRequest_requestUrl !~ ".*health.*" | __error__=``[5m]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: 5m
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 28
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "28"
            Grafana Query: https://grafana.corp.quotient.com/goto/5MXCSluIR?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the client request or the API endpoint itself. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes
          labels:
            application: post-offers-associate-ns
            metric: optimus
          isPaused: false
        - uid: eaff5410-775e-440d-a544-df09fa8a0eec
          title: POA (post-offers-associate-ns) | Exceptions | east | Prod | P3
          condition: A
          data:
            - refId: log_metrics_poa_Exception
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: sum(count_over_time({app="post-offers-associate-ns",cluster=~"gke-gke-riq-usest.+-prod-active",project="prj-promoplat-p", namespace="prod"} |~".*Exception.*" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: log_metrics_poa_Exception
            - refId: log_metrics_Exception_Status
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_poa_Exception
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: log_metrics_Exception_Status
                type: reduce
            - refId: A
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: log_metrics_Exception_Status
                intervalMs: 1000
                maxDataPoints: 43200
                refId: A
                type: threshold
          dashboardUid: cb189ada-1897-41a7-8759-01f3ff81e367
          panelId: 5
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: cb189ada-1897-41a7-8759-01f3ff81e367
            __panelId__: "5"
            Grafana Query: https://grafana.corp.quotient.com/goto/S8jQHluIg?orgId=1
            description: Exception Observed in logs for get-all-offers-ns Service.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: Exception Observed in logs for get-all-offers-ns Service.
          labels:
            application: post-offers-associate-ns
            metric: optimus
          isPaused: false
        - uid: e65cc65d-d413-4358-8214-e7c5aa77ffa8
          title: POA | High number of HTTP 5xx errors  | west | Prod | P1
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="post-offers-associate-ns",namespace="prod",project="prj-promoplat-p",region=~"us-west.+",source_type="ingress_logs"} | json | message_httpRequest_status >= 500 | message_httpRequest_requestUrl !~ ".*health.*" | __error__=``[$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 27
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "27"
            Grafana Query: https://grafana.corp.quotient.com/goto/jZfhK_XIg?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 5 in last 5 mins
          labels:
            application: post-offers-associate-ns
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: fd764c3f-0bb9-4190-99f0-9ea10d4a5764
          title: POA | High Latency Requests | east | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({project="prj-promoplat-p", namespace="prod", app="post-offers-associate-ns", region=~"us-east.+", source_type="kubernetes_logs"} |= `http_response_time=` |= `vr=1.0` != `oauth_internal=yes` != `warmup_service` != `GALO_HYDRATOR` != `user-agent=Postman` != `user-agent=curl` | pattern `nonce=<nonce> client_ip=<client_ip> - <datetime> <_> - /<endpoint>/<_> partnerId=<partnerId> <_> http_response_time=<latency>ms http_commit_response_time=<committime>ms` | latency > 1000 | __error__=``[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 26
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "26"
            Query: https://grafana.corp.quotient.com/goto/02eIa_XSR?orgId=1
            description: This alert is triggered when the latency of 5 requests to the get-all-offers-ns service in the East Prod environment exceeds the threshold of 1 second.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High latency was observed in get-all-offers-ns service (> 1 second )  requests in the Optimus-East environment.
          labels:
            application: post-offers-associate-ns
            metric: optimus
          isPaused: false
        - uid: ec36a9f5-ed29-4883-9717-7daa22f538d2
          title: POA | High Latency Requests | west | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({project="post-offers-associate-ns", namespace="prod", app="get-all-offers-ns", region=~"us-west.+", source_type="kubernetes_logs"} |= `http_response_time=` |= `vr=1.0` != `oauth_internal=yes` != `GALO_HYDRATOR` != `warmup_service` != `user-agent=curl` != `user-agent=Postman` | pattern `nonce=<nonce> client_ip=<client_ip> - <datetime> <_> - /<endpoint>/<_> partnerId=<partnerId> <_> http_response_time=<latency>ms http_commit_response_time=<committime>ms` | latency > 1000 | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: 5m
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: 6lr4j1UVz
          panelId: 26
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            __dashboardUid__: 6lr4j1UVz
            __panelId__: "26"
            Query: https://grafana.corp.quotient.com/goto/4luB0XuSR?orgId=1
            description: This alert is triggered when the latency of 5 requests to the get-all-offers-ns service in the WEST Prod environment exceeds the threshold of 1 seconds.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High latency was observed in get-all-offers-ns service (> 1 second )  requests in the Optimus-West environment.
          labels:
            application: post-offers-associate-ns
            metric: optimus
          isPaused: false
        - uid: ba9a0009-a493-457c-b9ab-b11fcabc240e
          title: POA | POD Health Checks failed | West| Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="post-offers-associate-ns",namespace="prod",region="us-west1",project="prj-promoplat-p",source_type="ingress_logs"} | json | message_httpRequest_status!=`200` | message_jsonPayload_statusDetails!="client_disconnected_before_any_response" | message_httpRequest_status!~ "4[0-9][0-9]" |~"/galo/actuator/health" | __error__=``[$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: sum
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 2
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            Query: https://grafana.corp.quotient.com/goto/TpICsXuIg?orgId=1
            description: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
          labels:
            application: post-offers-associate-ns
            metric: optimus
          isPaused: false
        - uid: f03dde4c-6171-43bd-a5d5-ce7a564004d6
          title: POA | POD Health Checks failed | East | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="post-offers-associate-ns",namespace="prod",region="us-east4",project="prj-promoplat-p",source_type="ingress_logs"} | json | message_httpRequest_status!=`200` | message_jsonPayload_statusDetails!="client_disconnected_before_any_response" | message_httpRequest_status!~ "4[0-9][0-9]" |~"/galo/actuator/health" | __error__=`` [$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: sum
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 2
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            Query: https://grafana.corp.quotient.com/goto/4AuLUuXSg?orgId=1
            description: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: this query helps monitor and quantify instances where the health check for the mentioned application fails, based on non-200 HTTP responses in the specified endpoint.
          labels:
            application: post-offers-associate-ns
            metric: optimus
          isPaused: false
        - uid: d9bc3d50-c532-4035-ba4f-e2491efebff3
          title: POA | DB Fetch Time Exceeds 1 Seconds | East | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="post-offers-associate-ns",namespace="prod",project="prj-promoplat-p",region="us-east4",source_type="kubernetes_logs"} |= `db_fetch_time` | pattern `<nonce> - <datetime> <_> - OfferDetails cache lookup stats for partnerId=<partnerId>. fetch_time=<fetch_time>, request_count=<request_count>, cache_hit_count=<cache_hit_count>, db_fetch_count=<db_fetch_count>, db_fetch_time=<db_fetch_time>, cache_get_count=<cache_get_count>, cache_get_time=<cache_get_time>, cache_put_count=<cache_put_count>, cache_put_time=<cache_put_time>, by_pass_cache=<by_pass_cache>` | db_fetch_time > 1000 !~ "GALO_HYDRATOR" | __error__=``[$__range]))
                intervalMs: 60000
                maxDataPoints: 43200
                queryType: range
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            Query: https://grafana.corp.quotient.com/goto/TcOzQuXIg?orgId=1
            description: Database fetch time is over 1 second, indicating a performance issue
            summary: Database fetch time is over 1 second, indicating a performance issue
          labels:
            application: post-offers-associate-ns
            metric: optimus
          isPaused: false
        - uid: af6905be-ed47-47cf-b7df-925aeb012573
          title: POA | DB Fetch Time Exceeds 1 Seconds | West | Prod | P2
          condition: C
          data:
            - refId: A
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="post-offers-associate-ns",namespace="prod",project="prj-promoplat-p",region="us-west1",source_type="kubernetes_logs"} |= `db_fetch_time` | pattern `<nonce> - <datetime> <_> - OfferDetails cache lookup stats for partnerId=<partnerId>. fetch_time=<fetch_time>, request_count=<request_count>, cache_hit_count=<cache_hit_count>, db_fetch_count=<db_fetch_count>, db_fetch_time=<db_fetch_time>, cache_get_count=<cache_get_count>, cache_get_time=<cache_get_time>, cache_put_count=<cache_put_count>, cache_put_time=<cache_put_time>, by_pass_cache=<by_pass_cache>` | db_fetch_time > 1000 !~ "GALO_HYDRATOR"[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: A
                step: 5m
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            Query: https://grafana.corp.quotient.com/goto/6AM2QXuSg?orgId=1
            description: Database fetch time is over 1 second, indicating a performance issue
            summary: Database fetch time is over 1 second, indicating a performance issue
          labels:
            application: post-offers-associate-ns
            metric: optimus
          isPaused: false
    - orgId: 1
      name: System-Alerts(Node Exporter)
      folder: Optimus
      interval: 5m
      rules:
        - uid: a9ca8f6a-480b-4af9-b1e9-affb16827364
          title: HostOomKillDetected | warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: increase(node_vmstat_oom_kill{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active",project="prj-promoplat-p"}[15m]) > 0
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostOomKillDetected
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostOomKillDetected
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: HostOomKillDetected
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: OOM kill detected\n  VALUE = {{ $value }}
            summary: Host OOM kill detected (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: ea7a1fe3-342f-4fc9-8086-41a4484eeda6
          title: HostOutOfMemory | warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: "100 * (\n  1 - (\n    node_memory_MemAvailable_bytes{cluster=~\"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active\",job=\"gke-riq-usest4-prod-active-node-exporter\",project=\"prj-promoplat-p\"} \n    /\n    node_memory_MemTotal_bytes{cluster=~\"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active\",job=\"gke-riq-usest4-prod-active-node-exporter\",project=\"prj-promoplat-p\"}\n  )\n)\n"
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: NODE_MEMORY
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: NODE_MEMORY
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 90
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: NODE_MEMORY
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: Node memory is filling up (< 10% left)\n  VALUE = {{ $value }}
            summary: Host out of memory (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: dd7d21b5-97c3-4555-a8b0-7a5a68f9f95b
          title: HostHighCpuLoad
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle", cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}[2m])) * 100)
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostHighCpuLoad
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostHighCpuLoad
                type: reduce
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 80
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: HostHighCpuLoad
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: CPU load is > 80%\n  VALUE = {{ $value }}
            summary: Host high CPU load (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: f6b0225a-3132-4281-86b8-2993bee10b14
          title: HostMemoryUnderMemoryPressure | warning
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: rate(node_vmstat_pgmajfault{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", project="prj-promoplat-p"}[1m])
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: page_faults
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: page_faults
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1000
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: page_faults
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: The node is under heavy memory pressure. High rate of major page faults\n  VALUE = {{ $value }}
            summary: Host memory under memory pressure (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: bac3cc0d-48d2-4ae3-b06f-20a7acb4e835
          title: HostUnusualNetworkThroughputIn
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: sum by (instance) (rate(node_network_receive_bytes_total{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", project="prj-promoplat-p"}[5m])) / 1024 / 1024
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: NetworkThroughputIn
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: NetworkThroughputIn
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 100
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: NetworkThroughputIn
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: Host network interfaces are probably receiving too much data (> 100 MB/s)\n  VALUE = {{ $value }}
            summary: Host unusual network throughput in (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: f72dbf7e-357f-4fc3-a2d9-69fa1c18f165
          title: HostUnusualNetworkThroughputOut
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: sum by (instance) (rate(node_network_transmit_bytes_total{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", project="prj-promoplat-p"}[5m])) / 1024 / 1024
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: NetworkThroughputOut
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: NetworkThroughputOut
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 100
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: NetworkThroughputOut
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: Host network interfaces are probably sending too much data (> 100 MB/s)\n  VALUE = {{ $value }}
            summary: Host unusual network throughput out (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: b104da53-b6e9-4e61-a2e5-58cb60cf02a2
          title: HostUnusualDiskReadRate
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: sum by (instance) (rate(node_disk_read_bytes_total{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", project="prj-promoplat-p"}[5m])) / 1024 / 1024
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: UnusualDiskReadRate
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: UnusualDiskReadRate
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 50
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: UnusualDiskReadRate
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: Disk is probably reading too much data (> 50 MB/s)\n  VALUE = {{ $value }}
            summary: Host unusual disk read rate (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: d1d0b9c5-4e90-4542-9dbc-d0d21dd99ac0
          title: HostUnusualDiskWriteRate
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: sum by (instance) (rate(node_disk_written_bytes_total{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", project="prj-promoplat-p"}[5m])) / 1024 / 1024
                instant: true
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostUnusualDiskWriteRate
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostUnusualDiskWriteRate
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 50
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: HostUnusualDiskWriteRate
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: NoData
          execErrState: Error
          for: 5m
          annotations:
            description: Disk is probably writing too much data (> 50 MB/s)\n  VALUE = {{ $value }}
            summary: Host unusual disk write rate (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: e496adaa-ccc1-4f61-b463-f369e6a92243
          title: HostOutOfDiskSpace
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |
                    (
                      100 * (1 - (
                        node_filesystem_avail_bytes{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}
                        / node_filesystem_size_bytes{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}
                      ))
                    )
                      and
                    ON (instance, device, mountpoint)
                    node_filesystem_readonly{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"} == 0
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostOutOfDiskSpace
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostOutOfDiskSpace
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 80
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: HostOutOfDiskSpace
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: Disk is almost full (< 10% left)\n  VALUE = {{ $value }}
            summary: Host out of disk space (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: e208989a-85a7-4f6b-b3df-bf437e723748
          title: HostDiskWillFillIn24Hours
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |
                    (
                      100 * (
                        1 - (
                          node_filesystem_avail_bytes{fstype!~"tmpfs", cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}
                          / node_filesystem_size_bytes{fstype!~"tmpfs", cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}
                        )
                      )
                      and
                      ON (instance, device, mountpoint)
                      predict_linear(
                        node_filesystem_avail_bytes{fstype!~"tmpfs", cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}[1h],
                        24 * 3600
                      ) < 0
                      and
                      ON (instance, device, mountpoint)
                      node_filesystem_readonly{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"} == 0
                    )
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostDiskWillFillIn24Hours
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostDiskWillFillIn24Hours
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 80
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: HostDiskWillFillIn24Hours
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: Filesystem is predicted to run out of space within the next 24 hours at current write rate\n  VALUE = {{ $value }}
            summary: Host disk will fill in 24 hours (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: dc04ec79-1715-4950-a96f-f0d2ce3cba03
          title: HostUnusualDiskReadLatency
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |-
                    (
                      rate(node_disk_read_time_seconds_total{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}[1m])
                      /
                      rate(node_disk_reads_completed_total{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}[1m])
                    ) > 0.1
                    and
                    rate(node_disk_reads_completed_total{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}[1m]) > 0
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostUnusualDiskReadLatency
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostUnusualDiskReadLatency
                type: reduce
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: HostUnusualDiskReadLatency
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: Disk latency is growing (write operations > 100ms)\n  VALUE = {{ $value }}
            summary: Host unusual disk write latency (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: f95143b0-f421-4af1-b400-1ed833e8c4cc
          title: HostUnusualDiskWriteLatency
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |
                    (
                      rate(node_disk_write_time_seconds_total{device!~"mmcblk.+", cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}[1m])
                      /
                      rate(node_disk_writes_completed_total{device!~"mmcblk.+", cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}[1m])
                    ) > 0.1
                    and
                    rate(node_disk_writes_completed_total{device!~"mmcblk.+", cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}[1m]) > 0
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostUnusualDiskWriteLatency
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostUnusualDiskWriteLatency
                type: reduce
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: HostUnusualDiskWriteLatency
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: Disk latency is growing (read operations > 100ms)\n  VALUE = {{ $value }}
            summary: Host unusual disk read latency (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: dcd83098-2069-4402-9b99-00a1439352b2
          title: HostCpuStealNoisyNeighbor
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |-
                    avg by(instance) (
                      rate(node_cpu_seconds_total{mode="steal", cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}[5m])
                    ) * 100
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostCpuStealNoisyNeighbor
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostCpuStealNoisyNeighbor
                type: reduce
            - refId: B
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: HostCpuStealNoisyNeighbor
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: CPU steal is > 10%. A noisy neighbor is killing VM performances or a spot instance may be out of credit.\n  VALUE = {{ $value }}
            summary: Host CPU steal noisy neighbor (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: fe2ff1ed-d844-4156-b510-d91f9aef70ee
          title: HostSystemdServiceCrashed
          condition: HostSystemdServiceCrashed
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: node_systemd_unit_state{state="failed", cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"} == 1
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostSystemdServiceCrashed
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: HostSystemdServiceCrashed
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: SystemD service crashed\n  VALUE = {{ $value }}
            summary: Host SystemD service crashed (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: a0bfa23b-1736-49f4-84a3-43962e45b66b
          title: HostClockNotSynchronising
          condition: HostSystemdServiceCrashed
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |-
                    min_over_time(node_timex_sync_status{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}[1m]) == 0
                    and
                    node_timex_maxerror_seconds{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"} >= 16
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostSystemdServiceCrashed
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: HostSystemdServiceCrashed
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: Clock not synchronising.\n  VALUE = {{ $value }}
            summary: Host clock not synchronising (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: daf2ff82-047a-42e3-bbf6-0d92b4eebb32
          title: HostClockSkew
          condition: HostClockSkew
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |-
                    (
                      (node_timex_offset_seconds{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"} > 0.05
                      and
                      deriv(node_timex_offset_seconds{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}[5m]) >= 0
                      )
                      or
                      (
                        node_timex_offset_seconds{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"} < -0.05
                        and
                        deriv(node_timex_offset_seconds{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}[5m]) <= 0
                      )
                      )
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostClockSkew
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: HostClockSkew
                settings:
                    mode: ""
                type: reduce
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: Clock skew detected. Clock is out of sync.\n  VALUE = {{ $value }}
            summary: Host clock skew (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: fa1bc147-643b-4d03-8ed7-d4afa40f3028
          title: HostConntrackLimit
          condition: HostConntrackLimit
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |-
                    node_nf_conntrack_entries{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}
                    /
                    node_nf_conntrack_entries_limit{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostConntrackLimit
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0.8
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: HostConntrackLimit
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: The number of conntrack is approching limit\n  VALUE = {{ $value }}
            summary: Host conntrack limit (instance {{ $labels.instance }})
          labels:
            metric: optimus
          isPaused: false
        - uid: abdfe7fb-5423-4a54-a35c-8eab6bab15ac
          title: HostNetworkInterfaceSaturated
          condition: HostNetworkInterfaceSaturated
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |-
                    (
                      rate(node_network_receive_bytes_total{device!~"^tap.*", cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}[1m])
                      +
                      rate(node_network_transmit_bytes_total{device!~"^tap.*", cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}[1m])
                    )
                    /
                    node_network_speed_bytes{device!~"^tap.*", cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostNetworkInterfaceSaturated
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0.8
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: HostNetworkInterfaceSaturated
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: The network interface is getting overloaded.\n  VALUE = {{ $value }}
            summary: Host Network Interface Saturated (instance {{ $labels.instance }}:{{ $labels.interface }})
          labels:
            metric: optimus
          isPaused: false
        - uid: d4a92050-f0f9-4c39-8959-eb885d808d53
          title: HostNetworkTransmitErrors
          condition: HostNetworkInterfaceSaturated
          data:
            - refId: A
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: code
                expr: |-
                    rate(node_network_transmit_errs_total{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}[2m])
                    /
                    rate(node_network_transmit_packets_total{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}[2m])
                    > 0.01
                    and
                    rate(node_network_transmit_packets_total{cluster=~"gke-riq-usest4-prod-active|gke-riq-uswst1-prod-active", job=~"gke-riq-usest4-prod-active-node-exporter|gke-riq-prod-uswst1-active-node-exporter", project="prj-promoplat-p"}[2m]) > 0
                instant: true
                intervalMs: 60000
                legendFormat: __auto
                maxDataPoints: 43200
                range: false
                refId: A
            - refId: HostNetworkInterfaceSaturated
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0.8
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                refId: HostNetworkInterfaceSaturated
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 5m
          annotations:
            description: Instance has encountered {{ printf "%.0f" $value }} transmit errors in the last five minutes.\n  VALUE = {{ $value }}
            summary: Host Network Transmit Errors (instance {{ $labels.instance }}:{{ $labels.device }})
          labels:
            metric: optimus
          isPaused: false
    - orgId: 1
      name: rebate-service
      folder: Optimus
      interval: 2m
      rules:
        - uid: b027f5a6-f33f-42c3-bb22-29c9d655e78b
          title: rebate-service | High number of HTTP 5xx errors  | east | Prod | P1
          condition: C
          data:
            - refId: rebate-service-east 5xx Failures
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="rebate-service",cluster="gke-tahoe-prod-cluster03",component="rebate-service-east",namespace="prod",project="riq-poc"} |~ "http_status_code" | pattern `[ACCESS] nonce=<nonce> client_ip=<client_ip> remote_host=<remote_host> - - [<datetime>] "<method> <url> HTTP/<http_version>" http_status_code=<status_code> http_response_bytes=<http_response_bytes> http_response_time=<latency>` | status_code>=500  | __error__=""[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: rebate-service-east 5xx Failures
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: rebate-service-east 5xx Failures
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/f1Oy2cQIg?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 10 in last 5 mins
          labels:
            Cluster: Tahoe
            application: rebate-service-east
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: ffb6d8fd-3037-410c-8573-a2879397ff52
          title: 'rebate-service | High number of HTTP 5xx errors  | west | Prod | P1 '
          condition: C
          data:
            - refId: rebate-service-west 5xx Failures
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="rebate-service",cluster="gke-tahoe-prod-cluster02",component="rebate-service-west",namespace="prod",project="riq-poc"} |~ "http_status_code" | pattern `[ACCESS] nonce=<nonce> client_ip=<client_ip> remote_host=<remote_host> - - [<datetime>] "<method> <url> HTTP/<http_version>" http_status_code=<status_code> http_response_bytes=<http_response_bytes> http_response_time=<latency>` | status_code>=500  | __error__=""[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: rebate-service-west 5xx Failures
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: rebate-service-west 5xx Failures
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/htx8hcQIR?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 5xx status codes > 10 in last 5 mins
          labels:
            Cluster: Tahoe
            application: rebate-service-west
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: ec6f5385-a396-4ee4-a81a-9a7449ea85db
          title: rebate-service | High number of HTTP 4xx errors  | east | Prod | P1
          condition: C
          data:
            - refId: rebate-service-east 4xx Failures
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="rebate-service",cluster="gke-tahoe-prod-cluster03",component="rebate-service-east",namespace="prod",project="riq-poc"} |~ "http_status_code" | pattern `[ACCESS] nonce=<nonce> client_ip=<client_ip> remote_host=<remote_host> - - [<datetime>] "<method> <url> HTTP/<http_version>" http_status_code=<status_code> http_response_bytes=<http_response_bytes> http_response_time=<latency>` | status_code=~"4[0-9][0-9]" | __error__=""[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: rebate-service-east 4xx Failures
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: rebate-service-east 4xx Failures
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/Fz1ucOQIg?orgId=1
            description: The rate of 4xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 4xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes > 5 in last 5 mins
          labels:
            Cluster: Tahoe
            application: rebate-service-east
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: fbed514b-2ebf-4d3b-97e2-b73c2703a58c
          title: rebate-service | High number of HTTP 4xx errors  | west | Prod | P1
          condition: C
          data:
            - refId: rebate-service-west 4xx Failures
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="rebate-service",cluster="gke-tahoe-prod-cluster02",component="rebate-service-west",namespace="prod",project="riq-poc"} |~ "http_status_code" | pattern `[ACCESS] nonce=<nonce> client_ip=<client_ip> remote_host=<remote_host> - - [<datetime>] "<method> <url> HTTP/<http_version>" http_status_code=<status_code> http_response_bytes=<http_response_bytes> http_response_time=<latency>` | status_code=~"4[0-9][0-9]"  | __error__=""[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: rebate-service-west 4xx Failures
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: rebate-service-west 4xx Failures
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/TqsA5dwIR?orgId=1
            description: The rate of 5xx status codes on the API is higher than normal, indicating a problem with the backend service. This alert is triggered if the count of requests with 5xx status codes exceeds a threshold value in a given time window
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High rate of 4xx status codes > 5 in last 5 mins
          labels:
            Cluster: Tahoe
            application: rebate-service-west
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: ed86abc5-0b5d-470b-8dec-96114429a2ad
          title: rebate-service | High Latency Requests | west | Prod | P2
          condition: C
          data:
            - refId: rebate-service-west Response time
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="rebate-service",cluster="gke-tahoe-prod-cluster02",component="rebate-service-west",namespace="prod",project="riq-poc"} |~ "http_response_time" | pattern `[ACCESS] nonce=<nonce> client_ip=<client_ip> remote_host=<remote_host> - - [<datetime>] "<method> <url> HTTP/<http_version>" http_status_code=<status_code> http_response_bytes=<http_response_bytes> http_response_time=<latency>` | latency>=2000 !~"oauth_internal=yes" | __error__=""[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: rebate-service-west Response time
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: rebate-service-west Response time
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/Mh799OwSR?orgId=1
            description: This alert is triggered when the latency of 10 requests to the rebate-service service in the rebate-service-west  Prod environment exceeds the threshold of 2 second.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High latency was observed in rebate-service service (> 2 second )  requests in the rebate-service-west environment
          labels:
            Cluster: Tahoe
            application: rebate-service-west
            metric: optimus
            severity: Critical
          isPaused: false
        - uid: dfe3949b-1620-478a-bd85-699ded6878b8
          title: 'rebate-service | High Latency Requests | east | Prod | P2 '
          condition: C
          data:
            - refId: rebate-service-east Response time
              queryType: range
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: sXVBxwenz
              model:
                editorMode: code
                expr: count(count_over_time({app="rebate-service",cluster="gke-tahoe-prod-cluster03",component="rebate-service-east",namespace="prod",project="riq-poc"} |~ "http_response_time" | pattern `[ACCESS] nonce=<nonce> client_ip=<client_ip> remote_host=<remote_host> - - [<datetime>] "<method> <url> HTTP/<http_version>" http_status_code=<status_code> http_response_bytes=<http_response_bytes> http_response_time=<latency>` | latency>=2000 !~"oauth_internal=yes" | __error__=""[$__range]))
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: rebate-service-east Response time
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: rebate-service-east Response time
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 10
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Alerting
          for: 2m
          annotations:
            Grafana Query: https://grafana.corp.quotient.com/goto/k_al5dQSR?orgId=1
            description: This alert is triggered when the latency of 10 requests to the rebate-service service in the rebate-service-east  Prod environment exceeds the threshold of 2 second.
            runbook_url: https://quotient.atlassian.net/wiki/spaces/SITEOPS/pages/15252193312/Optimus+-+Generic+Runbook
            summary: High latency was observed in rebate-service service (> 2 seconds )  requests in the  rebate-service-east environment
          labels:
            Cluster: Tahoe
            application: rebate-service-east
            metric: optimus
            severity: Critical
          isPaused: false
    - orgId: 1
      name: DevOps
      folder: DevOps
      interval: 1m
      rules:
        - uid: dbd754ed-7ee9-4e68-9eac-8997577ebbae
          title: MSTR-PROD-Internal-Services-Alert
          condition: Any MSTR component service down(0=false,1=true)
          data:
            - refId: Alert query
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                editorMode: builder
                expr: node_systemd_unit_state{job=~"mstr-.*",name=~"bi.*.service",state="inactive"}
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: Alert query
            - refId: Inactive state
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: Alert query
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: Inactive state
                type: reduce
            - refId: Any MSTR component service down(0=false,1=true)
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: Inactive state
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: Any MSTR component service down(0=false,1=true)
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: Service {{ $labels.name }} is not active in instance {{ $labels.instance }}
          labels:
            metric: mstr_alerts
          isPaused: false
        - uid: e6fefb68-5370-4e86-9a54-5794a7eb1acf
          title: MSTR Disk Usage Alert
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: 100 - ((node_filesystem_avail_bytes{instance=~"bi-.*",job=~"mstr-.*",device!~'rootfs'} * 100) / node_filesystem_size_bytes{instance=~"bi-.*",job=~"mstr-.*",device!~'rootfs'})
                hide: false
                intervalMs: 1000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params: []
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - B
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: last
                refId: B
                type: reduce
            - refId: C
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 90
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - C
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: B
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          noDataState: OK
          execErrState: Error
          for: 5m
          annotations:
            description: Disk usage exceeded 90% for instance {{ $labels.instance }}
          labels:
            metric: mstr_alerts
          isPaused: false
    - orgId: 1
      name: Thanos-Errors
      folder: DevOps
      interval: 30m
      rules:
        - uid: f014377c-7497-430c-88e6-086097947da5
          title: Thanos-Compactor-Error-Prod
          condition: B
          data:
            - refId: compactor_error_count__last_1h
              queryType: range
              relativeTimeRange:
                from: 10800
                to: 0
              datasourceUid: sXVBxwenz
              model:
                datasource:
                    type: loki
                    uid: sXVBxwenz
                editorMode: code
                expr: sum(count_over_time({cluster="gke-gke-prometheus-uswst2-p-act",component="compactor",namespace="thanos"}|="error"|logfmt[1h]))
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                queryType: range
                refId: compactor_error_count__last_1h
            - refId: B
              relativeTimeRange:
                from: 600
                to: 0
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0.5
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - compactor_error_count__last_1h
                      reducer:
                        params: []
                        type: max
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          noDataState: OK
          execErrState: Alerting
          for: 30m
          annotations:
            description: Error Observed in Thanos Compactor PROD.
            runbook_url: https://grafana.corp.quotient.com/explore?orgId=1&left=%7B%22datasource%22:%22sXVBxwenz%22,%22queries%22:%5B%7B%22datasource%22:%7B%22type%22:%22loki%22,%22uid%22:%22sXVBxwenz%22%7D,%22editorMode%22:%22code%22,%22expr%22:%22%7Bcluster%3D%5C%22gke-gke-prometheus-uswst2-p-act%5C%22,component%3D%5C%22compactor%5C%22,namespace%3D%5C%22thanos%5C%22%7D%7C%3D%5C%22error%5C%22%7Clogfmt%22,%22legendFormat%22:%22%22,%22maxLines%22:null,%22queryType%22:%22range%22,%22refId%22:%22A%22%7D%5D,%22range%22:%7B%22from%22:%22now-3h%22,%22to%22:%22now%22%7D%7D
            summary: Error Observed in Thanos Compactor PROD.
          labels:
            SRE: thanos-errors
            metric: thanos-errors
          isPaused: false
    - orgId: 1
      name: Confluent-Alerts
      folder: RIQ Tahoe Dashboards And alerts
      interval: 1m
      rules:
        - uid: -aTvPsUVk
          title: QUOT.FRAUD.MODEL.ANALYSIS.RESULT.EVENTS LAG
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 21600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_consumer_lag_offsets{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.FRAUD.MODEL.ANALYSIS.RESULT.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 500
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 2
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "2"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: m0BKPGQVk
          title: QUOT.FRAUD.MODEL.ANALYSIS.RESULT.EVENTS LAG - 2
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 21600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_consumer_lag_offsets{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.FRAUD.MODEL.ANALYSIS.RESULT.EVENTS", kafka_id="lkc-ngj36"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 500
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 6
          noDataState: NoData
          execErrState: Alerting
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "6"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: PSq0EGQVz
          title: QUOT.FRAUD.MODEL.ANALYSIS.RESULT.EVENTS RECEIVED RECORDS -2
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 21600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_received_records{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.FRAUD.MODEL.ANALYSIS.RESULT.EVENTS", kafka_id="lkc-ngj36"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 7
          noDataState: OK
          execErrState: OK
          for: 6h
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "7"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: VJTZbDQVk
          title: QUOT.FRAUD.SUBMISSION.EVENTS LAG
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 21600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_consumer_lag_offsets{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.FRAUD.SUBMISSION.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 500
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 8
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "8"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: UhUNLvwVz
          title: QUOT.PAYMENT.STATUS.EVENTS LAG
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_consumer_lag_offsets{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.PAYMENT.STATUS.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 500
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 12
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "12"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: vis1LDQVk
          title: QUOT.REBATE.AFFILIATE.WEBHOOK.EVENTS LAG
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_consumer_lag_offsets{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.REBATE.AFFILIATE.WEBHOOK.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 500
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 16
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "16"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: RFDKEDwVz
          title: QUOT.REBATE.PAYOUT.EVENTS LAG
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_consumer_lag_offsets{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.REBATE.PAYOUT.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 500
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 20
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "20"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: JMY1Evw4k
          title: QUOT.REBATE.REDEEM.EVENTS LAG
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_consumer_lag_offsets{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.REBATE.REDEEM.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 500
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 24
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "24"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: ZwjPEvw4k
          title: QUOT.REBATE.REWARD-STATUS.EVENTS LAG
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_consumer_lag_offsets{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.REBATE.REWARD-STATUS.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 500
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 28
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "28"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: P_nXPvQVz
          title: QUOT.RECEIPT.DATA.EXTRACT.EVENTS LAG
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_consumer_lag_offsets{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.RECEIPT.DATA.EXTRACT.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 500
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 32
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "32"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: vAj6Evw4k
          title: QUOT.RECEIPTS.OCR.DETAILS.EVENTS LAG
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_consumer_lag_offsets{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.RECEIPTS.OCR.DETAILS.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 500
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 36
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "36"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: WaK6svQVk
          title: QUOT.SALES.TRANSACTION.PROCESSED.EVENTS LAG
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 3600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_consumer_lag_offsets{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.SALES.TRANSACTION.PROCESSED.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 500
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 44
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "44"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: w2k4UDw4k
          title: QUOT.SALES.TRANSACTION.SUBMISSION.EVENTS LAG
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 3600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_consumer_lag_offsets{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.SALES.TRANSACTION.SUBMISSION.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 500
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 48
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "48"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: LKmK8DQ4k
          title: QUOT.SHOPMIUM.WALLET.REWARD.EVENTS LAG
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 3600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_consumer_lag_offsets{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.SHOPMIUM.WALLET.REWARD.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 800
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 52
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "52"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: bN8J8vQVz
          title: QUOT.USER.STATE.EVENT LAG
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 21600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_consumer_lag_offsets{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.USER.STATE.EVENT"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 500
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 56
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "56"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: ihV3g5QVz
          title: QUOT.SALES.TRANSACTION.PIPELINE.EVENTS LAG
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 21600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_consumer_lag_offsets{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.SALES.TRANSACTION.PIPELINE.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 500
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 40
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "40"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: f8600bc5-4065-4e78-8e06-062f290e2fd4
          title: QUOT.FRAUD.RULES.EVALUATION.EVENTS LAG
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 21600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_consumer_lag_offsets{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.FRAUD.RULES.EVALUATION.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 100
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 56
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "56"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
    - orgId: 1
      name: Confluent-Alerts2
      folder: RIQ Tahoe Dashboards And alerts
      interval: 5m
      rules:
        - uid: kpw2LMwVk
          title: 'QUOT.FRAUD.MODEL.ANALYSIS.RESULT.EVENTS RECEIVED_RECORDS '
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 21600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_received_records{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.FRAUD.MODEL.ANALYSIS.RESULT.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: max
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 3
          noDataState: OK
          execErrState: OK
          for: 6h
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "3"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: RDxvxDwVk
          title: QUOT.FRAUD.SUBMISSION.EVENTS RECEIVED RECORDS
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 21600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_received_records{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.FRAUD.SUBMISSION.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: max
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 9
          noDataState: OK
          execErrState: OK
          for: 6h
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "9"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: KLzcLDw4z
          title: QUOT.PAYMENT.STATUS.EVENTS RECEIVED RECORDS
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_received_records{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.PAYMENT.STATUS.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: max
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 13
          noDataState: OK
          execErrState: OK
          for: 6h
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "13"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: VKf-YvwVz
          title: QUOT.REBATE.AFFILIATE.WEBHOOK.EVENTS RECEIVED RECORDS
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_received_records{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.REBATE.AFFILIATE.WEBHOOK.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: max
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 17
          noDataState: OK
          execErrState: OK
          for: 6h
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "17"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: 4J_5EDQVz
          title: QUOT.REBATE.PAYOUT.EVENTS RECEIVED RECORDS
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_received_records{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.REBATE.PAYOUT.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: max
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 21
          noDataState: OK
          execErrState: OK
          for: 6h
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "21"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: 0WJBEDw4k
          title: QUOT.REBATE.REDEEM.EVENTS RECEIVED RECORDS
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_received_records{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.REBATE.REDEEM.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: max
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 25
          noDataState: OK
          execErrState: OK
          for: 6h
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "25"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: zyz8EDw4k
          title: QUOT.REBATE.REWARD-STATUS.EVENTS RECEIVED RECORDS
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_received_records{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.REBATE.REWARD-STATUS.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: max
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 29
          noDataState: OK
          execErrState: OK
          for: 6h
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "29"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: xVZjPvQVk
          title: QUOT.RECEIPT.DATA.EXTRACT.EVENTS RECEIVED RECORDS
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_received_records{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.RECEIPT.DATA.EXTRACT.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: max
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 33
          noDataState: OK
          execErrState: OK
          for: 6h
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "33"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: JavzsvwVz
          title: QUOT.RECEIPTS.OCR.DETAILS.EVENTS RECEIVED RECORDS
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_received_records{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.RECEIPTS.OCR.DETAILS.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 37
          noDataState: OK
          execErrState: OK
          for: 6h
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "37"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: eWLgUvwVz
          title: QUOT.SALES.TRANSACTION.PROCESSED.EVENTS RECEIVED RECORDS
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 3600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_received_records{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.SALES.TRANSACTION.PROCESSED.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: max
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 45
          noDataState: OK
          execErrState: OK
          for: 6h
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "45"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: tSBSUvwVk
          title: QUOT.SALES.TRANSACTION.SUBMISSION.EVENTS RECEIVED RECORDS
          condition: C
          data:
            - refId: A
              relativeTimeRange:
                from: 900
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_received_records{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.SALES.TRANSACTION.SUBMISSION.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: A
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: B
                settings:
                    mode: ""
                type: reduce
            - refId: C
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: B
                intervalMs: 1000
                maxDataPoints: 43200
                refId: C
                type: threshold
          dashboardUid: IbX0as84z
          panelId: 49
          noDataState: OK
          execErrState: OK
          for: 15h
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "49"
            summary: Received record for topic {{ $labels.topic }} under kafka instance {{ $labels.kafka_id }} is below 1
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: IzItUDwVz
          title: QUOT.SHOPMIUM.WALLET.REWARD.EVENTS RECEIVED RECORDS
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 3600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_received_records{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.SHOPMIUM.WALLET.REWARD.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: max
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 53
          noDataState: OK
          execErrState: OK
          for: 6h
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "53"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: DnwY8DQ4k
          title: QUOT.USER.STATE.EVENT RECEIVED RECORDS
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 21600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_received_records{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.USER.STATE.EVENT"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: max
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 57
          noDataState: OK
          execErrState: OK
          for: 6h
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "57"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: dIEizcQ4z
          title: QUOT.SALES.TRANSACTION.PIPELINE.EVENTS RECEIVED RECORDS
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 21600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_received_records{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.SALES.TRANSACTION.PIPELINE.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: max
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 41
          noDataState: OK
          execErrState: OK
          for: 6h
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "41"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: a3cbd97b-d36d-4554-822a-5c78349f3c34
          title: 'QUOT.FRAUD.RULES.EVALUATION.EVENTS RECEIVED RECORDS '
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 21600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_received_records{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.FRAUD.RULES.EVALUATION.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: max
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: A
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 41
          noDataState: OK
          execErrState: OK
          for: 6h
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "41"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: dea32cdf-d69f-48c3-8522-3f7d5ef2b03f
          title: QUOT.RECEIPTS.EVALUATION.EVENTS LAG
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 21600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_consumer_lag_offsets{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.RECEIPTS.EVALUATION.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1000
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 62
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "62"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
        - uid: f97ab468-f318-4bed-b1cb-ea86e6936fca
          title: QUOT.RECEIPTS.EVALUATION.EVENTS RECEIVED RECORDS
          condition: B
          data:
            - refId: A
              relativeTimeRange:
                from: 21600
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                datasource:
                    type: prometheus
                    uid: PFD0C3CD7571A05AB
                editorMode: builder
                expr: confluent_kafka_server_received_records{cluster="gke-logging-uswst2-p-active", job="Confluent-Cluster", topic="QUOT.RECEIPTS.EVALUATION.EVENTS"}
                interval: ""
                intervalMs: 15000
                legendFormat: __auto
                maxDataPoints: 43200
                range: true
                refId: A
            - refId: B
              datasourceUid: __expr__
              model:
                conditions:
                    - evaluator:
                        params:
                            - 1
                            - 0
                        type: lt
                      operator:
                        type: and
                      query:
                        params:
                            - A
                      reducer:
                        params: []
                        type: max
                      type: query
                datasource:
                    name: Expression
                    type: __expr__
                    uid: __expr__
                expression: ""
                intervalMs: 1000
                maxDataPoints: 43200
                refId: B
                type: classic_conditions
          dashboardUid: IbX0as84z
          panelId: 63
          noDataState: OK
          execErrState: OK
          for: 5m
          annotations:
            __dashboardUid__: IbX0as84z
            __panelId__: "63"
          labels:
            confluent_lag: confluent_kafka_cloud
          isPaused: false
    - orgId: 1
      name: No Hyperwallet Payment
      folder: RIQ Tahoe Dashboards And alerts
      interval: 5m
      rules:
        - uid: eyWF8fs7z
          title: No Hyperwallet Payment
          condition: final_result
          data:
            - refId: raw_data
              relativeTimeRange:
                from: 43200
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                exemplar: false
                expr: sum(payment_hyperwallet_total)
                hide: false
                interval: ""
                intervalMs: 1000
                legendFormat: ""
                maxDataPoints: 43200
                refId: raw_data
            - refId: raw_data_max
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 3
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - raw_data
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: raw_data_max
                type: reduce
            - refId: raw_data_min
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: min
                refId: raw_data_min
                type: reduce
            - refId: final_result
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: $raw_data_max - $raw_data_min <= 0
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: final_result
                type: math
          noDataState: OK
          execErrState: Error
          for: 1h
          annotations:
            description: No Hyperwallet Payment in last 12 hours
            runbook_url: https://grafana.corp.quotient.com/d/2daTpKy7k/payments?orgId=1&editPanel=8
            summary: No Hyperwallet Payment in last 12 hours
          labels:
            metric: tahoe_payment_hyperwallet_total
          isPaused: false
    - orgId: 1
      name: No Payment requests
      folder: RIQ Tahoe Dashboards And alerts
      interval: 5m
      rules:
        - uid: ql_MUfynz
          title: No Payment requests
          condition: final_result
          data:
            - refId: raw_data
              relativeTimeRange:
                from: 43200
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                exemplar: false
                expr: sum(payment_request_total)
                hide: false
                interval: ""
                intervalMs: 1000
                legendFormat: ""
                maxDataPoints: 43200
                refId: raw_data
            - refId: raw_data_max
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 3
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - raw_data
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: raw_data_max
                type: reduce
            - refId: raw_data_min
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: min
                refId: raw_data_min
                type: reduce
            - refId: final_result
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: $raw_data_max - $raw_data_min <= 0
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: final_result
                type: math
          noDataState: OK
          execErrState: Error
          for: 1h
          annotations:
            description: No Payment requests in last 12 hours
            runbook_url: https://grafana.corp.quotient.com/d/2daTpKy7k/payments?orgId=1&editPanel=6
            summary: No Payment requests in last 12 hours
          labels:
            metric: tahoe_payment_request_total
          isPaused: false
    - orgId: 1
      name: No Receipt Submission Events Received Alert
      folder: RIQ Tahoe Dashboards And alerts
      interval: 5m
      rules:
        - uid: vXe_Cby7z
          title: No Receipt Submission Events Received Alert
          condition: final_result
          data:
            - refId: raw_data
              relativeTimeRange:
                from: 43200
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                exemplar: false
                expr: sum(receipt_submission_eventReceived_total)
                hide: false
                interval: ""
                intervalMs: 1000
                legendFormat: ""
                maxDataPoints: 43200
                refId: raw_data
            - refId: raw_data_max
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 3
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - raw_data
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: raw_data_max
                type: reduce
            - refId: raw_data_min
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: min
                refId: raw_data_min
                type: reduce
            - refId: final_result
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: $raw_data_max - $raw_data_min <= 0
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: final_result
                type: math
          noDataState: OK
          execErrState: Error
          for: 1h
          annotations:
            description: No Receipt Submission Events Received  in last 12 hours
            runbook_url: https://grafana.corp.quotient.com/d/Pgy_hOs7k/receipt-submissions?orgId=1&editPanel=4
            summary: No Receipt Submission Events Received  in last 12 hours
          labels:
            metric: tahoe_receipt_submission_eventReceived_total
          isPaused: true
    - orgId: 1
      name: No Receipt Submission Requests Alert
      folder: RIQ Tahoe Dashboards And alerts
      interval: 5m
      rules:
        - uid: yIBfjbynz
          title: No Receipt Submission Requests Alert
          condition: final_result
          data:
            - refId: raw_data
              relativeTimeRange:
                from: 43200
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                exemplar: false
                expr: sum(receipt_submission_total)
                hide: false
                interval: ""
                intervalMs: 1000
                legendFormat: ""
                maxDataPoints: 43200
                refId: raw_data
            - refId: raw_data_max
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 4900
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - raw_data
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: raw_data_max
                type: reduce
            - refId: raw_data_min
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: min
                refId: raw_data_min
                type: reduce
            - refId: final_result
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: $raw_data_max - $raw_data_min <= 0
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: final_result
                type: math
          noDataState: OK
          execErrState: Error
          for: 1h
          annotations:
            description: No Receipt Submission Requests in last 12 hours
            runbook_url: https://grafana.corp.quotient.com/d/Pgy_hOs7k/receipt-submissions?orgId=1&editPanel=2
            summary: No Receipt Submission Requests in last 12 hours
          labels:
            metric: tahoe_receipt_submission_total
          isPaused: false
    - orgId: 1
      name: No Redemption Evaluation Requests
      folder: RIQ Tahoe Dashboards And alerts
      interval: 10m
      rules:
        - uid: Vn_nAfynk
          title: No Redemption Evaluation Requests
          condition: final_result
          data:
            - refId: raw_data
              relativeTimeRange:
                from: 43200
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                exemplar: false
                expr: sum(evaluate_transaction_receipt_total)
                hide: false
                interval: ""
                intervalMs: 1000
                legendFormat: ""
                maxDataPoints: 43200
                refId: raw_data
            - refId: raw_data_max
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 3
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - raw_data
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: raw_data_max
                type: reduce
            - refId: raw_data_min
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: min
                refId: raw_data_min
                type: reduce
            - refId: final_result
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: $raw_data_max - $raw_data_min <= 0
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: final_result
                type: math
          noDataState: OK
          execErrState: Error
          for: 1h
          annotations:
            description: No Redemption Evaluation Requests
            runbook_url: https://grafana.corp.quotient.com/d/Pgy_hOs7k/receipt-submissions?orgId=1&viewPanel=6
            summary: No Redemption Evaluation Requests in last 12 hours
          labels:
            metric: tahoe_evaluate_transaction_receipt_total
          isPaused: false
    - orgId: 1
      name: Payment Errors (User related)
      folder: RIQ Tahoe Dashboards And alerts
      interval: 5m
      rules:
        - uid: 2fpRjbs7k
          title: Payment Errors (User related)
          condition: final_result
          data:
            - refId: raw_data
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                exemplar: false
                expr: sum(payment_errors_user_total)
                hide: false
                interval: ""
                intervalMs: 1000
                legendFormat: ""
                maxDataPoints: 43200
                refId: raw_data
            - refId: raw_data_max
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 3
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - raw_data
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: raw_data_max
                type: reduce
            - refId: raw_data_min
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: min
                refId: raw_data_min
                type: reduce
            - refId: final_result
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: $raw_data_max - $raw_data_min > 5
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: final_result
                type: math
          noDataState: OK
          execErrState: Error
          for: 10m
          annotations:
            description: More than 5 Payment Errors (User related) in last 5 minutes
            runbook_url: https://grafana.corp.quotient.com/d/2daTpKy7k/payments?orgId=1&editPanel=6
            summary: More than 5 Payment Errors (User related) in last 5 minutes
          labels:
            metric: tahoe_payment_errors_user_total
          isPaused: false
    - orgId: 1
      name: Payment Request Rejected
      folder: RIQ Tahoe Dashboards And alerts
      interval: 5m
      rules:
        - uid: CBKFjbs7z
          title: Payment Request Rejected
          condition: final_result
          data:
            - refId: raw_data
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                exemplar: false
                expr: sum(payment_errors_request_total)
                hide: false
                interval: ""
                intervalMs: 1000
                legendFormat: ""
                maxDataPoints: 43200
                refId: raw_data
            - refId: raw_data_max
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 3
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - raw_data
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: raw_data_max
                type: reduce
            - refId: raw_data_min
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: min
                refId: raw_data_min
                type: reduce
            - refId: final_result
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: $raw_data_max - $raw_data_min >= 5
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: final_result
                type: math
          noDataState: OK
          execErrState: Error
          for: 10m
          annotations:
            description: More than Payment Requests Rejected in last 5 minutes
            runbook_url: https://grafana.corp.quotient.com/d/2daTpKy7k/payments?orgId=1&editPanel=6
            summary: More than Payment Requests Rejected in last 5 minutes
          labels:
            metric: tahoe_payment_errors_request_total
          isPaused: false
    - orgId: 1
      name: Receipt Correction Consumer Errors
      folder: RIQ Tahoe Dashboards And alerts
      interval: 5m
      rules:
        - uid: OWL_ubs7k
          title: Receipt Correction Consumer Errors
          condition: final_result
          data:
            - refId: raw_data
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                exemplar: false
                expr: sum(receipt_correction_error_total)
                hide: false
                interval: ""
                intervalMs: 1000
                legendFormat: ""
                maxDataPoints: 43200
                refId: raw_data
            - refId: raw_data_max
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 3
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - raw_data
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: raw_data_max
                type: reduce
            - refId: raw_data_min
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: min
                refId: raw_data_min
                type: reduce
            - refId: final_result
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: $raw_data_max - $raw_data_min >= 5
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: final_result
                type: math
          noDataState: OK
          execErrState: Error
          for: 10m
          annotations:
            description: More than 5 Correction consumer errors in last 5 minutes
            runbook_url: https://grafana.corp.quotient.com/d/Pgy_hOs7k/receipt-submissions?orgId=1&viewPanel=4
            summary: More than 5 Correction consumer errors in last 5 minutes
          labels:
            metric: tahoe_receipt_correction_error_total
          isPaused: false
    - orgId: 1
      name: Receipt Submission Consumer Errors
      folder: RIQ Tahoe Dashboards And alerts
      interval: 5m
      rules:
        - uid: ehkoXxsnz
          title: Receipt Submission Consumer Errors
          condition: final_result
          data:
            - refId: raw_data
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                exemplar: false
                expr: sum(receipt_submission_error_total)
                hide: false
                interval: ""
                intervalMs: 1000
                legendFormat: ""
                maxDataPoints: 43200
                refId: raw_data
            - refId: raw_data_max
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 3
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - raw_data
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: raw_data_max
                type: reduce
            - refId: raw_data_min
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: min
                refId: raw_data_min
                type: reduce
            - refId: final_result
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: $raw_data_max - $raw_data_min >= 5
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: final_result
                type: math
          noDataState: OK
          execErrState: Error
          for: 10m
          annotations:
            description: More than 5 Submission consumer errors in last 5 minutes
            runbook_url: https://grafana.corp.quotient.com/d/Pgy_hOs7k/receipt-submissions?orgId=1&viewPanel=4
            summary: More than 5 Submission consumer errors in last 5 minutes
          labels:
            metric: tahoe_receipt_submission_error
          isPaused: false
    - orgId: 1
      name: Redemption Evaluation API Errors
      folder: RIQ Tahoe Dashboards And alerts
      interval: 5m
      rules:
        - uid: M6n19by7k
          title: Redemption Evaluation API Errors
          condition: final_result
          data:
            - refId: raw_data
              relativeTimeRange:
                from: 300
                to: 0
              datasourceUid: PFD0C3CD7571A05AB
              model:
                exemplar: false
                expr: sum(receipt_evaluation_url_error_total)
                hide: false
                interval: ""
                intervalMs: 1000
                legendFormat: ""
                maxDataPoints: 43200
                refId: raw_data
            - refId: raw_data_max
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 3
                        type: gt
                      operator:
                        type: and
                      query:
                        params:
                            - raw_data
                      reducer:
                        params: []
                        type: last
                      type: query
                datasource:
                    type: __expr__
                    uid: "-100"
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: max
                refId: raw_data_max
                type: reduce
            - refId: raw_data_min
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: raw_data
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                reducer: min
                refId: raw_data_min
                type: reduce
            - refId: final_result
              datasourceUid: "-100"
              model:
                conditions:
                    - evaluator:
                        params:
                            - 0
                            - 0
                        type: gt
                      operator:
                        type: and
                      query:
                        params: []
                      reducer:
                        params: []
                        type: avg
                      type: query
                datasource:
                    type: __expr__
                    uid: __expr__
                expression: $raw_data_max - $raw_data_min >= 5
                hide: false
                intervalMs: 1000
                maxDataPoints: 43200
                refId: final_result
                type: math
          noDataState: OK
          execErrState: Error
          for: 10m
          annotations:
            description: Redemption Service Evaluation API - More than 5 errors in last 5 minutes
            runbook_url: https://grafana.corp.quotient.com/d/Pgy_hOs7k/receipt-submissions?orgId=1&editPanel=6
            summary: Redemption Service Evaluation API - More than 5 errors in last 5 minutes
          labels:
            metric: tahoe_receipt_evaluation_url_error_total
          isPaused: false
